\documentclass{article}

% --- PAKIETY PODSTAWOWE ---
\usepackage[utf8]{inputenc} % Pozwala na bezpośrednie używanie znaków UTF-8 (np. polskich liter)
\usepackage[T1]{fontenc}    % Poprawia kodowanie fontów, umożliwia poprawne dzielenie wyrazów z polskimi znakami
\usepackage[polish]{babel}  % Włącza polskie zasady składu tekstu (dzielenie wyrazów, nazwy itp.)
\usepackage{amsmath}        % Zaawansowane środowiska matematyczne
\usepackage{amssymb}        % Dodaje symbole matematyczne, np. \mathbb{N}
\usepackage{amsfonts}       % Dodatkowe fonty matematyczne
\usepackage{geometry}       % Umożliwia łatwe zarządzanie marginesami

% --- PAKIETY DODATKOWE ---
\usepackage{amsthm}         % Pakiety do tworzenia środowisk typu definicja, twierdzenie
\usepackage{enumitem}       % Umożliwia zaawansowaną konfigurację list
\usepackage[
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue
]{hyperref}                 % Tworzy klikalne linki w dokumencie PDF

% --- PAKIETY DO RYSOWANIA ---
\usepackage{tikz}
\usetikzlibrary{automata, arrows.meta, positioning}

% --- KONFIGURACJA STRONY ---
\geometry{a4paper, margin=1in}

% --- DEFINICJA WŁASNYCH ŚRODOWISK ---
\theoremstyle{definition}
\newtheorem{definition}{Definicja}[section] % Definicje będą numerowane w ramach sekcji
\newtheorem{example}[definition]{Przykład}
\newtheorem{lemat}[definition]{Lemat}
\newtheorem{wniosek}[definition]{Wniosek}
\newtheorem{twierdzenie}[definition]{Twierdzenie}
\newtheorem{obserwacja}[definition]{Obserwacja}

\renewcommand{\qedsymbol}{$\blacksquare$} % Zmiana symbolu końca dowodu

\begin{document}

\section{Procesy stochastyczne}
\renewcommand{\thedefinition}{\arabic{section}.\arabic{definition}} % Zmiana formatu numeracji na "sekcja.definicja"

\begin{definition}
Niech:
\begin{enumerate}[label=\alph*)]
    \item \textbf{Przestrzeń probabilistyczna} $(\Omega, \mathcal{F}, P)$, gdzie:
    \begin{itemize}
        \item $\Omega$ to przestrzeń zdarzeń elementarnych,
        \item $\mathcal{F}$ to $\sigma$-ciało podzbiorów $\Omega$,
        \item $P$ to miara prawdopodobieństwa określona na $\mathcal{F}$.
    \end{itemize}

    \item \textbf{Przestrzeń stanów} $(S, \mathcal{B})$, będąca przestrzenią mierzalną.

    \item Niepusty \textbf{zbiór indeksów (czasu)} $T$.
W zależności od natury tego zbioru, przyjęło się stosować odmienną notację:
    \begin{itemize}
        \item Gdy czas jest \textbf{ciągły}, np. $T = [0, \infty)$, proces oznaczamy jako $(X_t)_{t \in T}$.
        \item Gdy czas jest \textbf{dyskretny}, np. $T = \mathbb{N}_0 = \{0, 1, 2, \dots\}$, proces oznaczamy jako $(X_n)_{n \in \mathbb{N}_0}$.
    \end{itemize}
\end{enumerate}
\textbf{Procesem stochastycznym} nazywamy rodzinę zmiennych losowych {$X_t$}$_{t \in T}$, w której każda zmienna losowa $X_t: \Omega \to S$ jest określona na $(\Omega, \mathcal{F}, P)$ i przyjmuje wartości w $(S, \mathcal{B})$ (tzn. zachodzi warunek mierzalności: $X_t^{-1}(\mathcal{B}) \subset \mathcal{F}$). 

\end{definition}

\subsection{Dwa spojrzenia na proces – Intuicja}

Proces stochastyczny $X_t(\omega)$ jest funkcją dwóch argumentów: czasu $t \in T$ i zdarzenia elementarnego $\omega \in \Omega$. Aby go zrozumieć, możemy ustalić jeden z argumentów i zobaczyć, co otrzymamy.

\subsubsection*{1. Ustalmy czas $t \in T$ (patrzymy na "przekrój")}

Gdy ustalimy konkretny moment czasu $t_0$, funkcja $X_{t_0}(\omega)$ zależy już tylko od wyniku losowego $\omega$. Otrzymujemy w ten sposób \textbf{zmienną losową}. Jest to "zdjęcie" procesu w jednej chwili, pokazujące rozkład możliwych wartości.


\subsubsection*{2. Ustalmy wynik losowy $\omega \in \Omega$ (patrzymy na "ścieżkę")}

Gdy ustalimy konkretny wynik losowy $\omega_0$, funkcja $X_t(\omega_0)$ zależy już tylko od czasu $t$. Otrzymujemy w ten sposób zwykłą funkcję czasu, którą nazywamy \textbf{trajektorią} (ang. \textit{trajectory}, \textit{sample path}) lub \textbf{realizacją procesu}. Jest to "film" pokazujący jedną konkretną ewolucję procesu.


\vspace{1em}
Podsumowując, proces stochastyczny to cała kolekcja wszystkich możliwych trajektorii.

\subsection{Po co nam warunek mierzalności?}

Warunek mierzalności, czyli $X_t^{-1}(\mathcal{B}) \subset \mathcal{F}$, jest kluczowym technicznym wymogiem, który pozwala nam "przenosić" miarę prawdopodobieństwa $P$ z przestrzeni $\Omega$ na przestrzeń stanów $S$. Bez niego nie moglibyśmy w sensowny sposób pytać o prawdopodobieństwo zdarzeń typu "$X_t$ wpada do zbioru $B$".

Dla pojedynczej zmiennej losowej $X: (\Omega, \mathcal{F}) \to (S, \mathcal{B})$, jej \textbf{rozkład} (ozn. $\mu_X$) to nowa miara prawdopodobieństwa, ale zdefiniowana na przestrzeni stanów $(S, \mathcal{B})$. Mówi nam ona, jakie jest prawdopodobieństwo, że zmienna $X$ przyjmie wartość z danego zbioru $B \in \mathcal{B}$:
\[
\mu_X(B) := P(X \in B) = P(\{\omega \in \Omega : X(\omega) \in B\}) = P(X^{-1}(B))
\]
Aby to wyrażenie miało sens, zbiór $X^{-1}(B)$ musi należeć do $\sigma$-ciała $\mathcal{F}$ (musimy umieć zmierzyć jego "wielkość" za pomocą miary $P$). I to właśnie gwarantuje nam warunek mierzalności zmiennej losowej $X$.

W procesach stochastycznych uogólniamy pojęcie rozkładu na tzw. \textbf{rozkłady skończenie wymiarowe}. Zamiast patrzeć na jedną zmienną $X_t$, analizujemy łączne zachowanie procesu w wielu chwilach czasu, czyli wektory $(X_{t_1}, \dots, X_{t_n})$.

\begin{definition}[Rozkład skończenie wymiarowy]
Dla dowolnego $n \in \mathbb{N}$ i dowolnego zbioru chwil czasu $t_1, \dots, t_n \in T$, \textbf{rozkładem skończenie wymiarowym} procesu $(X_t)_{t \in T}$ nazywamy rozkład wektora losowego $(X_{t_1}, \dots, X_{t_n})$. Jest to miara prawdopodobieństwa $\mu_{t_1, \dots, t_n}$ na przestrzeni mierzalnej $(S^n, \mathcal{B}^n)$ zdefiniowana jako:
\[
\mu_{t_1, \dots, t_n}(B) := P((X_{t_1}, \dots, X_{t_n}) \in B), \quad \text{dla } B \in \mathcal{B}^n
\]
\end{definition}

\begin{definition}[Rodzina rozkładów skończenie wymiarowych]
Kolekcję wszystkich rozkładów skończenie wymiarowych procesu $(X_t)_{t \in T}$ dla wszystkich możliwych, skończonych wyborów chwil czasu, nazywamy \textbf{rodziną rozkładów skończenie wymiarowych} tego procesu. Formalnie jest to zbiór miar:
\begin{equation*}
\left\{ \mu_{t_1, \dots, t_n} \mid n \in \mathbb{N}, t_1, \dots, t_n \in T \right\}
\end{equation*}
\end{definition}

Co ważne, ta rodzina rozkładów jest jednym z podstawowych sposobów charakteryzowania i klasyfikowania procesów stochastycznych. Dwa procesy o tej samej rodzinie rozkładów skończenie wymiarowych są z perspektywy probabilistycznej nierozróżnialne. Warto też zauważyć, że najprostszy przypadek, $n=1$, daje nam \textbf{rozkłady jednowymiarowe} ($\mu_t$), które opisują zachowanie procesu w pojedynczej chwili czasu.

\begin{example}[Ciąg niezależnych zmiennych losowych (szum)]

Niech $(\xi_n)_{n \in \mathbb{N}_0}$ będzie ciągiem niezależnych zmiennych losowych o jednakowym rozkładzie (i.i.d. -- \textit{independent and identically-distributed}), zdefiniowanym następująco:
\begin{equation*}
 P(\xi_n = 1) = p, \quad P(\xi_n = -1) = 1-p
\end{equation*}
dla pewnego $p \in (0, 1)$.

W tym przypadku:
\begin{itemize}
    \item \textbf{Zbiór indeksów (czasu):} $T = \mathbb{N}_0 = \{0, 1, 2, \dots\}$ (czas dyskretny).
    \item \textbf{Przestrzeń stanów:} $S = \{-1, 1\}$.
\end{itemize}

\textbf{Intuicja:} Jest to prymitywny model, który nie modeluje żadnych zależności czasowych -- reprezentuje czysty \textbf{szum} (w tym przypadku tzw. biały szum). Wynik w chwili $n$ nie ma żadnego wpływu na wynik w chwili $n+1$.

\textbf{Ciekawostka (Twierdzenie Kołmogorowa):} Mogłoby się wydawać, że "skonstruowanie" nieskończonej rodziny niezależnych zmiennych losowych jest problematyczne. Jednak fundamentalne twierdzenie Kołmogorowa o istnieniu procesu gwarantuje, że dla dowolnego zadanego rozkładu prawdopodobieństwa, zawsze można skonstruować przestrzeń probabilistyczną i proces, który jest ciągiem niezależnych zmiennych losowych o dokładnie tym rozkładzie.
\end{example}

\begin{example}[Błądzenie losowe jako wstęp do procesów Markowa]

Ten przykład wprowadza prostą zależność między kolejnymi stanami procesu.

Zdefiniujmy nowy proces $(X_n)_{n \in \mathbb{N}_0}$ w oparciu o ciąg zmiennych $(\xi_n)$ z poprzedniego przykładu. Niech:
\begin{itemize}
    \item $X_0 = 0$ (startujemy z zera).
    \item $X_n = X_{n-1} + \xi_n$ dla $n \ge 1$.
\end{itemize}
Taki proces nazywamy \textbf{błądzeniem losowym} (lub spacerem losowym, ang. \textit{random walk}).

Jego komponenty to:
\begin{itemize}
    \item \textbf{Zbiór indeksów (czasu):} $T = \mathbb{N}_0$ (czas dyskretny).
    \item \textbf{Przestrzeń stanów:} $S = \mathbb{Z} = \{\dots, -2, -1, 0, 1, 2, \dots\}$ (zbiór liczb całkowitych).
\end{itemize}

\textbf{Intuicja (Własność Markowa):} Proces ten opisuje pozycję "wędrowca", który w każdej jednostce czasu wykonuje losowy krok. Kluczową różnicą w stosunku do poprzedniego przykładu jest tu "pamięć". Jednak jest to pamięć bardzo krótka -- aby poznać stan procesu w przyszłości (w chwili $n+1$), wystarczy nam znajomość stanu obecnego (w chwili $n$). Cała przeszłość procesu (stany $X_0, \dots, X_{n-1}$) nie wnosi już żadnej dodatkowej informacji.

Ta fundamentalna właściwość, polegająca na "braku pamięci" o odległej przeszłości, jest niezwykle ważna i nosi nazwę \textbf{własności Markowa}. Procesy ją spełniające to \textbf{procesami Markowa}, a błądzenie losowe jest ich koronnym przykładem. Własność ta prowadzi nas wprost do definicji nowej, potężnej klasy procesów, którym zajmiemy się w następnej sekcji.
\end{example}

\section{Łańcuchy Markowa z czasem dyskretnym}

Rozważmy proces stochastyczny z czasem dyskretnym ($T=\mathbb{N}_0$) i co najwyżej przeliczalną przestrzenią stanów $S$. Jak widzieliśmy, aby w pełni opisać taki proces, musimy znać jego rozkłady skończenie wymiarowe, czyli prawdopodobieństwa dowolnych ścieżek, np. $P(X_0=x_0, X_1=x_1, \dots, X_n=x_n)$.

Z ogólnej definicji prawdopodobieństwa warunkowego, $P(A \cap B) = P(A|B)P(B)$, możemy zapisać to prawdopodobieństwo łączne w postaci "teleskopowego" iloczynu:
\begin{equation*}
\begin{split}
    P(X_0=x_0, X_1=x_1, \dots, X_n=x_n) = P(X_0=x_0) \cdot P(X_1=x_1 | X_0=x_0) \cdot \\
    \cdot P(X_2=x_2 | X_0=x_0, X_1=x_1) \cdots P(X_n=x_n | X_0=x_0, \dots, X_{n-1}=x_{n-1})
\end{split}
\end{equation*}
Powyższy wzór jest zawsze prawdziwy, ale w ogólnym przypadku niepraktyczny, ponieważ ostatnie wyrazy warunkują prawdopodobieństwo od całej, potencjalnie bardzo długiej, historii procesu.

Kluczowa idea polega na rozważeniu szczególnej, ale bardzo ważnej klasy procesów, dla których ten wzór dramatycznie się upraszcza.

\begin{definition}[Własność Markowa]
Mówimy, że proces stochastyczny $(X_n)_{n \in \mathbb{N}_0}$ ma \textbf{własność Markowa} (a sam proces nazywamy \textbf{łańcuchem Markowa}), jeśli:
\begin{equation*}
\begin{gathered}
    \forall n \ge 1 \\
    \forall x_0, \dots, x_n \in S
\end{gathered}
\end{equation*}
zachodzi:
\begin{equation*}
    P(X_n=x_n | X_0=x_0, \dots, X_{n-1}=x_{n-1}) = P(X_n=x_n | X_{n-1}=x_{n-1})
\end{equation*}
Jest to sytuacja, w której "w każdym takim prawdopodobieństwie warunkowym interesuje nas tylko ostatni element" historii.
\end{definition}

Dzięki tej własności, "teleskopowy" wzór na prawdopodobieństwo łączne upraszcza się do postaci, która zależy już tylko od dwóch, znacznie prostszych komponentów:
\begin{enumerate}
    \item \textbf{Rozkładu początkowego} $\alpha = [\alpha_i]_{i \in S}$, czyli prawdopodobieństw $\alpha_i = P(X_0=i)$.
    \item \textbf{Prawdopodobieństw przejścia} w jednym kroku, czyli $P(X_n=j | X_{n-1}=i)$.
\end{enumerate}

\begin{definition}[Jednorodny Łańcuch Markowa]
Łańcuch Markowa nazywamy \textbf{jednorodnym}, jeśli prawdopodobieństwa przejścia w jednym kroku nie zależą od czasu $n$, tzn. prawdopodobieństwo przejścia ze stanu $i$ do stanu $j$ jest zawsze takie samo, niezależnie od tego, w którym kroku proces się znajduje.

Formalnie, istnieje funkcja $p: S \times S \to [0, 1]$ taka, że dla wszystkich $n \in \mathbb{N}$ oraz $i, j \in S$ zachodzi:
\begin{equation*}
    P(X_n=j | X_{n-1}=i) = p(i, j)
\end{equation*}
\end{definition}

\textit{Od teraz, mówiąc ``łańcuch Markowa'', będziemy prawie zawsze mieli na myśli \textbf{jednorodny łańcuch Markowa (jŁM)}.}

\begin{definition}[Macierz przejścia]
Funkcję $p(i,j)$ z powyższej definicji, określającą prawdopodobieństwa przejść, wygodnie jest zapisać w postaci macierzy. Jest to możliwe właśnie dzięki założeniu, że przestrzeń stanów $S$ jest co najwyżej przeliczalna (cnp), co pozwala nam ``ustawić'' stany w wierszach i kolumnach.

\textbf{Macierzą przejścia w jednym kroku} łańcucha Markowa nazywamy macierz $P$, której elementy $p_{ij}$ dane są przez:
\begin{equation*}
    p_{ij} = p(i,j) = P(X_n=j | X_{n-1}=i)
\end{equation*}
Macierz ta ma wymiary $|S| \times |S|$ (mogą być nieskończone) i w pełni opisuje dynamikę jednorodnego łańcucha. Każda macierz przejścia jest \textbf{macierzą stochastyczną}, tzn. spełnia dwa warunki:
\begin{enumerate}
    \item Jej elementy są nieujemne: $p_{ij} \ge 0$ dla wszystkich $i,j \in S$.
    \item Suma prawdopodobieństw w każdym wierszu jest równa 1: $\sum_{j \in S} p_{ij} = 1$ dla każdego $i \in S$.
\end{enumerate}
\end{definition}

\begin{example}
Rozważmy jŁM o następujących komponentach:
\begin{itemize}
    \item Przestrzeń stanów: $S = \{1, 2\}$.
    \item Rozkład początkowy: $\alpha = [\frac{1}{2}, \frac{1}{2}]$, co oznacza, że $P(X_0=1) = \frac{1}{2}$, a $P(X_0=2) = \frac{1}{2}$.
    \item Prawdopodobieństwa przejścia dane są następująco:
    \begin{itemize}
        \item $P(X_{n+1}=1 | X_n=1) = 2/3$
        \item $P(X_{n+1}=2 | X_n=1) = 1/3$
        \item $P(X_{n+1}=1 | X_n=2) = 1/2$
        \item $P(X_{n+1}=2 | X_n=2) = 1/2$
    \end{itemize}
\end{itemize}

Na podstawie tych prawdopodobieństw, możemy skonstruować \textbf{macierz przejścia} $P$:
\begin{equation*}
    P = 
    \begin{bmatrix}
        2/3 & 1/3 \\
        1/2 & 1/2
    \end{bmatrix}
\end{equation*}
Zauważmy, że jest to macierz stochastyczna, ponieważ wszystkie jej elementy są nieujemne, a suma każdego wiersza jest równa 1.

Dynamikę tego łańcucha można również zwizualizować za pomocą \textbf{grafu stanów}:

\begin{center}
\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=3cm, state/.style={circle, draw, minimum size=0.8cm}]
    \node[state] (1) {1};
    \node[state] (2) [right=of 1] {2};

    \path (1) edge [loop above] node {2/3} (1)
              edge [bend left]  node {1/3} (2);
    \path (2) edge [loop above] node {1/2} (2)
              edge [bend left]  node {1/2} (1);
\end{tikzpicture}
\end{center}

\textbf{Wniosek:} Mając te dwa obiekty – wektor rozkładu początkowego $\alpha$ i macierz przejścia $P$ – jesteśmy w stanie w pełni opisać zachowanie procesu i generować jego losowe trajektorie. Proces losowania wyglądałby następująco: najpierw losujemy stan początkowy $X_0$ zgodnie z rozkładem $\alpha$. Następnie, jeśli wylosowaliśmy $X_0=i$, losujemy stan $X_1$ zgodnie z rozkładem danym przez $i$-ty wiersz macierzy $P$. Proces ten kontynuujemy dla kolejnych kroków.
\end{example}

\begin{lemat}[Równoważny warunek Markowa]
Własność Markowa jest często przedstawiana w mocniejszej, równoważnej formie, która mówi, że przyszłość procesu zależy tylko od ostatniego znanego nam stanu, niezależnie od tego, jak odległa i ``dziurawa'' jest nasza wiedza o przeszłości.

Formalnie, dla dowolnego ciągu rosnących chwil czasu $n_1 < n_2 < \dots < n_k < n_{k+1}$ i dowolnych stanów $x_{n_1}, \dots, x_{n_{k+1}} \in S$, zachodzi:
\begin{equation*}
\begin{split}
    P(X_{n_{k+1}} = x_{n_{k+1}} | X_{n_k}=x_{n_k}, \dots, X_{n_1}=x_{n_1}) \\
    = P(X_{n_{k+1}} = x_{n_{k+1}} | X_{n_k}=x_{n_k})
\end{split}
\end{equation*}
Na przykład, wiedząc, jaki był stan procesu w chwili 7, informacja o stanie w chwili 3 nie wnosi już nic nowego do przewidywania stanu w chwili 10:
\begin{equation*}
    P(X_{10}=x_{10} | X_7=x_7, X_3=x_3) = P(X_{10}=x_{10} | X_7=x_7)
\end{equation*}
\end{lemat}

\section{Prawdopodobieństwa i macierze przejścia w n krokach}

\begin{definition}[Prawdopodobieństwo przejścia w n krokach]
Prawdopodobieństwem przejścia ze stanu $i$ do stanu $j$ w $n$ krokach ($n \in \mathbb{N}$) nazywamy prawdopodobieństwo warunkowe:
\begin{equation*}
    p_n(i, j) := P(X_n = j | X_0 = i)
\end{equation*}
Dzięki jednorodności łańcucha, prawdopodobieństwo to nie zależy od wyboru "chwili startowej", a jedynie od długości przedziału czasowego. Oznacza to, że dla dowolnego $k \in \mathbb{N}_0$:
\begin{equation*}
    p_n(i, j) = P(X_{n+k} = j | X_k = i)
\end{equation*}
\end{definition}

\begin{definition}[Macierz przejścia w n krokach]
Analogicznie do macierzy jednokrokowej, elementy $p_n(i, j)$ możemy zebrać w \textbf{macierz przejścia w n krokach}, oznaczaną jako $P(n)$:
\begin{equation*}
    P(n) := [p_n(i, j)]_{i,j \in S}
\end{equation*}
\end{definition}

\begin{twierdzenie}[Równania Chapmana-Kołmogorowa]
Dla dowolnych $m, n \in \mathbb{N}_0$ oraz dla wszystkich stanów $i, j \in S$ zachodzi:
\begin{equation*}
    p_{m+n}(i, j) = \sum_{k \in S} p_m(i, k) p_n(k, j)
\end{equation*}
\end{twierdzenie}

\begin{proof}
Dowód opiera się na zastosowaniu wzoru na prawdopodobieństwo całkowite oraz własności Markowa.
Z definicji prawdopodobieństwa przejścia w $m+n$ krokach mamy:
\begin{equation*}
    p_{m+n}(i, j) = P(X_{m+n} = j | X_0 = i)
\end{equation*}
Aby dotrzeć ze stanu $i$ do stanu $j$ w $m+n$ krokach, proces musi w "pośrednim" kroku $m$ znaleźć się w jakimś stanie $k \in S$. Sumując po wszystkich możliwych stanach pośrednich $k$, otrzymujemy:
\begin{align*} 
    P(X_{m+n} = j | X_0 = i) &= P\left(\bigcup_{k \in S} \{X_{m+n}=j, X_m=k\} \Big| X_0=i\right) \\
    &= \sum_{k \in S} P(X_{m+n}=j, X_m=k | X_0=i) \quad \text{(bo zdarzenia są rozłączne)} \\
    &= \sum_{k \in S} \frac{P(X_{m+n}=j, X_m=k, X_0=i)}{P(X_0=i)} \\
    & \quad \text{(rozpisujemy licznik ze wzoru } P(A,B)=P(A|B)P(B) \text{ )} \\
    &= \sum_{k \in S} \frac{P(X_{m+n}=j | X_m=k, X_0=i) \cdot P(X_m=k, X_0=i)}{P(X_0=i)} \\
    &= \sum_{k \in S} P(X_{m+n}=j | X_m=k, X_0=i) \cdot P(X_m=k | X_0=i)
\end{align*} 
Teraz stosujemy kluczowe założenia:
\begin{enumerate}
    \item \textbf{Własność Markowa}: Informacja o stanie w chwili $X_0=i$ jest zbędna do przewidywania przyszłości, jeśli znamy stan w chwili $X_m=k$.
    \begin{equation*} 
        P(X_{m+n}=j | X_m=k, X_0=i) = P(X_{m+n}=j | X_m=k)
    \end{equation*} 
    \item \textbf{Jednorodność w czasie}: Prawdopodobieństwo przejścia zależy tylko od różnicy czasu.
    \begin{align*} 
        P(X_{m+n}=j | X_m=k) &= p_n(k, j) \\
        P(X_m=k | X_0=i) &= p_m(i, k)
    \end{align*} 
\end{enumerate}
Podstawiając te zależności do naszej sumy, otrzymujemy tezę:
\begin{equation*} 
    p_{m+n}(i, j) = \sum_{k \in S} p_m(i, k) p_n(k, j)
\end{equation*} 
Co kończy dowód.
\end{proof}

\subsection{Postać macierzowa i intuicje}

Równania Chapmana-Kołmogorowa mają bardzo elegancką i użyteczną interpretację macierzową. Wyrażenie $\sum_{k \in S} p_m(i, k) p_n(k, j)$ odpowiada dokładnie definicji mnożenia macierzy: jest to wzór na element znajdujący się w $i$-tym wierszu i $j$-tej kolumnie iloczynu macierzy $P(m)$ i $P(n)$.

To spostrzeżenie pozwala zapisać równania Chapmana-Kołmogorowa w niezwykle zwartej postaci macierzowej:
\begin{equation*} 
    P(m+n) = P(m) \cdot P(n)
\end{equation*} 

\subsubsection*{Wniosek: Macierz przejścia w n krokach to n-ta potęga macierzy P}
Z powyższej własności wynika fundamentalny wniosek. Ustawiając $m=1$ i stosując indukcję, otrzymujemy:
\begin{itemize}
    \item $P(2) = P(1+1) = P(1) \cdot P(1) = P \cdot P = P^2$
    \item $P(3) = P(2+1) = P(2) \cdot P(1) = P^2 \cdot P = P^3$
    \item ...
    \item $P(n) = P^n$
\end{itemize}
\textbf{Macierz przejścia w n krokach jest po prostu n-tą potęgą macierzy przejścia w jednym kroku.}

\begin{example}
Jeśli chcemy obliczyć prawdopodobieństwo przejścia ze stanu $i$ do $j$ w 2 krokach, możemy albo sumować po wszystkich możliwych ścieżkach długości 2:
\begin{equation*} 
    p_2(i, j) = \sum_{k \in S} p_{ik} p_{kj}
\end{equation*} 
Albo po prostu obliczyć macierz $P^2$ i odczytać jej element $(i,j)$. Obie metody są tożsame.
\end{example}

\subsubsection*{Znaczenie praktyczne}
Ta prosta zależność jest niezwykle potężna. Oznacza, że cała dynamika jednorodnego łańcucha Markowa na dowolnym horyzoncie czasowym jest w pełni zdeterminowana przez macierz przejścia w jednym kroku $P$.

\textbf{Rozkład prawdopodobieństwa w chwili n:}
Jeśli znamy rozkład początkowy $\alpha = [\alpha_i]_{i \in S}$, gdzie $\alpha_i = P(X_0=i)$, to rozkład w chwili $n$, czyli wektor $\alpha^{(n)} = [P(X_n=j)]_{j \in S}$, możemy obliczyć następująco:
\begin{align*} 
    P(X_n=j) &= \sum_{i \in S} P(X_n=j, X_0=i) \\
    &= \sum_{i \in S} P(X_n=j | X_0=i) \cdot P(X_0=i) \\
    &= \sum_{i \in S} (P^n)_{ij} \cdot \alpha_i
\end{align*} 
W ostatnim kroku podstawiliśmy zdefiniowane wcześniej symbole: $P(X_n=j | X_0=i) = (P^n)_{ij}$ (prawdopodobieństwo przejścia w n krokach) oraz $P(X_0=i) = \alpha_i$ (prawdopodobieństwo z rozkładu początkowego).
W notacji wektorowej (traktując $\alpha$ jako wektor wierszowy) jest to po prostu:
\begin{equation*} 
    \alpha^{(n)} = \alpha \cdot P^n
\end{equation*} 
To pokazuje, że mając rozkład początkowy $\alpha$ i macierz przejścia $P$, możemy obliczyć dowolny rozkład skończenie wymiarowy, co w pełni determinuje cały proces.


\begin{example}[Jak obliczyć prawdopodobieństwo dla niekolejnych chwil?]
Załóżmy, że chcemy obliczyć prawdopodobieństwo łączne dla chwil, które nie następują po sobie, np. $P(X_{20}=x_{20}, X_5=x_5, X_3=x_3)$. Korzystając z reguły łańcuchowej i wielokrotnie stosując własność Markowa, możemy to zapisać jako:
\begin{align*} 
    & P(X_{20}=x_{20}, X_5=x_5, X_3=x_3) \\
    &= P(X_{20}=x_{20} | X_5=x_5) \cdot P(X_5=x_5 | X_3=x_3) \cdot P(X_3=x_3) \\
    &= (P^{15})_{x_5, x_{20}} \cdot (P^2)_{x_3, x_5} \cdot (\alpha P^3)_{x_3}
\end{align*} 
Warto przy tym wyjaśnić notację: $(P^{15})_{x_5, x_{20}}$ to element w wierszu $x_5$ i kolumnie $x_{20}$ macierzy $P^{15}$ (czyli macierzy przejścia w 15 krokach). Reprezentuje on prawdopodobieństwo przejścia ze stanu $x_5$ do stanu $x_{20}$ w dokładnie 15 krokach.
\end{example}

\begin{example}[Jak obliczyć prawdopodobieństwo warunkowe dla niekolejnych chwil?]
Podobnie postępujemy dla prawdopodobieństwa warunkowego. Własność Markowa pozwala na rozbicie prawdopodobieństwa ścieżki na iloczyn przejść:
\begin{align*} 
    & P(X_7=x_7, X_5=x_5, X_2=x_2 | X_0=x_0) \\
    &= P(X_7=x_7 | X_5=x_5) \cdot P(X_5=x_5 | X_2=x_2) \cdot P(X_2=x_2 | X_0=x_0) \\
    &= (P^2)_{x_5, x_7} \cdot (P^3)_{x_2, x_5} \cdot (P^2)_{x_0, x_2}
\end{align*} 
\end{example}

\section{Czasy i Prawdopodobieństwa Trafień}

Aby móc klasyfikować stany, musimy najpierw zdefiniować kilka kluczowych pojęć związanych z "trafianiem" w stany przez proces.

\begin{definition}[Moment pierwszego trafienia]
Dla danego stanu $j \in S$, \textbf{momentem pierwszego trafienia} w stanie $j$ nazywamy zmienną losową $T_j$ zdefiniowaną jako:
\begin{equation*} 
    T_j := \min\{ n \ge 1 \mid X_n = j \}
\end{equation*} 
Jest to numer kroku, w którym proces po raz pierwszy (po chwili początkowej) znalazł się w stanie $j$. Jeśli proces nigdy nie trafia do stanu $j$, przyjmujemy, że $T_j = \infty$.
\end{definition}

\begin{definition}[Całkowita liczba trafień]
Dla danego stanu $j \in S$, \textbf{całkowitą liczbę trafień} w stanie $j$ definiujemy jako zmienną losową $N_j$:
\begin{equation*} 
    N_j := \sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=j\}}
\end{equation*} 
gdzie $\mathbf{1}_{\{A\}}$ to funkcja indykatorowa zdarzenia $A$.
\vspace{1em}

\textbf{Intuicja:} Na każdej trajektorii procesu, zmienna losowa $N_j$ po prostu zlicza, ile razy (po chwili początkowej) proces "uderzył" w stan $j$. Istnieją trajektorie, dla których $N_j=0$, i zbiór takich trajektorii może mieć niezerowe prawdopodobieństwo.
\end{definition}

\begin{definition}[Prawdopodobieństwo pierwszego trafienia w chwili n]
Prawdopodobieństwem, że pierwsze trafienie w stanie $j$, startując ze stanu $i$, nastąpi dokładnie w chwili $n$, nazywamy $f_{ij}(n)$:
\begin{equation*} 
    f_{ij}(n) := P(T_j = n \mid X_0 = i)
\end{equation*} 
Można to równoważnie zapisać jako prawdopodobieństwo, że w chwili $n$ jesteśmy w $j$, a wcześniej nigdy tam nie byliśmy:
\begin{equation*} 
    f_{ij}(n) = P(X_n=j, X_{n-1} \neq j, \dots, X_1 \neq j \mid X_0 = i)
\end{equation*} 
\end{definition}

\begin{definition}[Prawdopodobieństwo dotarcia do stanu]
Prawdopodobieństwem \textbf{dotarcia} (lub "wejścia kiedykolwiek") do stanu $j$, startując ze stanu $i$, nazywamy $f_{ij}$:
\begin{equation*} 
    f_{ij} := P(T_j < \infty \mid X_0 = i)
\end{equation*} 
Jest to po prostu prawdopodobieństwo, że stan $j$ zostanie kiedykolwiek odwiedzony. Zdarzenie $\{T_j < \infty\}$ jest sumą rozłącznych zdarzeń $\{T_j=n\}$ dla wszystkich $n \ge 1$, zatem:
\begin{equation*} 
    f_{ij} = \sum_{n=1}^{\infty} P(T_j=n \mid X_0=i) = \sum_{n=1}^{\infty} f_{ij}(n)
\end{equation*} 
Równoważnie, dotarcie do stanu $j$ co najmniej raz jest tym samym, co posiadanie co najmniej jednego trafienia w tym stanie:
\begin{equation*} 
    f_{ij} = P(N_j \ge 1 \mid X_0 = i)
\end{equation*} 
\end{definition}

\begin{obserwacja}[Prawdopodobieństwo wielokrotnych trafień]
Dla dowolnych stanów $i, j \in S$ i dowolnego $k \in \mathbb{N}$, prawdopodobieństwo co najmniej $k$ trafień w stanie $j$, startując ze stanu $i$, dane jest wzorem:
\begin{equation*} 
    P(N_j \ge k \mid X_0 = i) = f_{ij} \cdot f_{jj}^{k-1}
\end{equation*} 

W szczególnym przypadku, gdy startujemy już ze stanu $j$ (czyli $i=j$), wzór upraszcza się do:
\begin{equation*} 
    P(N_j \ge k \mid X_0 = j) = f_{jj}^k
\end{equation*} 
\end{obserwacja}

\vspace{1em}

Ta obserwacja prowadzi nas do fundamentalnego podziału stanów łańcucha Markowa. Kluczową wielkością jest prawdopodobieństwo powrotu $f_{jj}$, czyli prawdopodobieństwo, że proces kiedykolwiek wróci do stanu $j$, startując z tego stanu.

\begin{definition}[Klasyfikacja stanów: powracające i chwilowe]
Niech $j \in S$ będzie stanem łańcucha Markowa. Stan $j$ klasyfikujemy w następujący sposób:

\begin{enumerate}[label=\alph*)]
    \item Stan $j$ nazywamy \textbf{stanem powracającym} (ang. \textit{recurrent state}), jeśli:
    \begin{equation*} 
        f_{jj} = 1
    \end{equation*}
    Oznacza to, że proces, startując ze stanu $j$, na pewno (z prawdopodobieństwem 1) kiedyś do niego powróci.

    \item Stan $j$ nazywamy \textbf{stanem chwilowym} (lub \textbf{przejściowym}, ang. \textit{transient state}), jeśli:
    \begin{equation*} 
        f_{jj} < 1
    \end{equation*}
    Oznacza to, że istnieje niezerowe prawdopodobieństwo $1-f_{jj} > 0$, że proces, startując ze stanu $j$, nigdy do niego nie powróci.
\end{enumerate}
\end{definition}

\begin{obserwacja}[Konsekwencje klasyfikacji dla liczby trafień]
Klasyfikacja stanów ma fundamentalne konsekwencje dla liczby trafień $N_j$:

\begin{enumerate}[label=\alph*)]
    \item Jeśli stan $j$ jest \textbf{powracający} ($f_{jj} = 1$), to proces, który raz wystartował ze stanu $j$, będzie do niego powracał gwarantowaną liczbę razy. Formalnie, dla dowolnego $k \ge 1$:
    \begin{equation*} 
        P(N_j \ge k \mid X_0 = j) = 1
    \end{equation*} 
    Prawdopodobieństwo co najmniej $k$ powrotów do stanu $j$ jest równe 1, niezależnie od tego, jak duże jest $k$.

    \item Jeśli stan $j$ jest \textbf{chwilowy} ($f_{jj} < 1$), to prawdopodobieństwo, że proces odwiedzi ten stan co najmniej $k$ razy, maleje do zera, gdy $k$ rośnie do nieskończoności. Co ważne, dzieje się tak niezależnie od stanu początkowego $i \in S$:
    \begin{equation*} 
        \lim_{k \to \infty} P(N_j \ge k \mid X_0 = i) = 0
    \end{equation*}
    Oznacza to, że dla stanów chwilowych liczba odwiedzin jest z prawdopodobieństwem 1 skończona.
\end{enumerate}
\end{obserwacja}

\begin{proof}
Dowód opiera się bezpośrednio na wzorze z Obserwacji 4.5: $P(N_j \ge k \mid X_0 = i) = f_{ij} f_{jj}^{k-1}$.

\begin{enumerate}[label=\alph*)]
    \item \textbf{Stan powracający ($f_{jj}=1$):}
    W tym przypadku, startując ze stanu $i=j$, wzór przyjmuje postać:
    \begin{equation*}
        P(N_j \ge k \mid X_0 = j) = f_{jj} \cdot f_{jj}^{k-1} = f_{jj}^k
    \end{equation*}
    Ponieważ $f_{jj}=1$, otrzymujemy $P(N_j \ge k \mid X_0 = j) = 1^k = 1$ dla dowolnego $k \ge 1$.

    \item \textbf{Stan chwilowy ($f_{jj}<1$):}
    Tym razem rozważamy dowolny stan początkowy $i$. Mamy:
    \begin{equation*}
        P(N_j \ge k \mid X_0 = i) = f_{ij} f_{jj}^{k-1}
    \end{equation*}
    Ponieważ $f_{jj} < 1$, to $\lim_{k \to \infty} f_{jj}^{k-1} = 0$. Prawdopodobieństwo $f_{ij}$ jest stałą z przedziału $[0, 1]$. W granicy otrzymujemy:
    \begin{equation*}
        \lim_{k \to \infty} P(N_j \ge k \mid X_0 = i) = f_{ij} \cdot \lim_{k \to \infty} f_{jj}^{k-1} = f_{ij} \cdot 0 = 0
    \end{equation*}
\end{enumerate}
Co kończy dowód.
\end{proof}

\begin{example}[Graficzna ilustracja klasyfikacji stanów]
Rozważmy łańcuch o trzech stanach $S=\{a, b, c\}$, którego graf przejść wygląda następująco:

\begin{center}
\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=3cm, state/.style={circle, draw, minimum size=0.8cm}]
    \node[state] (a) {a};
    \node[state] (b) [right=of a] {b};
    \node[state] (c) [below=of a] {c};

    % Przejścia z a
    \path (a) edge [loop above] node {1/3} (a);
    \path (a) edge [bend left]  node[above] {2/3} (b);

    % Przejścia z b
    \path (b) edge [bend left]  node[below] {1} (a);

    % Przejścia z c
    \path (c) edge [loop below] node {1/2} (c);
    \path (c) edge              node[left] {1/4} (a);
    \path (c) edge [bend right] node[right] {1/4} (b);
\end{tikzpicture}
\end{center}

W tym łańcuchu:
\begin{itemize}
    \item Stany $a$ i $b$ są \textbf{powracające}. Rozważmy podzbiór stanów $\{a, b\}$. Jeśli proces znajdzie się w tym podzbiorze, nigdy go nie opuści, ponieważ nie ma przejść z $a$ lub $b$ do $c$. Co więcej, niemożliwe jest "utknięcie" w jednym ze stanów bez powrotu do drugiego. Ze stanu $b$ proces musi wrócić do $a$. Ze stanu $a$ istnieje stała, niezerowa szansa na przejście do $b$. To gwarantuje, że proces będzie w nieskończoność przemieszczał się między nimi. Dlatego, startując z $a$ (lub $b$), mamy pewność, że proces kiedyś tam powróci ($f_{aa}=1$ i $f_{bb}=1$).
    \item Stan $c$ jest \textbf{chwilowy}. Ze stanu $c$ istnieje niezerowe prawdopodobieństwo ($1/4 + 1/4 = 1/2$) przejścia do stanu $a$ lub $b$. Jednakże, gdy proces raz przejdzie do $a$ lub $b$, nie ma już żadnej możliwości powrotu do stanu $c$. Ponieważ istnieje scenariusz, w którym proces opuszcza stan $c$ i nigdy do niego nie wraca, prawdopodobieństwo powrotu jest mniejsze od 1 ($f_{cc} < 1$).
\end{itemize}
\end{example}

\begin{lemat}[Wartość oczekiwana zmiennej o wartościach w $\mathbb{N}_0$]
Dla dowolnej zmiennej losowej $X$ przyjmującej wartości w zbiorze liczb naturalnych z zerem ($\mathbb{N}_0 = \{0, 1, 2, \dots\}$), jej wartość oczekiwana może być wyrażona jako:
\begin{equation*}
    E[X] = \sum_{k=1}^{\infty} P(X \ge k)
\end{equation*}
\end{lemat}
\begin{proof}
Dowód wynika z rozpisania sumy i zmiany kolejności sumowania (co jest dozwolone dla składników nieujemnych na mocy tw. Tonellego). Rozpisując podwójną sumę, otrzymujemy:
\begin{align*}
    \sum_{k=1}^{\infty} P(X \ge k) &= \sum_{k=1}^{\infty} \sum_{j=k}^{\infty} P(X=j) \\
    &= \begin{array}{l@{}l}
        & P(X=1) + P(X=2) + P(X=3) + \dots \\
        + & \phantom{P(X=1) +} P(X=2) + P(X=3) + \dots \\
        + & \phantom{P(X=1) + P(X=2) +} P(X=3) + \dots \\
        + & \phantom{P(X=1) + P(X=2) + P(X=3) +} \dots
    \end{array} \\
    &= \sum_{k=1}^{\infty} k \cdot P(X=k) = \sum_{k=0}^{\infty} k \cdot P(X=k) = E[X]
\end{align*}
Grupując wyrazy pionowo (kolumnami), widzimy, że $P(X=1)$ występuje raz, $P(X=2)$ dwa razy, itd., co prowadzi do wzoru na wartość oczekiwaną.
\end{proof}

\begin{twierdzenie}[Charakteryzacja stanów powracających i chwilowych]
Dla dowolnego stanu $j \in S$ w jednorodnym łańcuchu Markowa, następujące charakteryzacje są równoważne:

\begin{enumerate}[label=\alph*)]
    \item \textbf{Dla stanów powracających:}
    \begin{enumerate}[label=(\roman*)]
        \item Stan $j$ jest powracający (tzn. $f_{jj}=1$).
        \item Proces, startując z $j$, powróci do $j$ nieskończenie wiele razy z prawdopodobieństwem 1.
        \begin{equation*}
            P(N_j = \infty \mid X_0 = j) = 1
        \end{equation*}
        \item Oczekiwana liczba powrotów do stanu $j$ (startując z $j$), równa sumie prawdopodobieństw powrotu w $n$ krokach, jest nieskończona.
        \begin{equation*}
            E[N_j \mid X_0=j] = \sum_{n=1}^{\infty} p_n(j, j) = \infty
        \end{equation*}
    \end{enumerate}

    \item \textbf{Dla stanów chwilowych:}
    \begin{enumerate}[label=(\roman*)]
        \item Stan $j$ jest chwilowy (tzn. $f_{jj}<1$).
        \item Proces, startując z $j$, powróci do $j$ skończoną liczbę razy z prawdopodobieństwem 1.
        \begin{equation*}
            P(N_j < \infty \mid X_0 = j) = 1
        \end{equation*}
        \item Oczekiwana liczba powrotów do stanu $j$ (startując z $j$), równa sumie prawdopodobieństw powrotu w $n$ krokach, jest skończona.
        \begin{equation*}
            E[N_j \mid X_0=j] = \sum_{n=1}^{\infty} p_n(j, j) < \infty
        \end{equation*}
    \end{enumerate}
\end{enumerate}
\end{twierdzenie}

\begin{proof}
Dowód podzielimy na dwie części, odpowiadające dwóm równoważnościom dla każdego typu stanu.

\textbf{Równoważność 1: (i) $\Leftrightarrow$ (ii)} (Liczba powrotów)

Ta część dowodzi, że stan jest powracający wtedy i tylko wtedy, gdy liczba powrotów do niego jest nieskończona z prawdopodobieństwem 1.

\underline{Dowód dla $j$ powracającego (a) i chwilowego (b):}
Zdarzenie $\{N_j = \infty\}$ (nieskończona liczba powrotów) jest równe przecięciu zdarzeń $A_k = \{N_j \ge k\}$ (co najmniej $k$ powrotów) dla $k=1, 2, \dots$. Ponieważ $A_1 \supset A_2 \supset \dots$ jest \textbf{ciągiem zstępującym}, z \textbf{ciągłości miary prawdopodobieństwa} mamy:
\begin{equation*}
    P(N_j = \infty \mid X_0 = j) = P\left(\bigcap_{k=1}^{\infty} A_k \mid X_0=j\right) = \lim_{k \to \infty} P(A_k \mid X_0=j) = \lim_{k \to \infty} P(N_j \ge k \mid X_0 = j)
\end{equation*}
Korzystając z wzoru $P(N_j \ge k \mid X_0 = j) = f_{jj}^k$, otrzymujemy kluczową zależność:
\begin{equation*}
    P(N_j = \infty \mid X_0 = j) = \lim_{k \to \infty} f_{jj}^k
\end{equation*}
Teraz dowód staje się trywialny:
\begin{itemize}
    \item Równoważność dla stanu powracającego: $f_{jj}=1 \Leftrightarrow \lim_{k \to \infty} f_{jj}^k = 1 \Leftrightarrow P(N_j = \infty \mid X_0 = j) = 1$.
    \item Równoważność dla stanu chwilowego: $f_{jj}<1 \Leftrightarrow \lim_{k \to \infty} f_{jj}^k = 0 \Leftrightarrow P(N_j = \infty \mid X_0 = j) = 0$.
\end{itemize}

\vspace{1em}
\textbf{Równoważność 2: (i) $\Leftrightarrow$ (iii)} (Kryterium sumy)

Ta część dowodzi, że stan jest powracający wtedy i tylko wtedy, gdy suma $\sum p_n(j,j)$ jest nieskończona. Kluczowe jest wyprowadzenie tożsamości dla wartości oczekiwanej liczby powrotów $E[N_j \mid X_0=j]$ na dwa sposoby.

\textbf{Sposób 1: Użycie funkcji wskaźnikowych.}
Całkowitą liczbę trafień $N_j$ definiuje się jako sumę funkcji indykatorowych dla każdego kroku czasowego:
\begin{equation*}
    N_j = \sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=j\}}
\end{equation*}
gdzie $\mathbf{1}_{\{X_n=j\}}$ to zmienna losowa, która przyjmuje wartość 1, jeśli proces jest w stanie $j$ w chwili $n$, i 0 w przeciwnym przypadku.

Korzystając z \textbf{liniowości wartości oczekiwanej}, która pozwala zamienić wartość oczekiwaną sumy na sumę wartości oczekiwanych (nawet dla nieskończonej liczby nieujemnych zmiennych losowych), otrzymujemy:
\begin{equation*}
    E[N_j \mid X_0=j] = E\left[\sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=j\}} \mid X_0=j\right] = \sum_{n=1}^{\infty} E[\mathbf{1}_{\{X_n=j\}} \mid X_0=j]
\end{equation*}
Wartość oczekiwana funkcji indykatorowej jest równa prawdopodobieństwu zdarzenia, które ona wskazuje. Zatem:
\begin{equation*}
    E[\mathbf{1}_{\{X_n=j\}} \mid X_0=j] = P(X_n=j \mid X_0=j) = p_n(j,j)
\end{equation*}
Podstawiając to z powrotem, otrzymujemy pierwszą postać wartości oczekiwanej:
\begin{equation*}
    E[N_j \mid X_0=j] = \sum_{n=1}^{\infty} p_n(j,j)
\end{equation*}

\textbf{Sposób 2: Użycie lematu o wartości oczekiwanej.}
Zgodnie z Lematem 4.9, wartość oczekiwaną zmiennej losowej o wartościach w $\mathbb{N}_0$ można wyrazić jako sumę prawdopodobieństw postaci $P(X \ge k)$ dla $k \ge 1$:
\begin{equation*}
    E[N_j \mid X_0=j] = \sum_{k=1}^{\infty} P(N_j \ge k \mid X_0=j)
\end{equation*}

\textbf{Połączenie tożsamości}
Łącząc oba wzory na $E[N_j \mid X_0=j]$ i podstawiając znaną nam zależność $P(N_j \ge k \mid X_0 = j) = f_{jj}^k$ (z Obserwacji 4.5, dla $i=j$), otrzymujemy kluczową równość:
\begin{equation*}
    \sum_{n=1}^{\infty} p_n(j,j) = \sum_{k=1}^{\infty} f_{jj}^k
\end{equation*}
Prawa strona to szereg geometryczny. Zbieżność obu szeregów jest zatem identyczna i zależy od $f_{jj}$:
\begin{itemize}
    \item $f_{jj}=1$ (stan powracający) $\Leftrightarrow$ szereg jest rozbieżny, tj. $\sum_{n=1}^{\infty} p_n(j,j) = \infty$.
    \item $f_{jj}<1$ (stan chwilowy) $\Leftrightarrow$ szereg jest zbieżny, tj. $\sum_{n=1}^{\infty} p_n(j,j) < \infty$.
\end{itemize}
To dowodzi równoważności (i) $\Leftrightarrow$ (iii). Przy okazji udowodniliśmy też równoważność (ii) $\Leftrightarrow$ (iii), ponieważ (i) jest równoważne obu warunkom.
\end{proof}

\begin{wniosek}[Wzór na prawdopodobieństwo powrotu]
Z dowodu dla stanów chwilowych (Równoważność 2) otrzymaliśmy jawny wzór na sumę:
\begin{equation*}
    \sum_{n=1}^{\infty} p_n(j, j) = \frac{f_{jj}}{1 - f_{jj}}
\end{equation*}
Przekształcając go, możemy wyrazić prawdopodobieństwo powrotu $f_{jj}$ za pomocą sumy prawdopodobieństw przejścia:
\begin{equation*}
    f_{jj} = \frac{\sum_{n=1}^{\infty} p_n(j, j)}{1 + \sum_{n=1}^{\infty} p_n(j, j)}
\end{equation*}
Wzór ten potwierdza, że $f_{jj}=1$ wtedy i tylko wtedy, gdy suma $\sum p_n(j,j)$ jest nieskończona.
\end{wniosek}

\section{Osiągalność, komunikacja i klasy stanów}

Aby móc w pełni scharakteryzować i sklasyfikować stany łańcucha Markowa, musimy wprowadzić pojęcie osiągalności i komunikacji między nimi.

\begin{definition}[Osiągalność]
Niech $i, j \in S$. Mówimy, że stan $j$ jest \textbf{osiągalny} ze stanu $i$, co oznaczamy jako $i \to j$, jeśli istnieje $n \in \mathbb{N}_0$ takie, że $p_n(i, j) > 0$.
\begin{equation*}
    i \to j \iff \exists n \in \mathbb{N}_0 : p_n(i, j) > 0
\end{equation*}
Oznacza to, że istnieje niezerowe prawdopodobieństwo dotarcia ze stanu $i$ do stanu $j$ w pewnej (skończonej) liczbie kroków.

\vspace{1em}
\textbf{Uwaga:} Relacja osiągalności nie jest symetryczna. Jeśli $j$ jest osiągalny z $i$, nie oznacza to, że $i$ musi być osiągalny z $j$.
\end{definition}

\begin{definition}[Komunikacja]
Mówimy, że stany $i$ i $j$ \textbf{komunikują się ze sobą}, co oznaczamy jako $i \leftrightarrow j$, jeśli stan $j$ jest osiągalny z $i$ oraz stan $i$ jest osiągalny z $j$.
\begin{equation*}
    i \leftrightarrow j \iff (i \to j) \land (j \to i)
\end{equation*}
Intuicyjnie oznacza to, że będąc w stanie $i$, możemy dotrzeć do stanu $j$, a będąc w stanie $j$, możemy wrócić do stanu $i$. Niekoniecznie w tej samej liczbie kroków.
\end{definition}

\begin{twierdzenie}
Relacja komunikacji ($\leftrightarrow$) jest relacją równoważności na zbiorze stanów $S$.
\end{twierdzenie}

\begin{proof}
Musimy udowodnić trzy własności: zwrotność, symetrię i przechodniość.

\begin{enumerate}[label=\alph*)]
    \item \textbf{Zwrotność ($i \leftrightarrow i$):}
    Zgodnie z konwencją, macierz przejścia w 0 krokach $P^0$ jest macierzą identycznościową, co oznacza, że $p_0(i,i) = 1 > 0$. Zatem $i \to i$, co implikuje $i \leftrightarrow i$.

    \item \textbf{Symetria ($i \leftrightarrow j \implies j \leftrightarrow i$):}
    Ta własność wynika wprost z definicji. Jeśli $i \leftrightarrow j$, to z definicji $(i \to j) \land (j \to i)$. To jest to samo co $(j \to i) \land (i \to j)$, co z kolei oznacza, że $j \leftrightarrow i$.

    \item \textbf{Przechodniość ($i \leftrightarrow j \land j \leftrightarrow k \implies i \leftrightarrow k$):}
    Załóżmy, że $i \leftrightarrow j$ oraz $j \leftrightarrow k$. Musimy pokazać, że $i \leftrightarrow k$.
    
    Z założenia $i \to j$, więc istnieje $n \in \mathbb{N}_0$ takie, że $p_n(i, j) > 0$.
    Z założenia $j \to k$, więc istnieje $m \in \mathbb{N}_0$ takie, że $p_m(j, k) > 0$.

    Z równań Chapmana-Kołmogorowa:
    \begin{equation*}
        p_{n+m}(i, k) = \sum_{l \in S} p_n(i, l) p_m(l, k) \ge p_n(i,j) p_m(j,k) > 0
    \end{equation*}
    co dowodzi, że $i \to k$.

    Analogicznie dowodzimy, że $k \to i$. Ponieważ pokazaliśmy, że $i \to k$ i $k \to i$, to z definicji $i \leftrightarrow k$.
\end{enumerate}
Co kończy dowód.
\end{proof}

\begin{definition}[Klasy komunikujące się]
Ponieważ relacja $\leftrightarrow$ jest relacją równoważności, dzieli ona zbiór stanów $S$ na rozłączne podzbiory, zwane \textbf{klasami równoważności} lub \textbf{klasami komunikującymi się}. Dwa stany należą do tej samej klasy, jeśli komunikują się ze sobą.
\end{definition}

\section{Łańcuchy nieprzywiedlne}

\begin{definition}[Łańcuch nieprzywiedlny]
Jednorodny łańcuch Markowa nazywamy \textbf{nieprzywiedlnym} (lub \textbf{nieredukowalnym}), jeśli tworzy on tylko jedną klasę komunikującą się. Oznacza to, że wszystkie stany komunikują się ze sobą.
\begin{equation*}
    \forall i, j \in S \quad i \leftrightarrow j
\end{equation*}
Jeśli łańcuch nie jest nieprzywiedlny (tzn. ma więcej niż jedną klasę komunikującą się), nazywamy go \textbf{przywiedlnym} (lub \textbf{redukowalnym}).
\end{definition}

\begin{example}[Łańcuch nieprzywiedlny – cykl]
Rozważmy łańcuch o trzech stanach $S=\{1, 2, 3\}$, w którym proces cyklicznie przechodzi między stanami: $1 \to 2$, $2 \to 3$ i $3 \to 1$.
Macierz przejścia ma postać:
\begin{equation*}
    P = 
    \begin{bmatrix}
        0 & 1 & 0 \\
        0 & 0 & 1 \\
        1 & 0 & 0
    \end{bmatrix}
\end{equation*}
Graf stanów wygląda następująco:
\begin{center}
\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=2.5cm, state/.style={circle, draw, minimum size=0.8cm}]
    \node[state] (1) at (90:1.5cm) {1};
    \node[state] (3) at (210:1.5cm) {3};
    \node[state] (2) at (330:1.5cm) {2};

    \path (1) edge [bend left=20] node[above right] {1} (2);
    \path (2) edge [bend left=20] node[below] {1} (3);
    \path (3) edge [bend left=20] node[above left] {1} (1);
\end{tikzpicture}
\end{center}
W tym łańcuchu każdy stan jest osiągalny z każdego innego. Na przykład, ze stanu 1 możemy dotrzeć do 3 w dwóch krokach ($1 \to 2 \to 3$). Ze stanu 3 do 2 w dwóch krokach ($3 \to 1 \to 2$). Ponieważ wszystkie stany komunikują się ze sobą (tworzą jedną klasę), łańcuch jest \textbf{nieprzywiedlny}.
\end{example}

\begin{example}[Łańcuch przywiedlny]
Rozważmy łańcuch o czterech stanach $S=\{1, 2, 3, 4\}$, w którym dozwolone są tylko przejścia $1 \leftrightarrow 2$ oraz $3 \leftrightarrow 4$.
Macierz przejścia może wyglądać tak:
\begin{equation*}
    P = 
    \begin{bmatrix}
        0 & 1 & 0 & 0 \\
        1 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 \\
        0 & 0 & 1 & 0
    \end{bmatrix}
\end{equation*}
Graf stanów składa się z dwóch niepołączonych ze sobą komponentów:
\begin{center}
\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=3cm, state/.style={circle, draw, minimum size=0.8cm}]
    \node[state] (1) {1};
    \node[state] (2) [right=of 1] {2};
    
    \node[state] (3) [right=of 2, node distance=4cm] {3};
    \node[state] (4) [right=of 3] {4};

    \path (1) edge [bend left]  node {1} (2);
    \path (2) edge [bend left]  node {1} (1);
    
    \path (3) edge [bend left]  node {1} (4);
    \path (4) edge [bend left]  node {1} (3);
\end{tikzpicture}
\end{center}
W tym przypadku zbiór stanów $S$ dzieli się na dwie klasy komunikujące się: $C_1 = \{1, 2\}$ oraz $C_2 = \{3, 4\}$. Nie jest możliwe przejście ze stanu z klasy $C_1$ do stanu z klasy $C_2$ (np. $1 \not\to 3$). Ponieważ istnieje więcej niż jedna klasa, łańcuch jest \textbf{przywiedlny}.
\end{example}

\begin{lemat}
Niech $i, j \in S$ będą stanami łańcucha Markowa. Jeżeli stan $i$ jest powracający ($f_{ii}=1$) oraz stan $j$ jest osiągalny ze stanu $i$ ($i \to j$), to stan $j$ również jest powracający ($f_{jj}=1$).

Innymi słowy, z stanu powracającego nie da się przejść do stanu chwilowego.
\end{lemat}
\begin{proof}
    Dowód składa się z dwóch części. Najpierw pokażemy, że jeśli stan $i$ jest powracający i $i \to j$, to musi zachodzić również $j \to i$. Następnie, korzystając z tego faktu, udowodnimy, że stan $j$ jest powracający.

    \textbf{Krok 1: Dowód, że $j \to i$}
    
    Dowód nie wprost. Załóżmy, że $j \not\to i$. Oznacza to, że po osiągnięciu stanu $j$ powrót do $i$ jest niemożliwy, czyli $P(T_i = \infty \mid X_0=j) = 1$.
    
    Z założenia $i \to j$ wiemy, że istnieje przynajmniej jedna ścieżka z $i$ do $j$ o dodatnim prawdopodobieństwie. Rozważmy najkrótszą z takich ścieżek. Nie może ona zawierać $i$ jako stanu pośredniego (gdyby tak było, istniałaby jeszcze krótsza ścieżka do $j$). Zatem istnieje dodatnie prawdopodobieństwo dotarcia do $j$ bez wcześniejszego powrotu do $i$. Oznaczmy to zdarzenie $A = \{T_j < T_i\}$. Mamy $P(A \mid X_0=i) > 0$.
    
    Prawdopodobieństwo, że proces nigdy nie powróci do $i$ (startując z $i$), możemy oszacować następująco:
    \[
    P(T_i=\infty \mid X_0=i) \;\ge\; P(A \cap \{ \text{po trafieniu do j nigdy nie wracamy do i} \} \mid X_0=i)
    \]
    Używając silnej własności Markowa, można to formalnie zapisać jako $P(T_i=\infty \mid X_0=i) \ge P(A \mid X_0=i) \cdot P(T_i=\infty \mid X_{T_j}=j)$. Ponieważ $P(A \mid X_0=i) > 0$ oraz z założenia $P(T_i=\infty \mid X_0=j)=1$, otrzymujemy $P(T_i=\infty \mid X_0=i) > 0$. To oznacza, że $f_{ii} < 1$, co jest sprzeczne z założeniem, że $i$ jest stanem powracającym.
    
    Wniosek: założenie $j \not\to i$ musi być fałszywe, zatem $j \to i$.
    
    \textbf{Krok 2: Dowód, że $j$ jest powracający}

    Wykazaliśmy, że skoro $i$ jest powracający i $i \to j$, to musi zachodzić $j \to i$. Istnieją zatem liczby $k, m \ge 1$ takie, że $p_k(i,j) > 0$ i $p_m(j,i) > 0$.
    
    Rozważmy prawdopodobieństwo powrotu do stanu $j$ w $m+n+k$ krokach. Możemy je oszacować od dołu, biorąc pod uwagę tylko ścieżki prowadzące z $j$ do $i$ w $m$ krokach, następnie z $i$ do $i$ w $n$ krokach, i z powrotem z $i$ do $j$ w $k$ krokach.
    \[
    p_{m+n+k}(j,j) \ge p_m(j,i) p_n(i,i) p_k(i,j)
    \]
    Sumując obie strony po $n \ge 1$:
    \[
    \sum_{n=1}^{\infty} p_{m+n+k}(j,j) \ge p_m(j,i) p_k(i,j) \sum_{n=1}^{\infty} p_n(i,i)
    \]
    Ponieważ stan $i$ jest powracający, suma $\sum_{n=1}^{\infty} p_n(i,i)$ jest nieskończona. Iloczyn $p_m(j,i) p_k(i,j)$ jest stałą dodatnią, więc prawa strona nierówności jest nieskończona.
    \[
    \sum_{n=1}^{\infty} p_{m+n+k}(j,j) = \infty
    \]
    Suma po lewej stronie jest ogonem szeregu $\sum_{l=1}^{\infty} p_l(j,j)$. Skoro ogon szeregu o wyrazach nieujemnych jest nieskończony, to cały szereg również musi być nieskończony.
    \[
    \sum_{l=1}^{\infty} p_l(j,j) = \infty
    \]
    To na mocy Twierdzenia 4.10 dowodzi, że stan $j$ jest powracający.
    \end{proof}

\subsection*{Wnioski Końcowe: Klasyfikacja Stanów}

Powyższe rozważania prowadzą do fundamentalnych wniosków na temat struktury łańcuchów Markowa.

\begin{wniosek}
\textbf{Bycie stanem powracającym lub chwilowym to własność klasy.} Jeżeli dwa stany $i$ i $j$ komunikują się ze sobą ($i \leftrightarrow j$), to są one tego samego typu: albo oba są powracające, albo oba są chwilowe. Dlatego możemy mówić o \textbf{klasach powracających} i \textbf{klasach chwilowych}.
\end{wniosek}

\begin{wniosek}
\textbf{Łańcuchy nieprzywiedlne są jednorodne.} Jeżeli łańcuch Markowa jest nieprzywiedlny (wszystkie stany tworzą jedną klasę), to musi być w całości jednego typu:
\begin{itemize}
    \item albo wszystkie jego stany są powracające (\textbf{łańcuch powracający}),
    \item albo wszystkie jego stany są chwilowe (\textbf{łańcuch chwilowy}).
\end{itemize}
\end{wniosek}

\begin{wniosek}[Rola skończonej przestrzeni stanów]
Rozmiar przestrzeni stanów ma kluczowe znaczenie:
\begin{enumerate}
    \item W łańcuchu o \textbf{skończonej} liczbie stanów nie wszystkie stany mogą być chwilowe -- musi istnieć przynajmniej jedna klasa powracająca.
    \item W konsekwencji, każdy \textbf{nieprzywiedlny łańcuch o skończonej liczbie stanów jest zawsze powracający}.
    \item Łańcuch nieprzywiedlny może być chwilowy tylko wtedy, gdy ma \textbf{nieskończoną} przestrzeń stanów (np. błądzenie losowe w 3D).
\end{enumerate}
\end{wniosek}

\section{Zachowanie graniczne jednorodnych łańcuchów Markowa}

W poprzednich rozdziałach sklasyfikowaliśmy stany i klasy komunikujące się. Teraz zbadamy, jak jednorodne łańcuchy Markowa (JŁM) zachowują się w długim horyzoncie czasowym, czyli gdy liczba kroków $n$ dąży do nieskończoności. Interesuje nas, czy po wielu krokach proces "stabilizuje się" w pewien określony sposób.

Będziemy rozważać JŁM $(X_n)_{n \in \mathbb{N}_0}$ na skończonej przestrzeni stanów $S = \{1, 2, \dots, N\}$. Wiemy, że rozkład brzegowy procesu w kroku $n$ dany jest wzorem:
$$ [ P(X_n=j) ]_{j \in S} = \alpha P^n $$
gdzie $\alpha$ jest początkowym rozkładem prawdopodobieństwa. Kluczowe pytanie brzmi: \textbf{kiedy i do czego zbiega wektor rozkładu $\alpha P^n$, gdy $n \to \infty$?}

\subsection{Rozkład stacjonarny}

Szczególną rolę w analizie zachowania granicznego odgrywają rozkłady, które są niezmiennicze względem dynamiki łańcucha.

\begin{definition}[Rozkład stacjonarny]
Rozkład prawdopodobieństwa $\pi$ na przestrzeni stanów $S$ (reprezentowany jako wektor-wiersz) nazywamy \textbf{rozkładem stacjonarnym} łańcucha Markowa o macierzy przejścia $P$, jeżeli spełnia on równanie:
$$ \pi P = \pi $$
\end{definition}

Innymi słowy, rozkład stacjonarny to taki rozkład, że jeśli zostanie wybrany jako rozkład początkowy ($X_0 \sim \pi$), to rozkład procesu w każdym kolejnym kroku czasu pozostanie taki sam.

\begin{obserwacja}
Jeśli $\pi$ jest rozkładem stacjonarnym, to dla dowolnego $n \in \mathbb{N}$ zachodzi:
$$ \pi P^n = \pi $$
\begin{proof}
Dowód jest natychmiastowy przez indukcję. Baza ($n=1$) wynika z definicji. Krok indukcyjny: załóżmy, że $\pi P^k = \pi$ dla pewnego $k \ge 1$. Wówczas
$$ \pi P^{k+1} = (\pi P^k) P = \pi P = \pi $$
co kończy dowód.
\end{proof}
\end{obserwacja}

Zauważmy, że równanie $\pi P = \pi$ można przepisać jako $\pi(P - I) = \mathbf{0}$, gdzie $I$ jest macierzą jednostkową. Z perspektywy algebry liniowej oznacza to, że rozkład stacjonarny $\pi$ jest \textbf{lewostronnym wektorem własnym} macierzy $P$ odpowiadającym \textbf{wartości własnej $\lambda=1$}.

\begin{lemat}
Dla dowolnej macierzy stochastycznej $P$, liczba $\lambda=1$ jest jej wartością własną.
\begin{proof}
Prawostronnym wektorem własnym dla $\lambda=1$ jest wektor $\mathbf{1} = [1, 1, \dots, 1]^T$. Ponieważ wiersze macierzy stochastycznej sumują się do 1, mamy:
$$ (P \mathbf{1})_i = \sum_{j=1}^N P_{ij} \cdot 1 = 1 = (\mathbf{1})_i $$
Zatem $P\mathbf{1} = \mathbf{1}$, co dowodzi, że $1$ jest wartością własną. Skoro istnieje prawostronny wektor własny, to musi również istnieć odpowiadający mu lewostronny wektor własny.
\end{proof}
\end{lemat}

\begin{example}
Czy dla łańcucha o macierzy przejścia $P = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$ istnieje rozkład stacjonarny?
\begin{center}
\begin{tikzpicture}[->, >=Stealth, shorten >=1pt, auto, node distance=2.5cm, semithick]
    \node[state] (1) {$1$};
    \node[state] (2) [right of=1] {$2$};

    \path (1) edge [loop above] node {$0$} (1)
              edge [bend left]  node {$1$} (2);
    \path (2) edge [loop above] node {$0$} (2)
              edge [bend left]  node {$1$} (1);
\end{tikzpicture}
\end{center}
Szukamy wektora $\pi = [\pi_1, \pi_2]$ takiego, że $\pi_1 + \pi_2 = 1$, $\pi_1, \pi_2 \ge 0$ oraz $\pi P = \pi$.
$$ [\pi_1, \pi_2] \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} = [\pi_1, \pi_2] $$
Otrzymujemy układ równań:
$$ \begin{cases} \pi_2 = \pi_1 \\ \pi_1 = \pi_2 \end{cases} $$
Wraz z warunkiem normalizacyjnym $\pi_1 + \pi_2 = 1$ daje to jednoznaczne rozwiązanie: $\pi_1 = \pi_2 = 1/2$. Zatem jedynym rozkładem stacjonarnym jest $\pi = [1/2, 1/2]$.
\end{example}

\subsection{Rozkład graniczny i zbieżność}

Idealna sytuacja, do której będziemy dążyć, to taka, w której granica $\lim_{n \to \infty} P(X_n = j)$ istnieje i \textbf{nie zależy od stanu początkowego}.

\begin{definition}[Łańcuch ergodyczny]
Mówimy, że JŁM jest \textbf{ergodyczny}, jeśli istnieje wektor-wiersz $v$ (będący rozkładem prawdopodobieństwa) taki, że:
\begin{enumerate}
    \item Granica potęg macierzy przejścia istnieje: $\lim_{n \to \infty} P^n = P^\infty$.
    \item Wszystkie wiersze macierzy granicznej $P^\infty$ są identyczne i równe $v$:
    $$ P^\infty = \begin{bmatrix}
        \text{--- } v \text{ ---} \\ \text{--- } v \text{ ---} \\ \vdots \\ \text{--- } v \text{ ---} \end{bmatrix} $$
\end{enumerate}
Wektor $v$ nazywamy \textbf{rozkładem granicznym} łańcucha.
\end{definition}

\begin{twierdzenie}[Konsekwencje ergodyczności]
Jeśli łańcuch Markowa jest ergodyczny z rozkładem granicznym $v$, to:
\begin{enumerate}
    \item \textbf{Następuje stabilizacja rozkładów warunkowych:} Prawdopodobieństwo znalezienia się w stanie $j$ po $n$ krokach, startując ze stanu $i$, zbiega do $v_j$ niezależnie od $i$:
    $$ \lim_{n \to \infty} P(X_n=j | X_0=i) = \lim_{n \to \infty} (P^n)_{ij} = (P^{\infty})_{ij} = v_j \quad \forall i,j \in S $$

    \item \textbf{Następuje stabilizacja rozkładów bezwarunkowych:} Prawdopodobieństwo znalezienia się w stanie $j$ po $n$ krokach zbiega do $v_j$ niezależnie od początkowego rozkładu $\alpha$:
    $$ \lim_{n \to \infty} P(X_n=j) = \lim_{n \to \infty} (\alpha P^n)_j = (\alpha P^{\infty})_j = \sum_{i=1}^N \alpha_i (P^{\infty})_{ij} = \sum_{i=1}^N \alpha_i v_j = v_j \sum_{i=1}^N \alpha_i = v_j $$
    Ta własność nazywana jest \textbf{zapominaniem rozkładu początkowego}.
\end{enumerate}
\end{twierdzenie}

\begin{obserwacja}
Porównajmy pojęcia rozkładu stacjonarnego i granicznego:
\begin{itemize}
    \item \textbf{Rozkład stacjonarny} dla JŁM na skończonej przestrzeni stanów \textbf{zawsze istnieje}, ale może nie być unikalny. Jest to pojęcie czysto algebraiczne.
    \item \textbf{Rozkład graniczny} \textbf{nie zawsze istnieje}. Jeśli jednak istnieje, to jest \textbf{unikalny}.
\end{itemize}
\end{obserwacja}

\begin{twierdzenie}[Ergodyczność a rozkład stacjonarny]
Jeśli JŁM jest ergodyczny z rozkładem granicznym $v$, to $v$ jest jedynym rozkładem stacjonarnym tego łańcucha.
\end{twierdzenie}

\begin{twierdzenie}[Twierdzenie ergodyczne dla JŁM]
Dla łańcucha ergodycznego z rozkładem granicznym $v$, wektor $v$ ma interpretację jako średnia proporcja czasu spędzonego przez łańcuch w każdym ze stanów w długim okresie:
$$ v_j = \lim_{n \to \infty} E\left[\frac{1}{n} \sum_{k=0}^{n-1} \mathbf{1}_{\{X_k=j\}} \middle| X_0=i\right] \quad \text{dla dowolnego } i \in S $$
\begin{proof}[Szkic dowodu]
Korzystając z liniowości wartości oczekiwanej, mamy:
$$ E\left[\frac{1}{n} \sum_{k=0}^{n-1} \mathbf{1}_{\{X_k=j\}} \middle| X_0=i\right] = \frac{1}{n} \sum_{k=0}^{n-1} E\left[\mathbf{1}_{\{X_k=j\}} \middle| X_0=i\right] = \frac{1}{n} \sum_{k=0}^{n-1} P(X_k=j | X_0=i) = \frac{1}{n} \sum_{k=0}^{n-1} (P^k)_{ij} $$
Z założenia ergodyczności wiemy, że ciąg $(P^k)_{ij}$ zbiega do $v_j$ gdy $k \to \infty$. Z lematu Cesàro, jeśli ciąg $a_k$ zbiega do granicy $g$, to ciąg jego średnich arytmetycznych $\frac{1}{n}\sum_{k=0}^{n-1} a_k$ również zbiega do $g$. Stosując ten fakt do ciągu $(P^k)_{ij}$, otrzymujemy:
$$ \lim_{n \to \infty} \frac{1}{n} \sum_{k=0}^{n-1} (P^k)_{ij} = \lim_{k \to \infty} (P^k)_{ij} = v_j $$
\end{proof}
\end{twierdzenie}

\subsection{Struktura klasowa a zbieżność}

Warunek ergodyczności (identyczne wiersze w $P^\infty$) nie zawsze jest spełniony. Dzieje się tak w szczególności, gdy łańcuch posiada więcej niż jedną klasę powracającą.

Podzielmy zbiór stanów $S$ na rozłączne podzbiory:
\begin{itemize}
    \item \textbf{Klasy powracające (recurrent)} $R_1, R_2, \dots, R_r$. Ze stanu w klasie powracającej można przejść tylko do stanów w tej samej klasie.
    \item \textbf{Zbiór stanów chwilowych (transient)} $A$. Ze stanu chwilowego można ostatecznie przejść do którejś z klas powracających, ale po opuszczeniu zbioru $A$ nie ma już do niego powrotu.
\end{itemize}
Możemy tak przenumerować stany, aby macierz przejścia $P$ przybrała postać blokową:
$$ P = \left( \begin{array}{cccc|c}
    P_1 & & & & \\
    & P_2 & & & \mathbf{0} \\
    & & \ddots & & \\
    & & & P_r & \\
    \hline
    \multicolumn{4}{c|}{C} & Q
\end{array} \right) $$
gdzie:
\begin{itemize}
    \item $P_i$ jest macierzą stochastyczną opisującą dynamikę wewnątrz $i$-tej klasy powracającej.
    \item $Q$ opisuje przejścia między stanami chwilowymi. Sumy jej wierszy mogą być mniejsze od 1 (jest to macierz substochastyczna), co oznacza możliwość "ucieczki" ze zbioru $A$.
    \item $C$ opisuje przejścia ze stanów chwilowych do klas powracających.
    \item Blok $\mathbf{0}$ w prawym górnym rogu oznacza, że ze stanu powracającego nie da się przejść do stanu chwilowego. Zera poza diagonalą blokową $P_1, \dots, P_r$ oznaczają brak przejść między klasami powracającymi.
\end{itemize}

\begin{twierdzenie}[Granica dla macierzy z klasami]
Potęgi macierzy $P$ o powyższej strukturze blokowej mają postać:
$$ P^n = \left( \begin{array}{c|c}
    \mathbf{P_R}^n & \mathbf{0} \\
    \hline
    C_n & Q^n
\end{array} \right) \quad \text{gdzie } \mathbf{P_R}^n = \begin{pmatrix} P_1^n & & \\ & \ddots & \\ & & P_r^n \end{pmatrix} $$
Dla stanów chwilowych $j \in A$ zachodzi $\lim_{n \to \infty} P(X_n=j | X_0=i) = 0$ dla dowolnego $i \in S$. Oznacza to, że $\lim_{n \to \infty} Q^n = \mathbf{0}$ (macierz zerowa). Wówczas granica $P^\infty$ (jeśli istnieje) ma postać:
$$ P^\infty = \left( \begin{array}{c|c}
    \mathbf{P_R}^\infty & \mathbf{0} \\
    \hline
    C_\infty & \mathbf{0}
\end{array} \right) $$
\end{twierdzenie}
Jeżeli mamy więcej niż jedną klasę powracającą ($r > 1$), to wiersze $P^\infty$ odpowiadające stanom z różnych klas będą różne. Oznacza to, że zachowanie graniczne zależy od tego, w której klasie startujemy, a łańcuch nie jest ergodyczny.

\subsection{Warunki algebraiczne zbieżności macierzy}

Kiedy ogólnie istnieje granica $\lim_{n \to \infty} A^n$ dla macierzy $A \in \mathbb{R}^{N \times N}$? Odpowiedź leży w jej postaci Jordana. Każdą macierz $A$ można przedstawić jako $A = QJQ^{-1}$, gdzie $J$ jest macierzą blokowo-diagonalną złożoną z klatek Jordana. Wówczas $A^n = QJ^nQ^{-1}$, więc granica $\lim_{n \to \infty} A^n$ istnieje wtedy i tylko wtedy, gdy istnieje granica $\lim_{n \to \infty} J^n$.

\begin{twierdzenie}[Warunek zbieżności $A^n$]
Granica $\lim_{n \to \infty} A^n$ istnieje wtedy i tylko wtedy, gdy dla każdej wartości własnej $\lambda$ macierzy $A$ zachodzi jeden z dwóch warunków:
\begin{enumerate}
    \item $|\lambda| < 1$,
    \item $\lambda = 1$, a wszystkie klatki Jordana odpowiadające tej wartości własnej są wymiaru $1 \times 1$.
\end{enumerate}
\end{twierdzenie}

Warunek, by wszystkie klatki Jordana dla $\lambda=1$ były wymiaru $1 \times 1$, jest równoważny temu, by \textbf{krotność algebraiczna} wartości własnej $\lambda=1$ była równa jej \textbf{krotności geometrycznej}.

\begin{definition}
Dla wartości własnej $\lambda$:
\begin{itemize}
    \item \textbf{Krotność algebraiczna} $\text{alg. mult.}(\lambda)$ to krotność $\lambda$ jako pierwiastka wielomianu charakterystycznego $\det(A-\lambda I)$.
    \item \textbf{Krotność geometryczna} $\text{geom. mult.}(\lambda)$ to wymiar przestrzeni własnej $\text{dim} \, \ker(A-\lambda I)$.
\end{itemize}
Zawsze zachodzi nierówność $1 \le \text{geom. mult.}(\lambda) \le \text{alg. mult.}(\lambda)$. Równość zachodzi wtedy i tylko wtedy, gdy wszystkie klatki Jordana dla $\lambda$ są wymiaru $1 \times 1$.
\end{definition}

\begin{twierdzenie}[Twierdzenie Perrona-Frobeniusa dla macierzy stochastycznych]
Jeśli $P$ jest macierzą stochastyczną, to jej promień spektralny $\rho(P) = \max \{ |\lambda| : \lambda \text{ jest wartością własną } P \}$ jest równy 1.
\begin{proof}
Wiemy, że $1$ jest wartością własną $P$, więc $\rho(P) \ge 1$. Pokażemy, że $\rho(P) \le 1$.
Przypuśćmy nie wprost, że istnieje wartość własna $\lambda \in \mathbb{C}$ taka, że $|\lambda|>1$ oraz odpowiadający jej prawostronny wektor własny $x \in \mathbb{C}^N$, czyli $Px = \lambda x$.
Niech $m \in \{1, \dots, N\}$ będzie indeksem współrzędnej $x$ o maksymalnym module, tj. $|x_m| = \max_{j} |x_j| > 0$.
Rozważmy $m$-tą współrzędną iloczynu $Px$:
$$ |(Px)_m| = \left| \sum_{j=1}^N P_{mj} x_j \right| $$
Z nierówności trójkąta i własności macierzy stochastycznej ($\sum_j P_{mj} = 1$, $P_{mj} \ge 0$):
$$ \left| \sum_{j=1}^N P_{mj} x_j \right| \le \sum_{j=1}^N |P_{mj} x_j| = \sum_{j=1}^N P_{mj} |x_j| \le \sum_{j=1}^N P_{mj} |x_m| = |x_m| \sum_{j=1}^N P_{mj} = |x_m| $$
Z drugiej strony, z faktu, że $x$ jest wektorem własnym:
$$ |(Px)_m| = |\lambda x_m| = |\lambda| \cdot |x_m| $$
Otrzymujemy sprzeczność:
$$ |\lambda| \cdot |x_m| \le |x_m| $$
Ponieważ $|x_m| > 0$, musiałoby być $|\lambda| \le 1$, co jest sprzeczne z naszym założeniem, że $|\lambda| > 1$. Zatem promień spektralny musi być równy 1.
\end{proof}
\end{twierdzenie}

\begin{wniosek}
Dla macierzy stochastycznej $P$, granica $\lim_{n \to \infty} P^n$ istnieje wtedy i tylko wtedy, gdy dla każdej wartości własnej $\lambda$ o module $|\lambda|=1$, jest ona równa $1$ i jej krotność algebraiczna jest równa geometrycznej.
\end{wniosek}

Dla łańcuchów nieprzywiedlnych i aperiodycznych (które są ergodyczne), $1$ jest jedyną wartością własną na okręgu jednostkowym i jej krotności (algebraiczna i geometryczna) są równe 1, co gwarantuje zbieżność do macierzy $P^\infty$ o identycznych wierszach.

\end{document}