\documentclass{article}

% --- PAKIETY PODSTAWOWE ---
\usepackage[utf8]{inputenc} % Pozwala na bezpośrednie używanie znaków UTF-8 (np. polskich liter)
\usepackage[T1]{fontenc}    % Poprawia kodowanie fontów, umożliwia poprawne dzielenie wyrazów z polskimi znakami
\usepackage[polish]{babel}  % Włącza polskie zasady składu tekstu (dzielenie wyrazów, nazwy itp.)
\usepackage{amsmath}        % Zaawansowane środowiska matematyczne
\usepackage{amssymb}        % Dodaje symbole matematyczne, np. \mathbb{N}
\usepackage{amsfonts}       % Dodatkowe fonty matematyczne
\usepackage{geometry}       % Umożliwia łatwe zarządzanie marginesami

% --- PAKIETY DODATKOWE ---
\usepackage{amsthm}         % Pakiety do tworzenia środowisk typu definicja, twierdzenie
\usepackage{enumitem}       % Umożliwia zaawansowaną konfigurację list
\usepackage[
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue
]{hyperref}                 % Tworzy klikalne linki w dokumencie PDF

% --- PAKIETY DO RYSOWANIA ---
\usepackage{tikz}
\usetikzlibrary{automata, arrows.meta, positioning}

% --- KONFIGURACJA STRONY ---
\geometry{a4paper, margin=1in}

% --- DEFINICJA WŁASNYCH ŚRODOWISK ---
\theoremstyle{definition}
\newtheorem{definition}{Definicja}[section] % Definicje będą numerowane w ramach sekcji
\newtheorem{example}[definition]{Przykład}
\newtheorem{lemat}[definition]{Lemat}
\newtheorem{wniosek}[definition]{Wniosek}
\newtheorem{twierdzenie}[definition]{Twierdzenie}
\newtheorem{obserwacja}[definition]{Obserwacja}
\newtheorem{stwierdzenie}[definition]{Stwierdzenie} % DODANO DLA NOWEJ TREŚCI

\renewcommand{\qedsymbol}{$\blacksquare$} % Zmiana symbolu końca dowodu

\DeclareMathOperator{\NWD}{NWD} % Definicja operatora NWD

\begin{document}

\section{Procesy stochastyczne}
\renewcommand{\thedefinition}{\arabic{section}.\arabic{definition}} % Zmiana formatu numeracji na "sekcja.definicja"

\begin{definition}
	Niech:
	\begin{enumerate}[label=\alph*)]
		\item \textbf{Przestrzeń probabilistyczna} $(\Omega, \mathcal{F}, P)$, gdzie:
		      \begin{itemize}
			      \item $\Omega$ to przestrzeń zdarzeń elementarnych,
			      \item $\mathcal{F}$ to $\sigma$-ciało podzbiorów $\Omega$,
			      \item $P$ to miara prawdopodobieństwa określona na $\mathcal{F}$.
		      \end{itemize}

		\item \textbf{Przestrzeń stanów} $(S, \mathcal{B})$, będąca przestrzenią mierzalną.

		\item Niepusty \textbf{zbiór indeksów (czasu)} $T$.
		      W zależności od natury tego zbioru, przyjęło się stosować odmienną notację:
		      \begin{itemize}
			      \item Gdy czas jest \textbf{ciągły}, np. $T = [0, \infty)$, proces oznaczamy jako $(X_t)_{t \in T}$.
			      \item Gdy czas jest \textbf{dyskretny}, np. $T = \mathbb{N}_0 = \{0, 1, 2, \dots\}$, proces oznaczamy jako $(X_n)_{n \in \mathbb{N}_0}$.
		      \end{itemize}
	\end{enumerate}
	\textbf{Procesem stochastycznym} nazywamy rodzinę zmiennych losowych {$X_t$}$_{t \in T}$, w której każda zmienna losowa $X_t: \Omega \to S$ jest określona na $(\Omega, \mathcal{F}, P)$ i przyjmuje wartości w $(S, \mathcal{B})$ (tzn. zachodzi warunek mierzalności: $X_t^{-1}(\mathcal{B}) \subset \mathcal{F}$).

\end{definition}

\subsection{Dwa spojrzenia na proces – Intuicja}

Proces stochastyczny $X_t(\omega)$ jest funkcją dwóch argumentów: czasu $t \in T$ i zdarzenia elementarnego $\omega \in \Omega$. Aby go zrozumieć, możemy ustalić jeden z argumentów i zobaczyć, co otrzymamy.

\subsubsection*{1. Ustalmy czas $t \in T$ (patrzymy na "przekrój")}

Gdy ustalimy konkretny moment czasu $t_0$, funkcja $X_{t_0}(\omega)$ zależy już tylko od wyniku losowego $\omega$. Otrzymujemy w ten sposób \textbf{zmienną losową}. Jest to "zdjęcie" procesu w jednej chwili, pokazujące rozkład możliwych wartości.


\subsubsection*{2. Ustalmy wynik losowy $\omega \in \Omega$ (patrzymy na "ścieżkę")}

Gdy ustalimy konkretny wynik losowy $\omega_0$, funkcja $X_t(\omega_0)$ zależy już tylko od czasu $t$. Otrzymujemy w ten sposób zwykłą funkcję czasu, którą nazywamy \textbf{trajektorią} (ang. \textit{trajectory}, \textit{sample path}) lub \textbf{realizacją procesu}. Jest to "film" pokazujący jedną konkretną ewolucję procesu.


\vspace{1em}
Podsumowując, proces stochastyczny to cała kolekcja wszystkich możliwych trajektorii.

\subsection{Po co nam warunek mierzalności?}

Warunek mierzalności, czyli $X_t^{-1}(\mathcal{B}) \subset \mathcal{F}$, jest kluczowym technicznym wymogiem, który pozwala nam "przenosić" miarę prawdopodobieństwa $P$ z przestrzeni $\Omega$ na przestrzeń stanów $S$. Bez niego nie moglibyśmy w sensowny sposób pytać o prawdopodobieństwo zdarzeń typu "$X_t$ wpada do zbioru $B$".

Dla pojedynczej zmiennej losowej $X: (\Omega, \mathcal{F}) \to (S, \mathcal{B})$, jej \textbf{rozkład} (ozn. $\mu_X$) to nowa miara prawdopodobieństwa, ale zdefiniowana na przestrzeni stanów $(S, \mathcal{B})$. Mówi nam ona, jakie jest prawdopodobieństwo, że zmienna $X$ przyjmie wartość z danego zbioru $B \in \mathcal{B}$:
\[
	\mu_X(B) := P(X \in B) = P(\{\omega \in \Omega : X(\omega) \in B\}) = P(X^{-1}(B))
\]
Aby to wyrażenie miało sens, zbiór $X^{-1}(B)$ musi należeć do $\sigma$-ciała $\mathcal{F}$ (musimy umieć zmierzyć jego "wielkość" za pomocą miary $P$). I to właśnie gwarantuje nam warunek mierzalności zmiennej losowej $X$.

W procesach stochastycznych uogólniamy pojęcie rozkładu na tzw. \textbf{rozkłady skończenie wymiarowe}. Zamiast patrzeć na jedną zmienną $X_t$, analizujemy łączne zachowanie procesu w wielu chwilach czasu, czyli wektory $(X_{t_1}, \dots, X_{t_n})$.

\begin{definition}[Rozkład skończenie wymiarowy]
	Dla dowolnego $n \in \mathbb{N}$ i dowolnego zbioru chwil czasu $t_1, \dots, t_n \in T$, \textbf{rozkładem skończenie wymiarowym} procesu $(X_t)_{t \in T}$ nazywamy rozkład wektora losowego $(X_{t_1}, \dots, X_{t_n})$. Jest to miara prawdopodobieństwa $\mu_{t_1, \dots, t_n}$ na przestrzeni mierzalnej $(S^n, \mathcal{B}^n)$ zdefiniowana jako:
	\[
		\mu_{t_1, \dots, t_n}(B) := P((X_{t_1}, \dots, X_{t_n}) \in B), \quad \text{dla } B \in \mathcal{B}^n
	\]
\end{definition}

\begin{definition}[Rodzina rozkładów skończenie wymiarowych]
	Kolekcję wszystkich rozkładów skończenie wymiarowych procesu $(X_t)_{t \in T}$ dla wszystkich możliwych, skończonych wyborów chwil czasu, nazywamy \textbf{rodziną rozkładów skończenie wymiarowych} tego procesu. Formalnie jest to zbiór miar:
	\begin{equation*}
		\left\{ \mu_{t_1, \dots, t_n} \mid n \in \mathbb{N}, t_1, \dots, t_n \in T \right\}
	\end{equation*}
\end{definition}

Co ważne, ta rodzina rozkładów jest jednym z podstawowych sposobów charakteryzowania i klasyfikowania procesów stochastycznych. Dwa procesy o tej samej rodzinie rozkładów skończenie wymiarowych są z perspektywy probabilistycznej nierozróżnialne. Warto też zauważyć, że najprostszy przypadek, $n=1$, daje nam \textbf{rozkłady jednowymiarowe} ($\mu_t$), które opisują zachowanie procesu w pojedynczej chwili czasu.

\begin{example}[Ciąg niezależnych zmiennych losowych (szum)]

	Niech $(\xi_n)_{n \in \mathbb{N}_0}$ będzie ciągiem niezależnych zmiennych losowych o jednakowym rozkładzie (i.i.d. -- \textit{independent and identically-distributed}), zdefiniowanym następująco:
	\begin{equation*}
		P(\xi_n = 1) = p, \quad P(\xi_n = -1) = 1-p
	\end{equation*}
	dla pewnego $p \in (0, 1)$.

	W tym przypadku:
	\begin{itemize}
		\item \textbf{Zbiór indeksów (czasu):} $T = \mathbb{N}_0 = \{0, 1, 2, \dots\}$ (czas dyskretny).
		\item \textbf{Przestrzeń stanów:} $S = \{-1, 1\}$.
	\end{itemize}

	\textbf{Intuicja:} Jest to prymitywny model, który nie modeluje żadnych zależności czasowych -- reprezentuje czysty \textbf{szum} (w tym przypadku tzw. biały szum). Wynik w chwili $n$ nie ma żadnego wpływu na wynik w chwili $n+1$.

	\textbf{Ciekawostka (Twierdzenie Kołmogorowa):} Mogłoby się wydawać, że "skonstruowanie" nieskończonej rodziny niezależnych zmiennych losowych jest problematyczne. Jednak fundamentalne twierdzenie Kołmogorowa o istnieniu procesu gwarantuje, że dla dowolnego zadanego rozkładu prawdopodobieństwa, zawsze można skonstruować przestrzeń probabilistyczną i proces, który jest ciągiem niezależnych zmiennych losowych o dokładnie tym rozkładzie.
\end{example}

\begin{example}[Błądzenie losowe jako wstęp do procesów Markowa]

	Ten przykład wprowadza prostą zależność między kolejnymi stanami procesu.

	Zdefiniujmy nowy proces $(X_n)_{n \in \mathbb{N}_0}$ w oparciu o ciąg zmiennych $(\xi_n)$ z poprzedniego przykładu. Niech:
	\begin{itemize}
		\item $X_0 = 0$ (startujemy z zera).
		\item $X_n = X_{n-1} + \xi_n$ dla $n \ge 1$.
	\end{itemize}
	Taki proces nazywamy \textbf{błądzeniem losowym} (lub spacerem losowym, ang. \textit{random walk}).

	Jego komponenty to:
	\begin{itemize}
		\item \textbf{Zbiór indeksów (czasu):} $T = \mathbb{N}_0$ (czas dyskretny).
		\item \textbf{Przestrzeń stanów:} $S = \mathbb{Z} = \{\dots, -2, -1, 0, 1, 2, \dots\}$ (zbiór liczb całkowitych).
	\end{itemize}

	\textbf{Intuicja (Własność Markowa):} Proces ten opisuje pozycję "wędrowca", który w każdej jednostce czasu wykonuje losowy krok. Kluczową różnicą w stosunku do poprzedniego przykładu jest tu "pamięć". Jednak jest to pamięć bardzo krótka -- aby poznać stan procesu w przyszłości (w chwili $n+1$), wystarczy nam znajomość stanu obecnego (w chwili $n$). Cała przeszłość procesu (stany $X_0, \dots, X_{n-1}$) nie wnosi już żadnej dodatkowej informacji.

	Ta fundamentalna właściwość, polegająca na "braku pamięci" o odległej przeszłości, jest niezwykle ważna i nosi nazwę \textbf{własności Markowa}. Procesy ją spełniające to \textbf{procesami Markowa}, a błądzenie losowe jest ich koronnym przykładem. Własność ta prowadzi nas wprost do definicji nowej, potężnej klasy procesów, którym zajmiemy się w następnej sekcji.
\end{example}

\section{Łańcuchy Markowa z czasem dyskretnym}

Rozważmy proces stochastyczny z czasem dyskretnym ($T=\mathbb{N}_0$) i co najwyżej przeliczalną przestrzenią stanów $S$. Jak widzieliśmy, aby w pełni opisać taki proces, musimy znać jego rozkłady skończenie wymiarowe, czyli prawdopodobieństwa dowolnych ścieżek, np. $P(X_0=x_0, X_1=x_1, \dots, X_n=x_n)$.

Z ogólnej definicji prawdopodobieństwa warunkowego, $P(A \cap B) = P(A|B)P(B)$, możemy zapisać to prawdopodobieństwo łączne w postaci "teleskopowego" iloczynu:
\begin{equation*}
	\begin{split}
		P(X_0=x_0, X_1=x_1, \dots, X_n=x_n) = P(X_0=x_0) \cdot P(X_1=x_1 | X_0=x_0) \cdot \\
		\cdot P(X_2=x_2 | X_0=x_0, X_1=x_1) \cdots P(X_n=x_n | X_0=x_0, \dots, X_{n-1}=x_{n-1})
	\end{split}
\end{equation*}
Powyższy wzór jest zawsze prawdziwy, ale w ogólnym przypadku niepraktyczny, ponieważ ostatnie wyrazy warunkują prawdopodobieństwo od całej, potencjalnie bardzo długiej, historii procesu.

Kluczowa idea polega na rozważeniu szczególnej, ale bardzo ważnej klasy procesów, dla których ten wzór dramatycznie się upraszcza.

\begin{definition}[Własność Markowa]
	Mówimy, że proces stochastyczny $(X_n)_{n \in \mathbb{N}_0}$ ma \textbf{własność Markowa} (a sam proces nazywamy \textbf{łańcuchem Markowa}), jeśli:
	\begin{equation*}
		\begin{gathered}
			\forall n \ge 1 \\
			\forall x_0, \dots, x_n \in S
		\end{gathered}
	\end{equation*}
	zachodzi:
	\begin{equation*}
		P(X_n=x_n | X_0=x_0, \dots, X_{n-1}=x_{n-1}) = P(X_n=x_n | X_{n-1}=x_{n-1})
	\end{equation*}
	Jest to sytuacja, w której "w każdym takim prawdopodobieństwie warunkowym interesuje nas tylko ostatni element" historii.
\end{definition}

Dzięki tej własności, "teleskopowy" wzór na prawdopodobieństwo łączne upraszcza się do postaci, która zależy już tylko od dwóch, znacznie prostszych komponentów:
\begin{enumerate}
	\item \textbf{Rozkładu początkowego} $\alpha = [\alpha_i]_{i \in S}$, czyli prawdopodobieństw $\alpha_i = P(X_0=i)$.
	\item \textbf{Prawdopodobieństw przejścia} w jednym kroku, czyli $P(X_n=j | X_{n-1}=i)$.
\end{enumerate}

\begin{definition}[Jednorodny Łańcuch Markowa]
	Łańcuch Markowa nazywamy \textbf{jednorodnym}, jeśli prawdopodobieństwa przejścia w jednym kroku nie zależą od czasu $n$, tzn. prawdopodobieństwo przejścia ze stanu $i$ do stanu $j$ jest zawsze takie samo, niezależnie od tego, w którym kroku proces się znajduje.

	Formalnie, istnieje funkcja $p: S \times S \to [0, 1]$ taka, że dla wszystkich $n \in \mathbb{N}$ oraz $i, j \in S$ zachodzi:
	\begin{equation*}
		P(X_n=j | X_{n-1}=i) = p(i, j)
	\end{equation*}
\end{definition}

\textit{Od teraz, mówiąc ``łańcuch Markowa'', będziemy prawie zawsze mieli na myśli \textbf{jednorodny łańcuch Markowa (jŁM)}.}

\begin{definition}[Macierz przejścia]
	Funkcję $p(i,j)$ z powyższej definicji, określającą prawdopodobieństwa przejść, wygodnie jest zapisać w postaci macierzy. Jest to możliwe właśnie dzięki założeniu, że przestrzeń stanów $S$ jest co najwyżej przeliczalna (cnp), co pozwala nam ``ustawić'' stany w wierszach i kolumnach.

	\textbf{Macierzą przejścia w jednym kroku} łańcucha Markowa nazywamy macierz $P$, której elementy $p_{ij}$ dane są przez:
	\begin{equation*}
		p_{ij} = p(i,j) = P(X_n=j | X_{n-1}=i)
	\end{equation*}
	Macierz ta ma wymiary $|S| \times |S|$ (mogą być nieskończone) i w pełni opisuje dynamikę jednorodnego łańcucha. Każda macierz przejścia jest \textbf{macierzą stochastyczną}, tzn. spełnia dwa warunki:
	\begin{enumerate}
		\item Jej elementy są nieujemne: $p_{ij} \ge 0$ dla wszystkich $i,j \in S$.
		\item Suma prawdopodobieństw w każdym wierszu jest równa 1: $\sum_{j \in S} p_{ij} = 1$ dla każdego $i \in S$.
	\end{enumerate}
\end{definition}

\begin{example}
	Rozważmy jŁM o następujących komponentach:
	\begin{itemize}
		\item Przestrzeń stanów: $S = \{1, 2\}$.
		\item Rozkład początkowy: $\alpha = [\frac{1}{2}, \frac{1}{2}]$, co oznacza, że $P(X_0=1) = \frac{1}{2}$, a $P(X_0=2) = \frac{1}{2}$.
		\item Prawdopodobieństwa przejścia dane są następująco:
		      \begin{itemize}
			      \item $P(X_{n+1}=1 | X_n=1) = 2/3$
			      \item $P(X_{n+1}=2 | X_n=1) = 1/3$
			      \item $P(X_{n+1}=1 | X_n=2) = 1/2$
			      \item $P(X_{n+1}=2 | X_n=2) = 1/2$
		      \end{itemize}
	\end{itemize}

	Na podstawie tych prawdopodobieństw, możemy skonstruować \textbf{macierz przejścia} $P$:
	\begin{equation*}
		P =
		\begin{bmatrix}
			2/3 & 1/3 \\
			1/2 & 1/2
		\end{bmatrix}
	\end{equation*}
	Zauważmy, że jest to macierz stochastyczna, ponieważ wszystkie jej elementy są nieujemne, a suma każdego wiersza jest równa 1.

	Dynamikę tego łańcucha można również zwizualizować za pomocą \textbf{grafu stanów}:

	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=3cm, state/.style={circle, draw, minimum size=0.8cm}]
			\node[state] (1) {1};
			\node[state] (2) [right=of 1] {2};

			\path (1) edge [loop above] node {2/3} (1)
			edge [bend left]  node {1/3} (2);
			\path (2) edge [loop above] node {1/2} (2)
			edge [bend left]  node {1/2} (1);
		\end{tikzpicture}
	\end{center}

	\textbf{Wniosek:} Mając te dwa obiekty – wektor rozkładu początkowego $\alpha$ i macierz przejścia $P$ – jesteśmy w stanie w pełni opisać zachowanie procesu i generować jego losowe trajektorie. Proces losowania wyglądałby następująco: najpierw losujemy stan początkowy $X_0$ zgodnie z rozkładem $\alpha$. Następnie, jeśli wylosowaliśmy $X_0=i$, losujemy stan $X_1$ zgodnie z rozkładem danym przez $i$-ty wiersz macierzy $P$. Proces ten kontynuujemy dla kolejnych kroków.
\end{example}

\begin{lemat}[Równoważny warunek Markowa]
	Własność Markowa jest często przedstawiana w mocniejszej, równoważnej formie, która mówi, że przyszłość procesu zależy tylko od ostatniego znanego nam stanu, niezależnie od tego, jak odległa i ``dziurawa'' jest nasza wiedza o przeszłości.

	Formalnie, dla dowolnego ciągu rosnących chwil czasu $n_1 < n_2 < \dots < n_k < n_{k+1}$ i dowolnych stanów $x_{n_1}, \dots, x_{n_{k+1}} \in S$, zachodzi:
	\begin{equation*}
		\begin{split}
			P(X_{n_{k+1}} = x_{n_{k+1}} | X_{n_k}=x_{n_k}, \dots, X_{n_1}=x_{n_1}) \\
			= P(X_{n_{k+1}} = x_{n_{k+1}} | X_{n_k}=x_{n_k})
		\end{split}
	\end{equation*}
	Na przykład, wiedząc, jaki był stan procesu w chwili 7, informacja o stanie w chwili 3 nie wnosi już nic nowego do przewidywania stanu w chwili 10:
	\begin{equation*}
		P(X_{10}=x_{10} | X_7=x_7, X_3=x_3) = P(X_{10}=x_{10} | X_7=x_7)
	\end{equation*}
\end{lemat}

\section{Prawdopodobieństwa i macierze przejścia w n krokach}

\begin{definition}[Prawdopodobieństwo przejścia w n krokach]
	Prawdopodobieństwem przejścia ze stanu $i$ do stanu $j$ w $n$ krokach ($n \in \mathbb{N}$) nazywamy prawdopodobieństwo warunkowe:
	\begin{equation*}
		p_n(i, j) := P(X_n = j | X_0 = i)
	\end{equation*}
	Dzięki jednorodności łańcucha, prawdopodobieństwo to nie zależy od wyboru "chwili startowej", a jedynie od długości przedziału czasowego. Oznacza to, że dla dowolnego $k \in \mathbb{N}_0$:
	\begin{equation*}
		p_n(i, j) = P(X_{n+k} = j | X_k = i)
	\end{equation*}
\end{definition}

\begin{definition}[Macierz przejścia w n krokach]
	Analogicznie do macierzy jednokrokowej, elementy $p_n(i, j)$ możemy zebrać w \textbf{macierz przejścia w n krokach}, oznaczaną jako $P(n)$:
	\begin{equation*}
		P(n) := [p_n(i, j)]_{i,j \in S}
	\end{equation*}
\end{definition}

\begin{twierdzenie}[Równania Chapmana-Kołmogorowa]
	Dla dowolnych $m, n \in \mathbb{N}_0$ oraz dla wszystkich stanów $i, j \in S$ zachodzi:
	\begin{equation*}
		p_{m+n}(i, j) = \sum_{k \in S} p_m(i, k) p_n(k, j)
	\end{equation*}
\end{twierdzenie}

\begin{proof}
	Dowód opiera się na zastosowaniu wzoru na prawdopodobieństwo całkowite oraz własności Markowa.
	Z definicji prawdopodobieństwa przejścia w $m+n$ krokach mamy:
	\begin{equation*}
		p_{m+n}(i, j) = P(X_{m+n} = j | X_0 = i)
	\end{equation*}
	Aby dotrzeć ze stanu $i$ do stanu $j$ w $m+n$ krokach, proces musi w "pośrednim" kroku $m$ znaleźć się w jakimś stanie $k \in S$. Sumując po wszystkich możliwych stanach pośrednich $k$, otrzymujemy:
	\begin{align*}
		P(X_{m+n} = j | X_0 = i) & = P\left(\bigcup_{k \in S} \{X_{m+n}=j, X_m=k\} \Big| X_0=i\right)                    \\
		                         & = \sum_{k \in S} P(X_{m+n}=j, X_m=k | X_0=i) \quad \text{(bo zdarzenia są rozłączne)} \\
		                         & = \sum_{k \in S} \frac{P(X_{m+n}=j, X_m=k, X_0=i)}{P(X_0=i)}                          \\
		                         & \quad \text{(rozpisujemy licznik ze wzoru } P(A,B)=P(A|B)P(B) \text{ )}               \\
		                         & = \sum_{k \in S} \frac{P(X_{m+n}=j | X_m=k, X_0=i) \cdot P(X_m=k, X_0=i)}{P(X_0=i)}   \\
		                         & = \sum_{k \in S} P(X_{m+n}=j | X_m=k, X_0=i) \cdot P(X_m=k | X_0=i)
	\end{align*}
	Teraz stosujemy kluczowe założenia:
	\begin{enumerate}
		\item \textbf{Własność Markowa}: Informacja o stanie w chwili $X_0=i$ jest zbędna do przewidywania przyszłości, jeśli znamy stan w chwili $X_m=k$.
		      \begin{equation*}
			      P(X_{m+n}=j | X_m=k, X_0=i) = P(X_{m+n}=j | X_m=k)
		      \end{equation*}
		\item \textbf{Jednorodność w czasie}: Prawdopodobieństwo przejścia zależy tylko od różnicy czasu.
		      \begin{align*}
			      P(X_{m+n}=j | X_m=k) & = p_n(k, j) \\
			      P(X_m=k | X_0=i)     & = p_m(i, k)
		      \end{align*}
	\end{enumerate}
	Podstawiając te zależności do naszej sumy, otrzymujemy tezę:
	\begin{equation*}
		p_{m+n}(i, j) = \sum_{k \in S} p_m(i, k) p_n(k, j)
	\end{equation*}
	Co kończy dowód.
\end{proof}

\subsection{Postać macierzowa i intuicje}

Równania Chapmana-Kołmogorowa mają bardzo elegancką i użyteczną interpretację macierzową. Wyrażenie $\sum_{k \in S} p_m(i, k) p_n(k, j)$ odpowiada dokładnie definicji mnożenia macierzy: jest to wzór na element znajdujący się w $i$-tym wierszu i $j$-tej kolumnie iloczynu macierzy $P(m)$ i $P(n)$.

To spostrzeżenie pozwala zapisać równania Chapmana-Kołmogorowa w niezwykle zwartej postaci macierzowej:
\begin{equation*}
	P(m+n) = P(m) \cdot P(n)
\end{equation*}

\subsubsection*{Wniosek: Macierz przejścia w n krokach to n-ta potęga macierzy P}
Z powyższej własności wynika fundamentalny wniosek. Ustawiając $m=1$ i stosując indukcję, otrzymujemy:
\begin{itemize}
	\item $P(2) = P(1+1) = P(1) \cdot P(1) = P \cdot P = P^2$
	\item $P(3) = P(2+1) = P(2) \cdot P(1) = P^2 \cdot P = P^3$
	\item ...
	\item $P(n) = P^n$
\end{itemize}
\textbf{Macierz przejścia w n krokach jest po prostu n-tą potęgą macierzy przejścia w jednym kroku.}

\begin{example}
	Jeśli chcemy obliczyć prawdopodobieństwo przejścia ze stanu $i$ do $j$ w 2 krokach, możemy albo sumować po wszystkich możliwych ścieżkach długości 2:
	\begin{equation*}
		p_2(i, j) = \sum_{k \in S} p_{ik} p_{kj}
	\end{equation*}
	Albo po prostu obliczyć macierz $P^2$ i odczytać jej element $(i,j)$. Obie metody są tożsame.
\end{example}

\subsubsection*{Znaczenie praktyczne}
Ta prosta zależność jest niezwykle potężna. Oznacza, że cała dynamika jednorodnego łańcucha Markowa na dowolnym horyzoncie czasowym jest w pełni zdeterminowana przez macierz przejścia w jednym kroku $P$.

\textbf{Rozkład prawdopodobieństwa w chwili n:}
Jeśli znamy rozkład początkowy $\alpha = [\alpha_i]_{i \in S}$, gdzie $\alpha_i = P(X_0=i)$, to rozkład w chwili $n$, czyli wektor $\alpha^{(n)} = [P(X_n=j)]_{j \in S}$, możemy obliczyć następująco:
\begin{align*}
	P(X_n=j) & = \sum_{i \in S} P(X_n=j, X_0=i)                 \\
	         & = \sum_{i \in S} P(X_n=j | X_0=i) \cdot P(X_0=i) \\
	         & = \sum_{i \in S} (P^n)_{ij} \cdot \alpha_i
\end{align*}
W ostatnim kroku podstawiliśmy zdefiniowane wcześniej symbole: $P(X_n=j | X_0=i) = (P^n)_{ij}$ (prawdopodobieństwo przejścia w n krokach) oraz $P(X_0=i) = \alpha_i$ (prawdopodobieństwo z rozkładu początkowego).
W notacji wektorowej (traktując $\alpha$ jako wektor wierszowy) jest to po prostu:
\begin{equation*}
	\alpha^{(n)} = \alpha \cdot P^n
\end{equation*}
To pokazuje, że mając rozkład początkowy $\alpha$ i macierz przejścia $P$, możemy obliczyć dowolny rozkład skończenie wymiarowy, co w pełni determinuje cały proces.


\begin{example}[Jak obliczyć prawdopodobieństwo dla niekolejnych chwil?]
	Załóżmy, że chcemy obliczyć prawdopodobieństwo łączne dla chwil, które nie następują po sobie, np. $P(X_{20}=x_{20}, X_5=x_5, X_3=x_3)$. Korzystając z reguły łańcuchowej i wielokrotnie stosując własność Markowa, możemy to zapisać jako:
	\begin{align*}
		 & P(X_{20}=x_{20}, X_5=x_5, X_3=x_3)                                       \\
		 & = P(X_{20}=x_{20} | X_5=x_5) \cdot P(X_5=x_5 | X_3=x_3) \cdot P(X_3=x_3) \\
		 & = (P^{15})_{x_5, x_{20}} \cdot (P^2)_{x_3, x_5} \cdot (\alpha P^3)_{x_3}
	\end{align*}
	Warto przy tym wyjaśnić notację: $(P^{15})_{x_5, x_{20}}$ to element w wierszu $x_5$ i kolumnie $x_{20}$ macierzy $P^{15}$ (czyli macierzy przejścia w 15 krokach). Reprezentuje on prawdopodobieństwo przejścia ze stanu $x_5$ do stanu $x_{20}$ w dokładnie 15 krokach.
\end{example}

\begin{example}[Jak obliczyć prawdopodobieństwo warunkowe dla niekolejnych chwil?]
	Podobnie postępujemy dla prawdopodobieństwa warunkowego. Własność Markowa pozwala na rozbicie prawdopodobieństwa ścieżki na iloczyn przejść:
	\begin{align*}
		 & P(X_7=x_7, X_5=x_5, X_2=x_2 | X_0=x_0)                                       \\
		 & = P(X_7=x_7 | X_5=x_5) \cdot P(X_5=x_5 | X_2=x_2) \cdot P(X_2=x_2 | X_0=x_0) \\
		 & = (P^2)_{x_5, x_7} \cdot (P^3)_{x_2, x_5} \cdot (P^2)_{x_0, x_2}
	\end{align*}
\end{example}

\section{Czasy i Prawdopodobieństwa Trafień}

Aby móc klasyfikować stany, musimy najpierw zdefiniować kilka kluczowych pojęć związanych z "trafianiem" w stany przez proces.

\begin{definition}[Moment pierwszego trafienia]
	Dla danego stanu $j \in S$, \textbf{momentem pierwszego trafienia} w stanie $j$ nazywamy zmienną losową $T_j$ zdefiniowaną jako:
	\begin{equation*}
		T_j := \min\{ n \ge 1 \mid X_n = j \}
	\end{equation*}
	Jest to numer kroku, w którym proces po raz pierwszy (po chwili początkowej) znalazł się w stanie $j$. Jeśli proces nigdy nie trafia do stanu $j$, przyjmujemy, że $T_j = \infty$.
\end{definition}

\begin{definition}[Całkowita liczba trafień]
	Dla danego stanu $j \in S$, \textbf{całkowitą liczbę trafień} w stanie $j$ definiujemy jako zmienną losową $N_j$:
	\begin{equation*}
		N_j := \sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=j\}}
	\end{equation*}
	gdzie $\mathbf{1}_{\{A\}}$ to funkcja indykatorowa zdarzenia $A$.
	\vspace{1em}

	\textbf{Intuicja:} Na każdej trajektorii procesu, zmienna losowa $N_j$ po prostu zlicza, ile razy (po chwili początkowej) proces "uderzył" w stan $j$. Istnieją trajektorie, dla których $N_j=0$, i zbiór takich trajektorii może mieć niezerowe prawdopodobieństwo.
\end{definition}

\begin{definition}[Prawdopodobieństwo pierwszego trafienia w chwili n]
	Prawdopodobieństwem, że pierwsze trafienie w stanie $j$, startując ze stanu $i$, nastąpi dokładnie w chwili $n$, nazywamy $f_{ij}(n)$:
	\begin{equation*}
		f_{ij}(n) := P(T_j = n \mid X_0 = i)
	\end{equation*}
	Można to równoważnie zapisać jako prawdopodobieństwo, że w chwili $n$ jesteśmy w $j$, a wcześniej nigdy tam nie byliśmy:
	\begin{equation*}
		f_{ij}(n) = P(X_n=j, X_{n-1} \neq j, \dots, X_1 \neq j \mid X_0 = i)
	\end{equation*}
\end{definition}

\begin{definition}[Prawdopodobieństwo dotarcia do stanu]
	Prawdopodobieństwem \textbf{dotarcia} (lub "wejścia kiedykolwiek") do stanu $j$, startując ze stanu $i$, nazywamy $f_{ij}$:
	\begin{equation*}
		f_{ij} := P(T_j < \infty \mid X_0 = i)
	\end{equation*}
	Jest to po prostu prawdopodobieństwo, że stan $j$ zostanie kiedykolwiek odwiedzony. Zdarzenie $\{T_j < \infty\}$ jest sumą rozłącznych zdarzeń $\{T_j=n\}$ dla wszystkich $n \ge 1$, zatem:
	\begin{equation*}
		f_{ij} = \sum_{n=1}^{\infty} P(T_j=n \mid X_0=i) = \sum_{n=1}^{\infty} f_{ij}(n)
	\end{equation*}
	Równoważnie, dotarcie do stanu $j$ co najmniej raz jest tym samym, co posiadanie co najmniej jednego trafienia w tym stanie:
	\begin{equation*}
		f_{ij} = P(N_j \ge 1 \mid X_0 = i)
	\end{equation*}
\end{definition}

\begin{obserwacja}[Prawdopodobieństwo wielokrotnych trafień]
	Dla dowolnych stanów $i, j \in S$ i dowolnego $k \in \mathbb{N}$, prawdopodobieństwo co najmniej $k$ trafień w stanie $j$, startując ze stanu $i$, dane jest wzorem:
	\begin{equation*}
		P(N_j \ge k \mid X_0 = i) = f_{ij} \cdot f_{jj}^{k-1}
	\end{equation*}

	W szczególnym przypadku, gdy startujemy już ze stanu $j$ (czyli $i=j$), wzór upraszcza się do:
	\begin{equation*}
		P(N_j \ge k \mid X_0 = j) = f_{jj}^k
	\end{equation*}
\end{obserwacja}

\vspace{1em}

Ta obserwacja prowadzi nas do fundamentalnego podziału stanów łańcucha Markowa. Kluczową wielkością jest prawdopodobieństwo powrotu $f_{jj}$, czyli prawdopodobieństwo, że proces kiedykolwiek wróci do stanu $j$, startując z tego stanu.

\begin{definition}[Klasyfikacja stanów: powracające i chwilowe]
	Niech $j \in S$ będzie stanem łańcucha Markowa. Stan $j$ klasyfikujemy w następujący sposób:

	\begin{enumerate}[label=\alph*)]
		\item Stan $j$ nazywamy \textbf{stanem powracającym} (ang. \textit{recurrent state}), jeśli:
		      \begin{equation*}
			      f_{jj} = 1
		      \end{equation*}
		      Oznacza to, że proces, startując ze stanu $j$, na pewno (z prawdopodobieństwem 1) kiedyś do niego powróci.

		\item Stan $j$ nazywamy \textbf{stanem chwilowym} (lub \textbf{przejściowym}, ang. \textit{transient state}), jeśli:
		      \begin{equation*}
			      f_{jj} < 1
		      \end{equation*}
		      Oznacza to, że istnieje niezerowe prawdopodobieństwo $1-f_{jj} > 0$, że proces, startując ze stanu $j$, nigdy do niego nie powróci.
	\end{enumerate}
\end{definition}

\begin{obserwacja}[Konsekwencje klasyfikacji dla liczby trafień]
	Klasyfikacja stanów ma fundamentalne konsekwencje dla liczby trafień $N_j$:

	\begin{enumerate}[label=\alph*)]
		\item Jeśli stan $j$ jest \textbf{powracający} ($f_{jj} = 1$), to proces, który raz wystartował ze stanu $j$, będzie do niego powracał gwarantowaną liczbę razy. Formalnie, dla dowolnego $k \ge 1$:
		      \begin{equation*}
			      P(N_j \ge k \mid X_0 = j) = 1
		      \end{equation*}
		      Prawdopodobieństwo co najmniej $k$ powrotów do stanu $j$ jest równe 1, niezależnie od tego, jak duże jest $k$.

		\item Jeśli stan $j$ jest \textbf{chwilowy} ($f_{jj} < 1$), to prawdopodobieństwo, że proces odwiedzi ten stan co najmniej $k$ razy, maleje do zera, gdy $k$ rośnie do nieskończoności. Co ważne, dzieje się tak niezależnie od stanu początkowego $i \in S$:
		      \begin{equation*}
			      \lim_{k \to \infty} P(N_j \ge k \mid X_0 = i) = 0
		      \end{equation*}
		      Oznacza to, że dla stanów chwilowych liczba odwiedzin jest z prawdopodobieństwem 1 skończona.
	\end{enumerate}
\end{obserwacja}

\begin{proof}
	Dowód opiera się bezpośrednio na wzorze z Obserwacji 4.5: $P(N_j \ge k \mid X_0 = i) = f_{ij} f_{jj}^{k-1}$.

	\begin{enumerate}[label=\alph*)]
		\item \textbf{Stan powracający ($f_{jj}=1$):}
		      W tym przypadku, startując ze stanu $i=j$, wzór przyjmuje postać:
		      \begin{equation*}
			      P(N_j \ge k \mid X_0 = j) = f_{jj} \cdot f_{jj}^{k-1} = f_{jj}^k
		      \end{equation*}
		      Ponieważ $f_{jj}=1$, otrzymujemy $P(N_j \ge k \mid X_0 = j) = 1^k = 1$ dla dowolnego $k \ge 1$.

		\item \textbf{Stan chwilowy ($f_{jj}<1$):}
		      Tym razem rozważamy dowolny stan początkowy $i$. Mamy:
		      \begin{equation*}
			      P(N_j \ge k \mid X_0 = i) = f_{ij} f_{jj}^{k-1}
		      \end{equation*}
		      Ponieważ $f_{jj} < 1$, to $\lim_{k \to \infty} f_{jj}^{k-1} = 0$. Prawdopodobieństwo $f_{ij}$ jest stałą z przedziału $[0, 1]$. W granicy otrzymujemy:
		      \begin{equation*}
			      \lim_{k \to \infty} P(N_j \ge k \mid X_0 = i) = f_{ij} \cdot \lim_{k \to \infty} f_{jj}^{k-1} = f_{ij} \cdot 0 = 0
		      \end{equation*}
	\end{enumerate}
	Co kończy dowód.
\end{proof}

\begin{example}[Graficzna ilustracja klasyfikacji stanów]
	Rozważmy łańcuch o trzech stanach $S=\{a, b, c\}$, którego graf przejść wygląda następująco:

	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=3cm, state/.style={circle, draw, minimum size=0.8cm}]
			\node[state] (a) {a};
			\node[state] (b) [right=of a] {b};
			\node[state] (c) [below=of a] {c};

			% Przejścia z a
			\path (a) edge [loop above] node {1/3} (a);
			\path (a) edge [bend left]  node[above] {2/3} (b);

			% Przejścia z b
			\path (b) edge [bend left]  node[below] {1} (a);

			% Przejścia z c
			\path (c) edge [loop below] node {1/2} (c);
			\path (c) edge              node[left] {1/4} (a);
			\path (c) edge [bend right] node[right] {1/4} (b);
		\end{tikzpicture}
	\end{center}

	W tym łańcuchu:
	\begin{itemize}
		\item Stany $a$ i $b$ są \textbf{powracające}. Rozważmy podzbiór stanów $\{a, b\}$. Jeśli proces znajdzie się w tym podzbiorze, nigdy go nie opuści, ponieważ nie ma przejść z $a$ lub $b$ do $c$. Co więcej, niemożliwe jest "utknięcie" w jednym ze stanów bez powrotu do drugiego. Ze stanu $b$ proces musi wrócić do $a$. Ze stanu $a$ istnieje stała, niezerowa szansa na przejście do $b$. To gwarantuje, że proces będzie w nieskończoność przemieszczał się między nimi. Dlatego, startując z $a$ (lub $b$), mamy pewność, że proces kiedyś tam powróci ($f_{aa}=1$ i $f_{bb}=1$).
		\item Stan $c$ jest \textbf{chwilowy}. Ze stanu $c$ istnieje niezerowe prawdopodobieństwo ($1/4 + 1/4 = 1/2$) przejścia do stanu $a$ lub $b$. Jednakże, gdy proces raz przejdzie do $a$ lub $b$, nie ma już żadnej możliwości powrotu do stanu $c$. Ponieważ istnieje scenariusz, w którym proces opuszcza stan $c$ i nigdy do niego nie wraca, prawdopodobieństwo powrotu jest mniejsze od 1 ($f_{cc} < 1$).
	\end{itemize}
\end{example}

\begin{lemat}[Wartość oczekiwana zmiennej o wartościach w $\mathbb{N}_0$]
	Dla dowolnej zmiennej losowej $X$ przyjmującej wartości w zbiorze liczb naturalnych z zerem ($\mathbb{N}_0 = \{0, 1, 2, \dots\}$), jej wartość oczekiwana może być wyrażona jako:
	\begin{equation*}
		E[X] = \sum_{k=1}^{\infty} P(X \ge k)
	\end{equation*}
\end{lemat}
\begin{proof}
	Dowód wynika z rozpisania sumy i zmiany kolejności sumowania (co jest dozwolone dla składników nieujemnych na mocy tw. Tonellego). Rozpisując podwójną sumę, otrzymujemy:
	\begin{align*}
		\sum_{k=1}^{\infty} P(X \ge k) & = \sum_{k=1}^{\infty} \sum_{j=k}^{\infty} P(X=j)                                 \\
		                               & = \begin{array}{l@{}l}
			                                     & P(X=1) + P(X=2) + P(X=3) + \dots           \\
			                                   + & \phantom{P(X=1) +} P(X=2) + P(X=3) + \dots \\
			                                   + & \phantom{P(X=1) + P(X=2) +} P(X=3) + \dots \\
			                                   + & \phantom{P(X=1) + P(X=2) + P(X=3) +} \dots
		                                   \end{array}                                 \\
		                               & = \sum_{k=1}^{\infty} k \cdot P(X=k) = \sum_{k=0}^{\infty} k \cdot P(X=k) = E[X]
	\end{align*}
	Grupując wyrazy pionowo (kolumnami), widzimy, że $P(X=1)$ występuje raz, $P(X=2)$ dwa razy, itd., co prowadzi do wzoru na wartość oczekiwaną.
\end{proof}

\begin{twierdzenie}[Charakteryzacja stanów powracających i chwilowych]
	Dla dowolnego stanu $j \in S$ w jednorodnym łańcuchu Markowa, następujące charakteryzacje są równoważne:

	\begin{enumerate}[label=\alph*)]
		\item \textbf{Dla stanów powracających:}
		      \begin{enumerate}[label=(\roman*)]
			      \item Stan $j$ jest powracający (tzn. $f_{jj}=1$).
			      \item Proces, startując z $j$, powróci do $j$ nieskończenie wiele razy z prawdopodobieństwem 1.
			            \begin{equation*}
				            P(N_j = \infty \mid X_0 = j) = 1
			            \end{equation*}
			      \item Oczekiwana liczba powrotów do stanu $j$ (startując z $j$), równa sumie prawdopodobieństw powrotu w $n$ krokach, jest nieskończona.
			            \begin{equation*}
				            E[N_j \mid X_0=j] = \sum_{n=1}^{\infty} p_n(j, j) = \infty
			            \end{equation*}
		      \end{enumerate}

		\item \textbf{Dla stanów chwilowych:}
		      \begin{enumerate}[label=(\roman*)]
			      \item Stan $j$ jest chwilowy (tzn. $f_{jj}<1$).
			      \item Proces, startując z $j$, powróci do $j$ skończoną liczbę razy z prawdopodobieństwem 1.
			            \begin{equation*}
				            P(N_j < \infty \mid X_0 = j) = 1
			            \end{equation*}
			      \item Oczekiwana liczba powrotów do stanu $j$ (startując z $j$), równa sumie prawdopodobieństw powrotu w $n$ krokach, jest skończona.
			            \begin{equation*}
				            E[N_j \mid X_0=j] = \sum_{n=1}^{\infty} p_n(j, j) < \infty
			            \end{equation*}
		      \end{enumerate}
	\end{enumerate}
\end{twierdzenie}

\begin{proof}
	Dowód podzielimy na dwie części, odpowiadające dwóm równoważnościom dla każdego typu stanu.

	\textbf{Równoważność 1: (i) $\Leftrightarrow$ (ii)} (Liczba powrotów)

	Ta część dowodzi, że stan jest powracający wtedy i tylko wtedy, gdy liczba powrotów do niego jest nieskończona z prawdopodobieństwem 1.

	\underline{Dowód dla $j$ powracającego (a) i chwilowego (b):}
	Zdarzenie $\{N_j = \infty\}$ (nieskończona liczba powrotów) jest równe przecięciu zdarzeń $A_k = \{N_j \ge k\}$ (co najmniej $k$ powrotów) dla $k=1, 2, \dots$. Ponieważ $A_1 \supset A_2 \supset \dots$ jest \textbf{ciągiem zstępującym}, z \textbf{ciągłości miary prawdopodobieństwa} mamy:
	\begin{equation*}
		P(N_j = \infty \mid X_0 = j) = P\left(\bigcap_{k=1}^{\infty} A_k \mid X_0=j\right) = \lim_{k \to \infty} P(A_k \mid X_0=j) = \lim_{k \to \infty} P(N_j \ge k \mid X_0 = j)
	\end{equation*}
	Korzystając z wzoru $P(N_j \ge k \mid X_0 = j) = f_{jj}^k$, otrzymujemy kluczową zależność:
	\begin{equation*}
		P(N_j = \infty \mid X_0 = j) = \lim_{k \to \infty} f_{jj}^k
	\end{equation*}
	Teraz dowód staje się trywialny:
	\begin{itemize}
		\item Równoważność dla stanu powracającego: $f_{jj}=1 \Leftrightarrow \lim_{k \to \infty} f_{jj}^k = 1 \Leftrightarrow P(N_j = \infty \mid X_0 = j) = 1$.
		\item Równoważność dla stanu chwilowego: $f_{jj}<1 \Leftrightarrow \lim_{k \to \infty} f_{jj}^k = 0 \Leftrightarrow P(N_j = \infty \mid X_0 = j) = 0$.
	\end{itemize}

	\vspace{1em}
	\textbf{Równoważność 2: (i) $\Leftrightarrow$ (iii)} (Kryterium sumy)

	Ta część dowodzi, że stan jest powracający wtedy i tylko wtedy, gdy suma $\sum p_n(j,j)$ jest nieskończona. Kluczowe jest wyprowadzenie tożsamości dla wartości oczekiwanej liczby powrotów $E[N_j \mid X_0=j]$ na dwa sposoby.

	\textbf{Sposób 1: Użycie funkcji wskaźnikowych.}
	Całkowitą liczbę trafień $N_j$ definiuje się jako sumę funkcji indykatorowych dla każdego kroku czasowego:
	\begin{equation*}
		N_j = \sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=j\}}
	\end{equation*}
	gdzie $\mathbf{1}_{\{X_n=j\}}$ to zmienna losowa, która przyjmuje wartość 1, jeśli proces jest w stanie $j$ w chwili $n$, i 0 w przeciwnym przypadku.

	Korzystając z \textbf{liniowości wartości oczekiwanej}, która pozwala zamienić wartość oczekiwaną sumy na sumę wartości oczekiwanych (nawet dla nieskończonej liczby nieujemnych zmiennych losowych), otrzymujemy:
	\begin{equation*}
		E[N_j \mid X_0=j] = E\left[\sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=j\}} \mid X_0=j\right] = \sum_{n=1}^{\infty} E[\mathbf{1}_{\{X_n=j\}} \mid X_0=j]
	\end{equation*}
	Wartość oczekiwana funkcji indykatorowej jest równa prawdopodobieństwu zdarzenia, które ona wskazuje. Zatem:
	\begin{equation*}
		E[\mathbf{1}_{\{X_n=j\}} \mid X_0=j] = P(X_n=j \mid X_0=j) = p_n(j,j)
	\end{equation*}
	Podstawiając to z powrotem, otrzymujemy pierwszą postać wartości oczekiwanej:
	\begin{equation*}
		E[N_j \mid X_0=j] = \sum_{n=1}^{\infty} p_n(j,j)
	\end{equation*}

	\textbf{Sposób 2: Użycie lematu o wartości oczekiwanej.}
	Zgodnie z Lematem 4.9, wartość oczekiwaną zmiennej losowej o wartościach w $\mathbb{N}_0$ można wyrazić jako sumę prawdopodobieństw postaci $P(X \ge k)$ dla $k \ge 1$:
	\begin{equation*}
		E[N_j \mid X_0=j] = \sum_{k=1}^{\infty} P(N_j \ge k \mid X_0=j)
	\end{equation*}

	\textbf{Połączenie tożsamości}
	Łącząc oba wzory na $E[N_j \mid X_0=j]$ i podstawiając znaną nam zależność $P(N_j \ge k \mid X_0 = j) = f_{jj}^k$ (z Obserwacji 4.5, dla $i=j$), otrzymujemy kluczową równość:
	\begin{equation*}
		\sum_{n=1}^{\infty} p_n(j,j) = \sum_{k=1}^{\infty} f_{jj}^k
	\end{equation*}
	Prawa strona to szereg geometryczny. Zbieżność obu szeregów jest zatem identyczna i zależy od $f_{jj}$:
	\begin{itemize}
		\item $f_{jj}=1$ (stan powracający) $\Leftrightarrow$ szereg jest rozbieżny, tj. $\sum_{n=1}^{\infty} p_n(j,j) = \infty$.
		\item $f_{jj}<1$ (stan chwilowy) $\Leftrightarrow$ szereg jest zbieżny, tj. $\sum_{n=1}^{\infty} p_n(j,j) < \infty$.
	\end{itemize}
	To dowodzi równoważności (i) $\Leftrightarrow$ (iii). Przy okazji udowodniliśmy też równoważność (ii) $\Leftrightarrow$ (iii), ponieważ (i) jest równoważne obu warunkom.
\end{proof}

\begin{wniosek}[Wzór na prawdopodobieństwo powrotu]
	Z dowodu dla stanów chwilowych (Równoważność 2) otrzymaliśmy jawny wzór na sumę:
	\begin{equation*}
		\sum_{n=1}^{\infty} p_n(j, j) = \frac{f_{jj}}{1 - f_{jj}}
	\end{equation*}
	Przekształcając go, możemy wyrazić prawdopodobieństwo powrotu $f_{jj}$ za pomocą sumy prawdopodobieństw przejścia:
	\begin{equation*}
		f_{jj} = \frac{\sum_{n=1}^{\infty} p_n(j, j)}{1 + \sum_{n=1}^{\infty} p_n(j, j)}
	\end{equation*}
	Wzór ten potwierdza, że $f_{jj}=1$ wtedy i tylko wtedy, gdy suma $\sum p_n(j,j)$ jest nieskończona.
\end{wniosek}

\section{Osiągalność, komunikacja i klasy stanów}

Aby móc w pełni scharakteryzować i sklasyfikować stany łańcucha Markowa, musimy wprowadzić pojęcie osiągalności i komunikacji między nimi.

\begin{definition}[Osiągalność]
	Niech $i, j \in S$. Mówimy, że stan $j$ jest \textbf{osiągalny} ze stanu $i$, co oznaczamy jako $i \to j$, jeśli istnieje $n \in \mathbb{N}_0$ takie, że $p_n(i, j) > 0$.
	\begin{equation*}
		i \to j \iff \exists n \in \mathbb{N}_0 : p_n(i, j) > 0
	\end{equation*}
	Oznacza to, że istnieje niezerowe prawdopodobieństwo dotarcia ze stanu $i$ do stanu $j$ w pewnej (skończonej) liczbie kroków.

	\vspace{1em}
	\textbf{Uwaga:} Relacja osiągalności nie jest symetryczna. Jeśli $j$ jest osiągalny z $i$, nie oznacza to, że $i$ musi być osiągalny z $j$.
\end{definition}

\begin{definition}[Komunikacja]
	Mówimy, że stany $i$ i $j$ \textbf{komunikują się ze sobą}, co oznaczamy jako $i \leftrightarrow j$, jeśli stan $j$ jest osiągalny z $i$ oraz stan $i$ jest osiągalny z $j$.
	\begin{equation*}
		i \leftrightarrow j \iff (i \to j) \land (j \to i)
	\end{equation*}
	Intuicyjnie oznacza to, że będąc w stanie $i$, możemy dotrzeć do stanu $j$, a będąc w stanie $j$, możemy wrócić do stanu $i$. Niekoniecznie w tej samej liczbie kroków.
\end{definition}

\begin{twierdzenie}
	Relacja komunikacji ($\leftrightarrow$) jest relacją równoważności na zbiorze stanów $S$.
\end{twierdzenie}

\begin{proof}
	Musimy udowodnić trzy własności: zwrotność, symetrię i przechodniość.

	\begin{enumerate}[label=\alph*)]
		\item \textbf{Zwrotność ($i \leftrightarrow i$):}
		      Zgodnie z konwencją, macierz przejścia w 0 krokach $P^0$ jest macierzą identycznościową, co oznacza, że $p_0(i,i) = 1 > 0$. Zatem $i \to i$, co implikuje $i \leftrightarrow i$.

		\item \textbf{Symetria ($i \leftrightarrow j \implies j \leftrightarrow i$):}
		      Ta własność wynika wprost z definicji. Jeśli $i \leftrightarrow j$, to z definicji $(i \to j) \land (j \to i)$. To jest to samo co $(j \to i) \land (i \to j)$, co z kolei oznacza, że $j \leftrightarrow i$.

		\item \textbf{Przechodniość ($i \leftrightarrow j \land j \leftrightarrow k \implies i \leftrightarrow k$):}
		      Załóżmy, że $i \leftrightarrow j$ oraz $j \leftrightarrow k$. Musimy pokazać, że $i \leftrightarrow k$.

		      Z założenia $i \to j$, więc istnieje $n \in \mathbb{N}_0$ takie, że $p_n(i, j) > 0$.
		      Z założenia $j \to k$, więc istnieje $m \in \mathbb{N}_0$ takie, że $p_m(j, k) > 0$.

		      Z równań Chapmana-Kołmogorowa:
		      \begin{equation*}
			      p_{n+m}(i, k) = \sum_{l \in S} p_n(i, l) p_m(l, k) \ge p_n(i,j) p_m(j,k) > 0
		      \end{equation*}
		      co dowodzi, że $i \to k$.

		      Analogicznie dowodzimy, że $k \to i$. Ponieważ pokazaliśmy, że $i \to k$ i $k \to i$, to z definicji $i \leftrightarrow k$.
	\end{enumerate}
	Co kończy dowód.
\end{proof}

\begin{definition}[Klasy komunikujące się]
	Ponieważ relacja $\leftrightarrow$ jest relacją równoważności, dzieli ona zbiór stanów $S$ na rozłączne podzbiory, zwane \textbf{klasami równoważności} lub \textbf{klasami komunikującymi się}. Dwa stany należą do tej samej klasy, jeśli komunikują się ze sobą.
\end{definition}

\section{Łańcuchy nieprzywiedlne}

\begin{definition}[Łańcuch nieprzywiedlny]
	Jednorodny łańcuch Markowa nazywamy \textbf{nieprzywiedlnym} (lub \textbf{nieredukowalnym}), jeśli tworzy on tylko jedną klasę komunikującą się. Oznacza to, że wszystkie stany komunikują się ze sobą.
	\begin{equation*}
		\forall i, j \in S \quad i \leftrightarrow j
	\end{equation*}
	Jeśli łańcuch nie jest nieprzywiedlny (tzn. ma więcej niż jedną klasę komunikującą się), nazywamy go \textbf{przywiedlnym} (lub \textbf{redukowalnym}).
\end{definition}

\begin{example}[Łańcuch nieprzywiedlny – cykl]
	Rozważmy łańcuch o trzech stanach $S=\{1, 2, 3\}$, w którym proces cyklicznie przechodzi między stanami: $1 \to 2$, $2 \to 3$ i $3 \to 1$.
	Macierz przejścia ma postać:
	\begin{equation*}
		P =
		\begin{bmatrix}
			0 & 1 & 0 \\
			0 & 0 & 1 \\
			1 & 0 & 0
		\end{bmatrix}
	\end{equation*}
	Graf stanów wygląda następująco:
	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=2.5cm, state/.style={circle, draw, minimum size=0.8cm}]
			\node[state] (1) at (90:1.5cm) {1};
			\node[state] (3) at (210:1.5cm) {3};
			\node[state] (2) at (330:1.5cm) {2};

			\path (1) edge [bend left=20] node[above right] {1} (2);
			\path (2) edge [bend left=20] node[below] {1} (3);
			\path (3) edge [bend left=20] node[above left] {1} (1);
		\end{tikzpicture}
	\end{center}
	W tym łańcuchu każdy stan jest osiągalny z każdego innego. Na przykład, ze stanu 1 możemy dotrzeć do 3 w dwóch krokach ($1 \to 2 \to 3$). Ze stanu 3 do 2 w dwóch krokach ($3 \to 1 \to 2$). Ponieważ wszystkie stany komunikują się ze sobą (tworzą jedną klasę), łańcuch jest \textbf{nieprzywiedlny}.
\end{example}

\begin{example}[Łańcuch przywiedlny]
	Rozważmy łańcuch o czterech stanach $S=\{1, 2, 3, 4\}$, w którym dozwolone są tylko przejścia $1 \leftrightarrow 2$ oraz $3 \leftrightarrow 4$.
	Macierz przejścia może wyglądać tak:
	\begin{equation*}
		P =
		\begin{bmatrix}
			0 & 1 & 0 & 0 \\
			1 & 0 & 0 & 0 \\
			0 & 0 & 0 & 1 \\
			0 & 0 & 1 & 0
		\end{bmatrix}
	\end{equation*}
	Graf stanów składa się z dwóch niepołączonych ze sobą komponentów:
	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, auto, semithick, node distance=3cm, state/.style={circle, draw, minimum size=0.8cm}]
			\node[state] (1) {1};
			\node[state] (2) [right=of 1] {2};

			\node[state] (3) [right=of 2, node distance=4cm] {3};
			\node[state] (4) [right=of 3] {4};

			\path (1) edge [bend left]  node {1} (2);
			\path (2) edge [bend left]  node {1} (1);

			\path (3) edge [bend left]  node {1} (4);
			\path (4) edge [bend left]  node {1} (3);
		\end{tikzpicture}
	\end{center}
	W tym przypadku zbiór stanów $S$ dzieli się na dwie klasy komunikujące się: $C_1 = \{1, 2\}$ oraz $C_2 = \{3, 4\}$. Nie jest możliwe przejście ze stanu z klasy $C_1$ do stanu z klasy $C_2$ (np. $1 \not\to 3$). Ponieważ istnieje więcej niż jedna klasa, łańcuch jest \textbf{przywiedlny}.
\end{example}

\begin{lemat}
	Niech $i, j \in S$ będą stanami łańcucha Markowa. Jeżeli stan $i$ jest powracający ($f_{ii}=1$) oraz stan $j$ jest osiągalny ze stanu $i$ ($i \to j$), to stan $j$ również jest powracający ($f_{jj}=1$).

	Innymi słowy, z stanu powracającego nie da się przejść do stanu chwilowego.
\end{lemat}
\begin{proof}
	Dowód składa się z dwóch części. Najpierw pokażemy, że jeśli stan $i$ jest powracający i $i \to j$, to musi zachodzić również $j \to i$. Następnie, korzystając z tego faktu, udowodnimy, że stan $j$ jest powracający.

	\textbf{Krok 1: Dowód, że $j \to i$}

	Dowód nie wprost. Załóżmy, że $j \not\to i$. Oznacza to, że po osiągnięciu stanu $j$ powrót do $i$ jest niemożliwy, czyli $P(T_i = \infty \mid X_0=j) = 1$.

	Z założenia $i \to j$ wiemy, że istnieje przynajmniej jedna ścieżka z $i$ do $j$ o dodatnim prawdopodobieństwie. Rozważmy najkrótszą z takich ścieżek. Nie może ona zawierać $i$ jako stanu pośredniego (gdyby tak było, istniałaby jeszcze krótsza ścieżka do $j$). Zatem istnieje dodatnie prawdopodobieństwo dotarcia do $j$ bez wcześniejszego powrotu do $i$. Oznaczmy to zdarzenie $A = \{T_j < T_i\}$. Mamy $P(A \mid X_0=i) > 0$.

	Prawdopodobieństwo, że proces nigdy nie powróci do $i$ (startując z $i$), możemy oszacować następująco:
	\[
		P(T_i=\infty \mid X_0=i) \;\ge\; P(A \cap \{ \text{po trafieniu do j nigdy nie wracamy do i} \} \mid X_0=i)
	\]
	Używając silnej własności Markowa, można to formalnie zapisać jako $P(T_i=\infty \mid X_0=i) \ge P(A \mid X_0=i) \cdot P(T_i=\infty \mid X_{T_j}=j)$. Ponieważ $P(A \mid X_0=i) > 0$ oraz z założenia $P(T_i=\infty \mid X_0=j)=1$, otrzymujemy $P(T_i=\infty \mid X_0=i) > 0$. To oznacza, że $f_{ii} < 1$, co jest sprzeczne z założeniem, że $i$ jest stanem powracającym.

	Wniosek: założenie $j \not\to i$ musi być fałszywe, zatem $j \to i$.

	\textbf{Krok 2: Dowód, że $j$ jest powracający}

	Wykazaliśmy, że skoro $i$ jest powracający i $i \to j$, to musi zachodzić $j \to i$. Istnieją zatem liczby $k, m \ge 1$ takie, że $p_k(i,j) > 0$ i $p_m(j,i) > 0$.

	Rozważmy prawdopodobieństwo powrotu do stanu $j$ w $m+n+k$ krokach. Możemy je oszacować od dołu, biorąc pod uwagę tylko ścieżki prowadzące z $j$ do $i$ w $m$ krokach, następnie z $i$ do $i$ w $n$ krokach, i z powrotem z $i$ do $j$ w $k$ krokach.
	\[
		p_{m+n+k}(j,j) \ge p_m(j,i) p_n(i,i) p_k(i,j)
	\]
	Sumując obie strony po $n \ge 1$:
	\[
		\sum_{n=1}^{\infty} p_{m+n+k}(j,j) \ge p_m(j,i) p_k(i,j) \sum_{n=1}^{\infty} p_n(i,i)
	\]
	Ponieważ stan $i$ jest powracający, suma $\sum_{n=1}^{\infty} p_n(i,i)$ jest nieskończona. Iloczyn $p_m(j,i) p_k(i,j)$ jest stałą dodatnią, więc prawa strona nierówności jest nieskończona.
	\[
		\sum_{n=1}^{\infty} p_{m+n+k}(j,j) = \infty
	\]
	Suma po lewej stronie jest ogonem szeregu $\sum_{l=1}^{\infty} p_l(j,j)$. Skoro ogon szeregu o wyrazach nieujemnych jest nieskończony, to cały szereg również musi być nieskończony.
	\[
		\sum_{l=1}^{\infty} p_l(j,j) = \infty
	\]
	To na mocy Twierdzenia 4.10 dowodzi, że stan $j$ jest powracający.
\end{proof}

\subsection*{Wnioski Końcowe: Klasyfikacja Stanów}

Powyższe rozważania prowadzą do fundamentalnych wniosków na temat struktury łańcuchów Markowa.

\begin{wniosek}
	\textbf{Bycie stanem powracającym lub chwilowym to własność klasy.} Jeżeli dwa stany $i$ i $j$ komunikują się ze sobą ($i \leftrightarrow j$), to są one tego samego typu: albo oba są powracające, albo oba są chwilowe. Dlatego możemy mówić o \textbf{klasach powracających} i \textbf{klasach chwilowych}.
\end{wniosek}

\begin{wniosek}
	\textbf{Łańcuchy nieprzywiedlne są jednorodne.} Jeżeli łańcuch Markowa jest nieprzywiedlny (wszystkie stany tworzą jedną klasę), to musi być w całości jednego typu:
	\begin{itemize}
		\item albo wszystkie jego stany są powracające (\textbf{łańcuch powracający}),
		\item albo wszystkie jego stany są chwilowe (\textbf{łańcuch chwilowy}).
	\end{itemize}
\end{wniosek}

\begin{wniosek}[Rola skończonej przestrzeni stanów]
	Rozmiar przestrzeni stanów ma kluczowe znaczenie:
	\begin{enumerate}
		\item W łańcuchu o \textbf{skończonej} liczbie stanów nie wszystkie stany mogą być chwilowe -- musi istnieć przynajmniej jedna klasa powracająca.
		\item W konsekwencji, każdy \textbf{nieprzywiedlny łańcuch o skończonej liczbie stanów jest zawsze powracający}.
		\item Łańcuch nieprzywiedlny może być chwilowy tylko wtedy, gdy ma \textbf{nieskończoną} przestrzeń stanów (np. błądzenie losowe w 3D).
	\end{enumerate}
\end{wniosek}

\section{Zachowanie graniczne jednorodnych łańcuchów Markowa}

W poprzednich rozdziałach sklasyfikowaliśmy stany i klasy komunikujące się. Teraz zbadamy, jak jednorodne łańcuchy Markowa (JŁM) zachowują się w długim horyzoncie czasowym, czyli gdy liczba kroków $n$ dąży do nieskończoności. Interesuje nas, czy po wielu krokach proces "stabilizuje się" w pewien określony sposób.

Będziemy rozważać JŁM $(X_n)_{n \in \mathbb{N}_0}$ na skończonej przestrzeni stanów $S = \{1, 2, \dots, N\}$. Wiemy, że rozkład brzegowy procesu w kroku $n$ dany jest wzorem:
$$ [ P(X_n=j) ]_{j \in S} = \alpha P^n $$
gdzie $\alpha$ jest początkowym rozkładem prawdopodobieństwa. Kluczowe pytanie brzmi: \textbf{kiedy i do czego zbiega wektor rozkładu $\alpha P^n$, gdy $n \to \infty$?}

\subsection{Rozkład stacjonarny}

Szczególną rolę w analizie zachowania granicznego odgrywają rozkłady, które są niezmiennicze względem dynamiki łańcucha.

\begin{definition}[Rozkład stacjonarny]
	Rozkład prawdopodobieństwa $\pi$ na przestrzeni stanów $S$ (reprezentowany jako wektor-wiersz) nazywamy \textbf{rozkładem stacjonarnym} łańcucha Markowa o macierzy przejścia $P$, jeżeli spełnia on równanie:
	$$ \pi P = \pi $$
\end{definition}

Innymi słowy, rozkład stacjonarny to taki rozkład, że jeśli zostanie wybrany jako rozkład początkowy ($X_0 \sim \pi$), to rozkład procesu w każdym kolejnym kroku czasu pozostanie taki sam.

\begin{obserwacja}
	Jeśli $\pi$ jest rozkładem stacjonarnym, to dla dowolnego $n \in \mathbb{N}$ zachodzi:
	$$ \pi P^n = \pi $$
	\begin{proof}
		Dowód jest natychmiastowy przez indukcję. Baza ($n=1$) wynika z definicji. Krok indukcyjny: załóżmy, że $\pi P^k = \pi$ dla pewnego $k \ge 1$. Wówczas
		$$ \pi P^{k+1} = (\pi P^k) P = \pi P = \pi $$
		co kończy dowód.
	\end{proof}
\end{obserwacja}

Zauważmy, że równanie $\pi P = \pi$ można przepisać jako $\pi(P - I) = \mathbf{0}$, gdzie $I$ jest macierzą jednostkową. Z perspektywy algebry liniowej oznacza to, że rozkład stacjonarny $\pi$ jest \textbf{lewostronnym wektorem własnym} macierzy $P$ odpowiadającym \textbf{wartości własnej $\lambda=1$}.

\begin{lemat}
	Dla dowolnej macierzy stochastycznej $P$, liczba $\lambda=1$ jest jej wartością własną.
	\begin{proof}
		Prawostronnym wektorem własnym dla $\lambda=1$ jest wektor $\mathbf{1} = [1, 1, \dots, 1]^T$. Ponieważ wiersze macierzy stochastycznej sumują się do 1, mamy:
		$$ (P \mathbf{1})_i = \sum_{j=1}^N P_{ij} \cdot 1 = 1 = (\mathbf{1})_i $$
		Zatem $P\mathbf{1} = \mathbf{1}$, co dowodzi, że $1$ jest wartością własną. Skoro istnieje prawostronny wektor własny, to musi również istnieć odpowiadający mu lewostronny wektor własny.
	\end{proof}
\end{lemat}

\begin{example}
	Czy dla łańcucha o macierzy przejścia $P = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$ istnieje rozkład stacjonarny?
	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, shorten >=1pt, auto, node distance=2.5cm, semithick]
			\node[state] (1) {$1$};
			\node[state] (2) [right of=1] {$2$};

			\path (1) edge [loop above] node {$0$} (1)
			edge [bend left]  node {$1$} (2);
			\path (2) edge [loop above] node {$0$} (2)
			edge [bend left]  node {$1$} (1);
		\end{tikzpicture}
	\end{center}
	Szukamy wektora $\pi = [\pi_1, \pi_2]$ takiego, że $\pi_1 + \pi_2 = 1$, $\pi_1, \pi_2 \ge 0$ oraz $\pi P = \pi$.
	$$ [\pi_1, \pi_2] \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} = [\pi_1, \pi_2] $$
	Otrzymujemy układ równań:
	$$ \begin{cases} \pi_2 = \pi_1 \\ \pi_1 = \pi_2 \end{cases} $$
	Wraz z warunkiem normalizacyjnym $\pi_1 + \pi_2 = 1$ daje to jednoznaczne rozwiązanie: $\pi_1 = \pi_2 = 1/2$. Zatem jedynym rozkładem stacjonarnym jest $\pi = [1/2, 1/2]$.
\end{example}

\subsection{Rozkład graniczny i zbieżność}

Idealna sytuacja, do której będziemy dążyć, to taka, w której granica $\lim_{n \to \infty} P(X_n = j)$ istnieje i \textbf{nie zależy od stanu początkowego}.

\begin{definition}[Łańcuch ergodyczny]
	Mówimy, że JŁM jest \textbf{ergodyczny}, jeśli istnieje wektor-wiersz $v$ (będący rozkładem prawdopodobieństwa) taki, że:
	\begin{enumerate}
		\item Granica potęg macierzy przejścia istnieje: $\lim_{n \to \infty} P^n = P^\infty$.
		\item Wszystkie wiersze macierzy granicznej $P^\infty$ są identyczne i równe $v$:
		      $$ P^\infty = \begin{bmatrix}
				      \text{--- } v \text{ ---} \\ \text{--- } v \text{ ---} \\ \vdots \\ \text{--- } v \text{ ---} \end{bmatrix} $$
	\end{enumerate}
	Wektor $v$ nazywamy \textbf{rozkładem granicznym} łańcucha.
\end{definition}

\begin{twierdzenie}[Konsekwencje ergodyczności]
	Jeśli łańcuch Markowa jest ergodyczny z rozkładem granicznym $v$, to:
	\begin{enumerate}
		\item \textbf{Następuje stabilizacja rozkładów warunkowych:} Prawdopodobieństwo znalezienia się w stanie $j$ po $n$ krokach, startując ze stanu $i$, zbiega do $v_j$ niezależnie od $i$:
		      $$ \lim_{n \to \infty} P(X_n=j | X_0=i) = \lim_{n \to \infty} (P^n)_{ij} = (P^{\infty})_{ij} = v_j \quad \forall i,j \in S $$

		\item \textbf{Następuje stabilizacja rozkładów bezwarunkowych:} Prawdopodobieństwo znalezienia się w stanie $j$ po $n$ krokach zbiega do $v_j$ niezależnie od początkowego rozkładu $\alpha$:
		      $$ \lim_{n \to \infty} P(X_n=j) = \lim_{n \to \infty} (\alpha P^n)_j = (\alpha P^{\infty})_j = \sum_{i=1}^N \alpha_i (P^{\infty})_{ij} = \sum_{i=1}^N \alpha_i v_j = v_j \sum_{i=1}^N \alpha_i = v_j $$
		      Ta własność nazywana jest \textbf{zapominaniem rozkładu początkowego}.
	\end{enumerate}
\end{twierdzenie}

\begin{obserwacja}
	Porównajmy pojęcia rozkładu stacjonarnego i granicznego:
	\begin{itemize}
		\item \textbf{Rozkład stacjonarny} dla JŁM na skończonej przestrzeni stanów \textbf{zawsze istnieje}, ale może nie być unikalny. Jest to pojęcie czysto algebraiczne.
		\item \textbf{Rozkład graniczny} \textbf{nie zawsze istnieje}. Jeśli jednak istnieje, to jest \textbf{unikalny}.
	\end{itemize}
\end{obserwacja}

\begin{twierdzenie}[Ergodyczność a rozkład stacjonarny]
	Jeśli JŁM jest ergodyczny z rozkładem granicznym $v$, to $v$ jest jedynym rozkładem stacjonarnym tego łańcucha.
\end{twierdzenie}

\begin{twierdzenie}[Twierdzenie ergodyczne dla JŁM]
	Dla łańcucha ergodycznego z rozkładem granicznym $v$, wektor $v$ ma interpretację jako średnia proporcja czasu spędzonego przez łańcuch w każdym ze stanów w długim okresie:
	$$ v_j = \lim_{n \to \infty} E\left[\frac{1}{n} \sum_{k=0}^{n-1} \mathbf{1}_{\{X_k=j\}} \middle| X_0=i\right] \quad \text{dla dowolnego } i \in S $$
	\begin{proof}[Szkic dowodu]
		Korzystając z liniowości wartości oczekiwanej, mamy:
		$$ E\left[\frac{1}{n} \sum_{k=0}^{n-1} \mathbf{1}_{\{X_k=j\}} \middle| X_0=i\right] = \frac{1}{n} \sum_{k=0}^{n-1} E\left[\mathbf{1}_{\{X_k=j\}} \middle| X_0=i\right] = \frac{1}{n} \sum_{k=0}^{n-1} P(X_k=j | X_0=i) = \frac{1}{n} \sum_{k=0}^{n-1} (P^k)_{ij} $$
		Z założenia ergodyczności wiemy, że ciąg $(P^k)_{ij}$ zbiega do $v_j$ gdy $k \to \infty$. Z lematu Cesàro, jeśli ciąg $a_k$ zbiega do granicy $g$, to ciąg jego średnich arytmetycznych $\frac{1}{n}\sum_{k=0}^{n-1} a_k$ również zbiega do $g$. Stosując ten fakt do ciągu $(P^k)_{ij}$, otrzymujemy:
		$$ \lim_{n \to \infty} \frac{1}{n} \sum_{k=0}^{n-1} (P^k)_{ij} = \lim_{k \to \infty} (P^k)_{ij} = v_j $$
	\end{proof}
\end{twierdzenie}

\subsection{Struktura klasowa a zbieżność}

Warunek ergodyczności (identyczne wiersze w $P^\infty$) nie zawsze jest spełniony. Dzieje się tak w szczególności, gdy łańcuch posiada więcej niż jedną klasę powracającą.

Podzielmy zbiór stanów $S$ na rozłączne podzbiory:
\begin{itemize}
	\item \textbf{Klasy powracające (recurrent)} $R_1, R_2, \dots, R_r$. Ze stanu w klasie powracającej można przejść tylko do stanów w tej samej klasie.
	\item \textbf{Zbiór stanów chwilowych (transient)} $A$. Ze stanu chwilowego można ostatecznie przejść do którejś z klas powracających, ale po opuszczeniu zbioru $A$ nie ma już do niego powrotu.
\end{itemize}
Możemy tak przenumerować stany, aby macierz przejścia $P$ przybrała postać blokową:
$$ P = \left( \begin{array}{cccc|c}
			P_1                    &     &        &     &            \\
			                       & P_2 &        &     & \mathbf{0} \\
			                       &     & \ddots &     &            \\
			                       &     &        & P_r &            \\
			\hline
			\multicolumn{4}{c|}{C} & Q
		\end{array} \right) $$
gdzie:
\begin{itemize}
	\item $P_i$ jest macierzą stochastyczną opisującą dynamikę wewnątrz $i$-tej klasy powracającej.
	\item $Q$ opisuje przejścia między stanami chwilowymi. Sumy jej wierszy mogą być mniejsze od 1 (jest to macierz substochastyczna), co oznacza możliwość "ucieczki" ze zbioru $A$.
	\item $C$ opisuje przejścia ze stanów chwilowych do klas powracających.
	\item Blok $\mathbf{0}$ w prawym górnym rogu oznacza, że ze stanu powracającego nie da się przejść do stanu chwilowego. Zera poza diagonalą blokową $P_1, \dots, P_r$ oznaczają brak przejść między klasami powracającymi.
\end{itemize}

\begin{twierdzenie}[Granica dla macierzy z klasami]
	Potęgi macierzy $P$ o powyższej strukturze blokowej mają postać:
	$$ P^n = \left( \begin{array}{c|c}
				\mathbf{P_R}^n & \mathbf{0} \\
				\hline
				C_n            & Q^n
			\end{array} \right) \quad \text{gdzie } \mathbf{P_R}^n = \begin{pmatrix} P_1^n & & \\ & \ddots & \\ & & P_r^n \end{pmatrix} $$
	Dla stanów chwilowych $j \in A$ zachodzi $\lim_{n \to \infty} P(X_n=j | X_0=i) = 0$ dla dowolnego $i \in S$. Oznacza to, że $\lim_{n \to \infty} Q^n = \mathbf{0}$ (macierz zerowa). Wówczas granica $P^\infty$ (jeśli istnieje) ma postać:
	$$ P^\infty = \left( \begin{array}{c|c}
				\mathbf{P_R}^\infty & \mathbf{0} \\
				\hline
				C_\infty            & \mathbf{0}
			\end{array} \right) $$
\end{twierdzenie}
Jeżeli mamy więcej niż jedną klasę powracającą ($r > 1$), to wiersze $P^\infty$ odpowiadające stanom z różnych klas będą różne. Oznacza to, że zachowanie graniczne zależy od tego, w której klasie startujemy, a łańcuch nie jest ergodyczny.

\subsection{Warunki algebraiczne zbieżności macierzy}

Kiedy ogólnie istnieje granica $\lim_{n \to \infty} A^n$ dla macierzy $A \in \mathbb{R}^{N \times N}$? Odpowiedź leży w jej postaci Jordana. Każdą macierz $A$ można przedstawić jako $A = QJQ^{-1}$, gdzie $J$ jest macierzą blokowo-diagonalną złożoną z klatek Jordana. Wówczas $A^n = QJ^nQ^{-1}$, więc granica $\lim_{n \to \infty} A^n$ istnieje wtedy i tylko wtedy, gdy istnieje granica $\lim_{n \to \infty} J^n$.

\begin{twierdzenie}[Warunek zbieżności $A^n$]
	Granica $\lim_{n \to \infty} A^n$ istnieje wtedy i tylko wtedy, gdy dla każdej wartości własnej $\lambda$ macierzy $A$ zachodzi jeden z dwóch warunków:
	\begin{enumerate}
		\item $|\lambda| < 1$,
		\item $\lambda = 1$, a wszystkie klatki Jordana odpowiadające tej wartości własnej są wymiaru $1 \times 1$.
	\end{enumerate}
\end{twierdzenie}

Warunek, by wszystkie klatki Jordana dla $\lambda=1$ były wymiaru $1 \times 1$, jest równoważny temu, by \textbf{krotność algebraiczna} wartości własnej $\lambda=1$ była równa jej \textbf{krotności geometrycznej}.

\begin{definition}
	Dla wartości własnej $\lambda$:
	\begin{itemize}
		\item \textbf{Krotność algebraiczna} $\text{alg. mult.}(\lambda)$ to krotność $\lambda$ jako pierwiastka wielomianu charakterystycznego $\det(A-\lambda I)$.
		\item \textbf{Krotność geometryczna} $\text{geom. mult.}(\lambda)$ to wymiar przestrzeni własnej $\text{dim} \, \ker(A-\lambda I)$.
	\end{itemize}
	Zawsze zachodzi nierówność $1 \le \text{geom. mult.}(\lambda) \le \text{alg. mult.}(\lambda)$. Równość zachodzi wtedy i tylko wtedy, gdy wszystkie klatki Jordana dla $\lambda$ są wymiaru $1 \times 1$.
\end{definition}

\begin{twierdzenie}[Twierdzenie Perrona-Frobeniusa dla macierzy stochastycznych]
	Jeśli $P$ jest macierzą stochastyczną, to jej promień spektralny $\rho(P) = \max \{ |\lambda| : \lambda \in \sigma(P) \}$ jest równy 1.
	\begin{proof}
		Wiemy, że $1$ jest wartością własną $P$, więc $\rho(P) \ge 1$. Pokażemy, że $\rho(P) \le 1$.
		Przypuśćmy nie wprost, że istnieje wartość własna $\lambda \in \mathbb{C}$ taka, że $|\lambda|>1$ oraz odpowiadający jej prawostronny wektor własny $x \in \mathbb{C}^N$, czyli $Px = \lambda x$.
		Niech $m \in \{1, \dots, N\}$ będzie indeksem współrzędnej $x$ o maksymalnym module, tj. $|x_m| = \max_{j} |x_j| > 0$.
		Rozważmy $m$-tą współrzędną iloczynu $Px$:
		$$ |(Px)_m| = \left| \sum_{j=1}^N P_{mj} x_j \right| $$
		Z nierówności trójkąta i własności macierzy stochastycznej ($\sum_j P_{mj} = 1$, $P_{mj} \ge 0$):
		$$ \left| \sum_{j=1}^N P_{mj} x_j \right| \le \sum_{j=1}^N |P_{mj} x_j| = \sum_{j=1}^N P_{mj} |x_j| \le \sum_{j=1}^N P_{mj} |x_m| = |x_m| \sum_{j=1}^N P_{mj} = |x_m| $$
		Z drugiej strony, z faktu, że $x$ jest wektorem własnym:
		$$ |(Px)_m| = |\lambda x_m| = |\lambda| \cdot |x_m| $$
		Otrzymujemy sprzeczność:
		$$ |\lambda| \cdot |x_m| \le |x_m| $$
		Ponieważ $|x_m| > 0$, musiałoby być $|\lambda| \le 1$, co jest sprzeczne z naszym założeniem, że $|\lambda| > 1$. Zatem promień spektralny musi być równy 1.
	\end{proof}
\end{twierdzenie}

\begin{obserwacja}[Znaczenie wartości własnych na okręgu jednostkowym]
	Powyższe twierdzenie gwarantuje jedynie, że nie istnieją wartości własne o module większym niż 1. Nie wyklucza ono jednak istnienia innych wartości własnych (poza $\lambda=1$) o module równym 1, na przykład $\lambda=-1$ lub wartości zespolonych.

	Istnienie takich wartości własnych jest związane z \textbf{cyklicznością} łańcucha Markowa. Jeśli $\lambda=-1$ jest wartością własną, łańcuch może wykazywać zachowanie okresowe (np. oscylować między dwoma zbiorami stanów), co uniemożliwia zbieżność ciągu macierzy $P^n$ do jednej, stałej macierzy granicznej.

	\begin{example}
		Rozważmy macierz $P = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$. Jest to macierz stochastyczna. Jej wielomian charakterystyczny to $\det(P-\lambda I) = \lambda^2 - 1 = 0$, więc wartościami własnymi są $\lambda_1=1$ i $\lambda_2=-1$. Obie leżą na okręgu jednostkowym, więc twierdzenie jest spełnione. Jednak potęgi macierzy $P$ nie zbiegają:
		$$ P^2 = I, \quad P^3 = P, \quad P^4 = I, \quad \dots $$
		Ciąg $(P^n)$ oscyluje i nie ma granicy. Aby granica istniała, wartość własna $\lambda=1$ musi być \textbf{dominująca} w tym sensie, że jest jedyną wartością własną o module równym 1 (oraz musi spełniać warunek równości krotności algebraicznej i geometrycznej, jak wspomniano dalej).
	\end{example}

	\begin{obserwacja}[Sztuczka ze śladem]
		Ślad macierzy kwadratowej, $\text{tr}(A)$, jest równy sumie jej wartości własnych (liczonych z krotnościami algebraicznymi). Jest to użyteczna własność przy szybkiej analizie małych macierzy.
	\end{obserwacja}
\end{obserwacja}

\begin{twierdzenie}[Warunek zbieżności dla macierzy stochastycznych]
	Dla macierzy stochastycznej $P$, granica $\lim_{n \to \infty} P^n$ istnieje wtedy i tylko wtedy, gdy $\lambda=1$ jest jedyną wartością własną o module równym 1.
\end{twierdzenie}

\begin{definition}[Dominująca wartość własna]
	Mówimy, że $\lambda=1$ jest dominującą wartością własną macierzy stochastycznej $P$, jeśli dla każdej innej wartości własnej $\tilde{\lambda} \in \sigma(P)$ zachodzi $|\tilde{\lambda}| < 1$.
\end{definition}

Gdy ten warunek jest spełniony, granica istnieje. Dodatkowo, jeśli wartość własna $\lambda=1$ jest \textbf{prosta} (ma krotność algebraiczną równą 1), to łańcuch jest ergodyczny, a macierz graniczna ma postać, w której wszystkie wiersze są identyczne. \subsection{Struktura macierzy granicznej}

Załóżmy, że $\lambda=1$ jest prostą i dominującą wartością własną macierzy stochastycznej $P$. Jak widzieliśmy, granica $P^\infty = \lim_{n \to \infty} P^n$ istnieje. Aby zrozumieć jej strukturę, ponownie wykorzystamy rozkład Jordana $P = Q J Q^{-1}$.

Granicę możemy zapisać jako:
$$ P^\infty = Q \cdot (\lim_{n \to \infty} J^n) \cdot Q^{-1} $$
Ponieważ wszystkie wartości własne w bloku $J'$ mają moduł mniejszy od 1, potęgi tego bloku zbiegają do zera. W związku z tym macierz graniczna potęg $J$ ma bardzo prostą postać — jest to macierz zerowa z wyjątkiem jedynki w lewym górnym rogu:
$$ J^\infty = \lim_{n \to \infty} J^n = \begin{pmatrix} 1 & 0 & \dots & 0 \\ 0 & 0 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & 0 \end{pmatrix} $$
Teraz musimy zrozumieć strukturę macierzy $Q$ i $Q^{-1}$.

\begin{enumerate}
	\item \textbf{Macierz wektorów własnych $Q$:} Jej kolumny to (uogólnione) prawostronne wektory własne macierzy $P$. Ponieważ $\lambda=1$ jest wartością prostą, pierwsza kolumna $Q$ to prawostronny wektor własny dla $\lambda=1$. Dla macierzy stochastycznej jest to wektor złożony z samych jedynek.
	      $$ Q = \begin{bmatrix} | & | & & | \\ \vec{v}_1 & \vec{v}_2 & \dots & \vec{v}_n \\ | & | & & | \end{bmatrix}, \quad \text{gdzie } \vec{v}_1 = \begin{pmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{pmatrix} $$

	\item \textbf{Macierz odwrotna $Q^{-1}$:} Jej wiersze to (uogólnione) lewostronne wektory własne. Pierwszy wiersz $Q^{-1}$ to lewostronny wektor własny dla $\lambda=1$. Po znormalizowaniu tak, aby jego współrzędne sumowały się do 1, jest to dokładnie rozkład stacjonarny $\vec{\pi}$.
	      $$ Q^{-1} = \begin{bmatrix} \text{---} & \vec{u}_1^T & \text{---} \\ \text{---} & \vec{u}_2^T & \text{---} \\ & \vdots & \\ \text{---} & \vec{u}_n^T & \text--- \end{bmatrix}, \quad \text{gdzie } \vec{u}_1^T = \vec{\pi} = (\pi_1, \pi_2, \dots, \pi_n) $$
\end{enumerate}

Mając te trzy macierze, możemy obliczyć iloczyn $P^\infty = Q J^\infty Q^{-1}$. Rozbijmy to na dwa kroki:

\textbf{Krok 1: Obliczenie $Q J^\infty$}
Mnożenie $Q$ z prawej strony przez $J^\infty$ "wybiera" tylko pierwszą kolumnę $Q$ i zeruje pozostałe:
$$ Q J^\infty = \begin{bmatrix} | & | & & | \\ \vec{v}_1 & \vec{v}_2 & \dots & \vec{v}_n \\ | & | & & | \end{bmatrix} \begin{pmatrix} 1 & 0 & \dots & 0 \\ 0 & 0 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & 0 \end{pmatrix} = \begin{bmatrix} | & | & & | \\ \vec{v}_1 & \vec{0} & \dots & \vec{0} \\ | & | & & | \end{bmatrix} $$

\textbf{Krok 2: Obliczenie $(Q J^\infty) Q^{-1}$}
Teraz mnożymy wynik z lewej strony przez $Q^{-1}$. To sprowadza się do iloczynu zewnętrznego pierwszej kolumny z pierwszego wyniku i pierwszego wiersza z $Q^{-1}$:
$$ P^\infty = \begin{bmatrix} | & | & & | \\ \vec{v}_1 & \vec{0} & \dots & \vec{0} \\ | & | & & | \end{bmatrix} \begin{bmatrix} \text{---} & \vec{u}_1^T & \text{---} \\ \text{---} & \vec{u}_2^T & \text{---} \\ & \vdots & \\ \text{---} & \vec{u}_n^T & \text--- \end{bmatrix} = \vec{v}_1 \cdot \vec{u}_1^T $$
Podstawiając konkretne wektory $\vec{v}_1$ i $\vec{u}_1^T = \vec{\pi}$, otrzymujemy ostateczną postać macierzy granicznej:
$$ P^\infty = \begin{pmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{pmatrix} \begin{pmatrix} \pi_1 & \pi_2 & \dots & \pi_n \end{pmatrix} = \begin{pmatrix} \pi_1 & \pi_2 & \dots & \pi_n \\ \pi_1 & \pi_2 & \dots & \pi_n \\ \vdots & \vdots & \ddots & \vdots \\ \pi_1 & \pi_2 & \dots & \pi_n \end{pmatrix} $$
W ten sposób pokazaliśmy, dlaczego macierz graniczna dla ergodycznego łańcucha Markowa składa się z identycznych wierszy, z których każdy jest rozkładem stacjonarnym.


\begin{twierdzenie}
	Niech $(X_n)_n$ będzie łańcuchem Markowa na skończonej przestrzeni stanów $S$ z macierzą przejść $P$. Jeśli wartość własna $\lambda=1$ jest dominująca i prosta w widmie $\sigma(P)$, to:
	\begin{enumerate}
		\item Istnieje rozkład graniczny, tzn. dla dowolnego rozkładu początkowego $\vec{\alpha}$ granica $\lim_{n \to \infty} \vec{\alpha} P^n$ istnieje i jest taka sama.
		\item Istnieje dokładnie jeden rozkład stacjonarny $\vec{\pi}$ (czyli wektor spełniający $\vec{\pi} P = \vec{\pi}$).
		\item Rozkład graniczny jest równy rozkładowi stacjonarnemu.
	\end{enumerate}
\end{twierdzenie}

\begin{lemat}
	Każdy rozkład graniczny jest rozkładem stacjonarnym.
\end{lemat}
\begin{proof}
	Niech $\vec{\nu}$ będzie rozkładem granicznym, czyli $\vec{\nu} = \lim_{n \to \infty} \vec{\alpha} P^n$ dla pewnego początkowego $\vec{\alpha}$. Wtedy:
	$$ \vec{\nu} P = \left( \lim_{n \to \infty} \vec{\alpha} P^n \right) P = \lim_{n \to \infty} (\vec{\alpha} P^n \cdot P) = \lim_{n \to \infty} \vec{\alpha} P^{n+1} = \vec{\nu} $$
	Zatem $\vec{\nu}$ jest rozkładem stacjonarnym.
\end{proof}

\begin{obserwacja}
	Implikacja w drugą stronę nie jest prawdziwa. Istnienie rozkładu stacjonarnego (nawet jedynego) nie gwarantuje istnienia rozkładu granicznego.
\end{obserwacja}

\begin{example}
	Rozważmy ponownie macierz $P = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$. Jedynym rozkładem stacjonarnym jest $\vec{\pi} = [1/2, 1/2]$, ponieważ $[1/2, 1/2]P = [1/2, 1/2]$. Jednak, jak widzieliśmy, granica $\lim P^n$ nie istnieje. Dla rozkładu początkowego $\vec{\alpha} = [1, 0]$, ciąg rozkładów $\vec{\alpha}P^n$ oscyluje między $[1, 0]$ a $[0, 1]$ i nie zbiega.
\end{example}

\section{Twierdzenie Perrona-Frobeniusa}

Kluczowym narzędziem do wykazania, że $\lambda=1$ jest prostą i dominującą wartością własną, jest twierdzenie Perrona-Frobeniusa. Najpierw podamy jego wersję dla macierzy ściśle dodatnich.

\begin{twierdzenie}[Perron, 1907]
	Niech $A$ będzie macierzą kwadratową o elementach ściśle dodatnich ($A > 0$, tzn. $A_{ij} > 0$ dla wszystkich $i,j$). Wtedy:
	\begin{enumerate}
		\item Promień spektralny $\rho(A)$ jest wartością własną macierzy $A$.
		\item $\rho(A)$ jest dominującą wartością własną, tzn. dla każdej innej wartości własnej $\lambda \in \sigma(A)$ zachodzi $|\lambda| < \rho(A)$.
		\item $\rho(A) > 0$.
		\item Krotność algebraiczna wartości własnej $\rho(A)$ jest równa 1 (jest to wartość prosta).
		\item Istnieją prawostronny wektor własny $\vec{v}$ i lewostronny wektor własny $\vec{u}$ odpowiadające wartości własnej $\rho(A)$, których wszystkie współrzędne są ściśle dodatnie ($\vec{v} > 0, \vec{u} > 0$).
	\end{enumerate}
\end{twierdzenie}

\begin{obserwacja}
	Twierdzenie to stanowi teoretyczną podstawę algorytmu PageRank używanego przez Google.
\end{obserwacja}

Zastosujmy to twierdzenie do macierzy stochastycznych.

\begin{wniosek}
	Niech $P$ będzie macierzą stochastyczną o elementach ściśle dodatnich ($P>0$). Wtedy:
	\begin{itemize}
		\item Wartość własna $\lambda=1$ ma krotność algebraiczną (i geometryczną) równą 1.
		\item Dla każdej innej wartości własnej $\tilde{\lambda} \in \sigma(P)$, zachodzi $|\tilde{\lambda}| < 1$.
		\item Istnieją ściśle dodatnie wektory własne: prawostronny $\vec{v}$ (np. $\vec{v}=[1, \dots, 1]^T$) i lewostronny $\vec{u}$ (rozkład stacjonarny).
	\end{itemize}
\end{wniosek}

\begin{proof}
	Ponieważ $P$ jest stochastyczna, wiemy, że $\rho(P)=1$. Ponieważ $P>0$, z twierdzenia Perrona wynika, że $\rho(P)=1$ jest prostą i dominującą wartością własną.
\end{proof}

Zatem dla łańcucha Markowa, którego macierz przejścia $P$ jest ściśle dodatnia, mamy zagwarantowane istnienie unikalnego rozkładu stacjonarnego, który jest jednocześnie rozkładem granicznym.

\subsection{Macierze regularne}

Założenie $P>0$ jest bardzo silne. Można je osłabić.

\begin{example}
	Rozważmy macierz $P = \begin{pmatrix} 0 & 1 \\ 1/2 & 1/2 \end{pmatrix}$. Nie jest ona ściśle dodatnia. Jej widmo to $\sigma(P)=\{1, -1/2\}$. Wartość $\lambda=1$ jest prosta i dominująca, więc łańcuch zbiega do równowagi. Zauważmy, że:
	$$ P^2 = \begin{pmatrix} 1/2 & 1/2 \\ 1/4 & 3/4 \end{pmatrix} > 0 $$
\end{example}

To prowadzi do pojęcia macierzy regularnej.

\begin{definition}[Macierz regularna]
	Macierz stochastyczną $P$ nazywamy \textbf{regularną}, jeśli istnieje taka liczba naturalna $n \in \mathbb{N}$, że macierz $P^n$ ma wszystkie elementy ściśle dodatnie ($P^n>0$).
\end{definition}

\begin{twierdzenie}
	Jeśli macierz stochastyczna $P$ jest regularna, to $\lambda=1$ jest jej prostą i dominującą wartością własną.
\end{twierdzenie}

\begin{proof}
	Niech $n_0$ będzie takie, że macierz $P^{n_0}$ jest ściśle dodatnia ($P^{n_0} > 0$). Zastosujmy twierdzenie Perrona do macierzy $P^{n_0}$. Wynika z niego, że $\lambda=1$ jest jej prostą (krotność algebraiczna równa 1) i dominującą wartością własną. Pokażemy, że te własności przenoszą się na macierz $P$.

	\begin{obserwacja}
		Jeśli $\vec{x}$ jest wektorem własnym macierzy $A$ dla wartości własnej $\lambda$, to jest też wektorem własnym macierzy $A^k$ dla wartości własnej $\lambda^k$.
	\end{obserwacja}

	\textbf{1. Prostota:} Dowód przez sprzeczność. Załóżmy, że $\lambda=1$ nie jest prostą wartością własną $P$, co oznacza, że jej krotność algebraiczna, oznaczmy ją $\text{alg.mult.}(1, P)$, jest większa od 1. Pokażemy, że implikuje to, iż $\text{alg.mult.}(1, P^{n_0}) > 1$, co doprowadzi do sprzeczności.

	Kluczowy krok dowodu opiera się na następującym fakcie z algebry liniowej:
	\begin{lemat}
		Dla dowolnej macierzy kwadratowej $A$ i $k \in \mathbb{N}$, zachodzi nierówność:
		$$ \text{alg.mult.}(1, A^k) \ge \text{alg.mult.}(1, A) $$
	\end{lemat}
	\begin{proof}[Dowód lematu]
		Niech $A = QJQ^{-1}$ będzie rozkładem Jordana macierzy $A$. Macierz $J$ jest blokowo-diagonalna, a krotność algebraiczna wartości własnej $\lambda$ jest z definicji sumą rozmiarów wszystkich klatek Jordana odpowiadających tej wartości własnej.
		
		Mamy $A^k = QJ^kQ^{-1}$, więc $\text{alg.mult.}(1, A^k) = \text{alg.mult.}(1, J^k)$. Krotność ta jest sumą krotności algebraicznych wartości własnej 1 dla każdej z klatek macierzy $J^k$.
		
		Rozważmy klatkę Jordana $J_i$ o rozmiarze $s \times s$ z macierzy $J$, odpowiadającą wartości własnej $\lambda_i$.
		\begin{itemize}
			\item Jeśli $\lambda_i = 1$, to $J_i = I + N$, gdzie $N$ jest macierzą $s \times s$ z jedynkami na superdiagonali i zerami w pozostałych miejscach. Wtedy $J_i^k = (I+N)^k = I + k N + \dots$. Jest to macierz górnotrójkątna, której wszystkie elementy na przekątnej są równe 1. Wartości własne macierzy trójkątnej leżą na jej przekątnej, zatem wszystkie $s$ wartości własnych macierzy $J_i^k$ jest równych 1. Oznacza to, że $\text{alg.mult.}(1, J_i^k) = s = \text{alg.mult.}(1, J_i)$.
			\item Jeśli $\lambda_i \neq 1$, ale $\lambda_i^k = 1$, to klatka $J_i^k$ również będzie miała na przekątnej tylko jedynki, więc $\text{alg.mult.}(1, J_i^k) = s > 0$.
		\end{itemize}
		Sumując wkłady od wszystkich klatek, otrzymujemy:
		$$ \text{alg.mult.}(1, A^k) = \sum_{i: \lambda_i^k=1} \text{alg.mult.}(1, J_i^k) \ge \sum_{i: \lambda_i=1} \text{alg.mult.}(1, J_i) = \text{alg.mult.}(1, A) $$
		co kończy dowód lematu.
	\end{proof}
	
	Stosując powyższy lemat dla $A=P$ i $k=n_0$, z naszego założenia, że $\text{alg.mult.}(1, P) > 1$, wynika bezpośrednio, że $\text{alg.mult.}(1, P^{n_0}) > 1$.
	To stoi w sprzeczności z twierdzeniem Perrona dla macierzy $P^{n_0}>0$, które gwarantuje, że $\lambda=1$ jest jej prostą wartością własną ($\text{alg.mult.}(1, P^{n_0})=1$).
	Zatem założenie było fałszywe i $\lambda=1$ musi być prostą wartością własną $P$.

	\textbf{2. Dominacja:} Dowód przez sprzeczność. Załóżmy, że $\lambda=1$ nie jest dominująca dla $P$. Oznacza to, że istnieje inna wartość własna $\tilde{\lambda} \in \sigma(P)$ taka, że $|\tilde{\lambda}|=1$ i $\tilde{\lambda} \neq 1$.
	Zgodnie z obserwacją, $\tilde{\lambda}^{n_0}$ jest wartością własną macierzy $P^{n_0}$ i zachodzi $|\tilde{\lambda}^{n_0}| = |\tilde{\lambda}|^{n_0} = 1$.
	Z twierdzenia Perrona dla $P^{n_0}>0$ wiemy, że jedyną jej wartością własną o module 1 jest 1. Zatem musi zachodzić $\tilde{\lambda}^{n_0} = 1$.
	Niech $\vec{v}$ będzie wektorem własnym $P$ dla $\tilde{\lambda}$. Ponieważ $\tilde{\lambda} \neq 1$, jest on liniowo niezależny od wektora własnego $\vec{1}$ dla $\lambda=1$.
	Jednocześnie, skoro $\tilde{\lambda}^{n_0}=1$, to $\vec{v}$ jest również wektorem własnym $P^{n_0}$ dla wartości własnej 1. To oznacza, że krotność geometryczna $g(1, P^{n_0})$ jest większa od 1.
	Ponieważ krotność algebraiczna jest zawsze większa lub równa geometrycznej ($\text{alg.mult.}(1, P^{n_0}) \ge g(1, P^{n_0})$), oznacza to, że $\text{alg.mult.}(1, P^{n_0}) > 1$. To stoi w sprzeczności z twierdzeniem Perrona.
	Zatem założenie było fałszywe i $\lambda=1$ jest dominującą wartością własną $P$.

	Zatem dla regularnej macierzy $P$, wartość $\lambda=1$ musi być prosta i dominująca. $\Box$
\end{proof}

\begin{wniosek}
	Jeśli łańcuch Markowa jest regularny (jego macierz przejścia jest regularna), to zbiega on do unikalnego rozkładu stacjonarnego.
\end{wniosek}



\subsection{Jeszcze jeden wniosek z twierdzenia Perrona}

\textbf{Dowód dla łańcuchów nieprzywiedlnych (metoda uśredniania)}

Poniższy dowód pokazuje, że dla łańcucha nieprzywiedlnego na skończonej przestrzeni stanów, wartość własna $\lambda=1$ jest prosta, co gwarantuje istnienie unikalnego rozkładu stacjonarnego.

\textbf{Stwierdzenie:}
Jeśli łańcuch $(X_n)_n$ jest nieprzywiedlny i ma skończoną przestrzeń stanów ($\#S < \infty$), to krotność geometryczna wartości własnej $\lambda=1$ jest równa 1.

\textbf{Szkic dowodu:}
\begin{enumerate}
	\item Definiujemy liczbę $M$ jako maksymalną długość najkrótszej ścieżki między dowolnymi dwoma stanami:
	      $$ M := \max_{(i,j) \in S^2} \min \{l \in \mathbb{N} : (P^l)_{ij} > 0 \} < \infty $$
	      Ponieważ łańcuch jest nieprzywiedlny i skończony, $M$ jest dobrze zdefiniowane.

	\item Konstruujemy macierz uśrednioną $\bar{P}$:
	      $$ \bar{P} := \frac{1}{M} \sum_{k=1}^{M} P^k $$
	      Macierz $\bar{P}$ jest stochastyczna i ściśle dodatnia ($\bar{P} > 0$).

	\item Z twierdzenia Perrona dla macierzy dodatnich, dla $\bar{P}$ wartość własna $\lambda=1$ jest prosta w widmie $\sigma(\bar{P})$.

	\item Pokazujemy, że każdy wektor własny $v$ macierzy $P$ dla $\lambda=1$ jest też wektorem własnym macierzy $\bar{P}$ dla $\lambda=1$. Jeśli $vP=v$, to:
	      $$ v \bar{P} = v \left( \frac{1}{M} \sum_{k=1}^{M} P^k \right) = \frac{1}{M} \sum_{k=1}^{M} (v P^k) = \frac{1}{M} \sum_{k=1}^{M} v = v $$

	\item Prowadzi to do sprzeczności: gdyby krotność geometryczna $\lambda=1$ dla $P$ była większa niż 1, to istniałyby co najmniej dwa liniowo niezależne wektory własne. Wszystkie one byłyby też wektorami własnymi dla $\bar{P}$, co przeczyłoby prostocie wartości własnej $\lambda=1$ dla $\bar{P}$. Zatem krotność geometryczna $\lambda=1$ dla $P$ musi być równa 1.
\end{enumerate}

\textbf{Morał 1: Krotność geometryczna a klasy powracające}

Kluczowym uogólnieniem powyższego wyniku jest następujący fakt:

\textit{Dla dowolnego łańcucha Markowa na skończonej przestrzeni stanów, krotność geometryczna wartości własnej $\lambda=1$ jest równa liczbie klas powracających w tym łańcuchu.}

\textbf{Morał 2: Konsekwencje dla łańcuchów skończonych}

Powyższy fakt ma fundamentalne konsekwencje:
\begin{itemize}
	\item Ponieważ dla każdej macierzy stochastycznej $\lambda=1$ jest wartością własną, jej krotność geometryczna jest $\ge 1$.
	\item Oznacza to, że w łańcuchu o \textbf{skończonej} liczbie stanów \textbf{musi istnieć przynajmniej jedna klasa powracająca}.
	\item To z kolei gwarantuje istnienie \textbf{przynajmniej jednego rozkładu stacjonarnego}.
\end{itemize}
\textit{Uwaga:} Powyższe wnioski dotyczą łańcuchów na \textbf{skończonej} przestrzeni stanów. W przypadku przestrzeni nieskończonych sytuacja może być inna, ponieważ definicja $M := \max_{(i,j) \in S^2} \min \{l \in \mathbb{N} : (P^l)_{ij} > 0 \}$ może prowadzić do $M=\infty$, co uniemożliwia konstrukcję macierzy uśrednionej $\bar{P}$ o elementach ściśle dodatnich.

\section{Okresowość}
\begin{definition}[Okres stanu]
	Okresem stanu $j \in S$ nazywamy liczbę:
	\[ o(j) := \NWD \{ n \ge 1 : p_n(j,j) > 0 \} \]
	gdzie $\NWD$ oznacza największy wspólny dzielnik. Jeżeli zbiór $\{ n \ge 1 : p_n(j,j) > 0 \}$ jest pusty, to przyjmujemy $o(j) = \infty$. Stan, dla którego $o(j)=1$ nazywamy \textbf{nieokresowym} lub \textbf{aperiodycznym}.
\end{definition}

Innymi słowy, okres stanu $j$ to największa liczba, przez którą dzielą się wszystkie możliwe czasy powrotu do tego stanu.

\begin{obserwacja}
	Okres jest własnością klasy komunikacji. Oznacza to, że jeśli stany $i$ oraz $j$ komunikują się ze sobą ($i \leftrightarrow j$), to $o(i) = o(j)$.
\end{obserwacja}

\begin{example}[Macierze permutacji]
	Macierze permutacji generują okresowe łańcuchy.
	\[ P_1 = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}, \quad P_2 = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{pmatrix} \]
	Potęgi tych macierzy nigdy nie staną się dodatnie, ponieważ zera pozostaną na stałych pozycjach, jedynie przesuwając się cyklicznie.
	Dla $P_1$, powrót do stanu 1 jest możliwy w 2, 4, 6, ... krokach. Zatem $o(1) = \NWD\{2, 4, 6, \dots\} = 2$. Podobnie $o(2)=2$.
\end{example}

\begin{example}[Łańcuch okresowy]
	Rozważmy łańcuch opisany macierzą $P = \begin{pmatrix} 0 & 1/2 & 1/2 \\ 1 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix}$ i odpowiadający mu graf stanów.

	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, shorten >=1pt, auto, node distance=2.5cm, semithick, state/.style={circle, draw, minimum size=0.8cm}]
			\node[state] (1)              {$1$};
			\node[state] (2) [left of=1]  {$2$};
			\node[state] (3) [right of=1] {$3$};

			\path (1) edge [bend left] node {1/2} (2)
			edge [bend right] node {1/2} (3);
			\path (2) edge [bend left] node {1} (1);
			\path (3) edge [bend right] node {1} (1);
		\end{tikzpicture}
	\end{center}

	Łańcuch jest nieprzywiedlny. Możliwe powroty do stanu 1:
	\begin{itemize}
		\item $1 \to 2 \to 1$ (2 kroki),
		\item $1 \to 3 \to 1$ (2 kroki).
	\end{itemize}
	Zbiór długości powrotów zawiera $\{2, 4, 6, \dots\}$. Zatem $o(1)=2$. Ponieważ wszystkie stany są w jednej klasie, $o(2)=o(3)=2$.
\end{example}

\begin{example}[Łańcuch nieokresowy]
	Wystarczy niewielka zmiana, aby łańcuch stał się nieokresowy. Rozważmy macierz $P = \begin{pmatrix} 1/2 & 1/2 \\ 1 & 0 \end{pmatrix}$.

	\begin{center}
		\begin{tikzpicture}[->, >=Stealth, shorten >=1pt, auto, node distance=2.5cm, semithick, state/.style={circle, draw, minimum size=0.8cm}]
			\node[state] (1)              {$1$};
			\node[state] (2) [right of=1] {$2$};

			\path (1) edge [loop above] node {1/2} (1)
			edge [bend left]  node {1/2} (2);
			\path (2) edge [bend left]  node {1} (1);
		\end{tikzpicture}
	\end{center}

	Możliwe powroty do stanu 1:
	\begin{itemize}
		\item $1 \to 1$ (1 krok),
		\item $1 \to 2 \to 1$ (2 kroki).
	\end{itemize}
	Ponieważ zbiór długości powrotów zawiera $\{1, 2\}$, to $\NWD\{1, 2, \dots\} = 1$. Stan 1 jest nieokresowy, a co za tym idzie, cały łańcuch jest nieokresowy.
\end{example}

Dla stanów nieokresowych (najważniejszy dla nas przypadek) zachodzi następująca ważna własność.

\begin{lemat}
	Jeśli stan $i \in S$ jest powracalny i nieokresowy, to istnieje takie $n_0 = n_0(i)$, że dla wszystkich $n > n_0$ zachodzi $p_n(i,i) > 0$.
\end{lemat}

\begin{proof}
	Dowód opiera się na następującym fakcie z teorii liczb:
	\vspace{0.5cm}

	\noindent\textit{Fakt. Niech $A \subset \mathbb{N}$ będzie niepustym zbiorem zamkniętym na dodawanie (tzn. $m,n \in A \Rightarrow m+n \in A$). Jeśli $\NWD(A) = 1$, to istnieje takie $n_0$, że $\{n_0, n_0+1, n_0+2, \dots\} \subset A$.}
	\vspace{0.5cm}

	Zdefiniujmy zbiór $A$ jako zbiór czasów, po których możliwy jest powrót do stanu $i$:
	\[ A := \{n \ge 1 : p_n(i,i) > 0\} \]
	Stan $i$ jest powracalny, więc zbiór ten jest niepusty ($A \neq \emptyset$).

	Załóżmy, że $m, n \in A$. Oznacza to, że $p_m(i,i) > 0$ oraz $p_n(i,i) > 0$. Z nierówności Chapmana-Kołmogorowa mamy:
	\[ p_{m+n}(i,i) \ge p_m(i,i) p_n(i,i) > 0 \]
	To pokazuje, że $m+n \in A$, a więc zbiór $A$ jest zamknięty na dodawanie.
	Z definicji stanu nieokresowego wiemy, że $\NWD(A) = o(i) = 1$.

	Wszystkie założenia faktu z teorii liczb są spełnione. Zatem istnieje $n_0$ takie, że dla każdego $n > n_0$ mamy $n \in A$, co jest równoważne stwierdzeniu, że $p_n(i,i) > 0$.
\end{proof}

Powyższy lemat pozwala udowodnić silniejsze twierdzenie dotyczące łańcuchów, które są jednocześnie nieprzywiedlne i nieokresowe.

\begin{twierdzenie}
	Niech $(X_n)_n$ będzie nieprzywiedlnym i nieokresowym łańcuchem Markowa. Wtedy dla dowolnych stanów $i, j \in S$ istnieje $n_0 = n_0(i,j)$ takie, że dla wszystkich $n > n_0$ zachodzi $p_n(i,j) > 0$.
\end{twierdzenie}

\begin{proof}
	Ustalmy dowolne stany $i, j \in S$.
	\begin{itemize}
		\item Ponieważ łańcuch jest nieprzywiedlny, stany $i$ i $j$ komunikują się. Istnieje więc takie $m \in \mathbb{N}$, że $p_m(i,j) > 0$.
		\item Ponieważ łańcuch jest nieprzywiedlny i nieokresowy, to wszystkie jego stany są nieokresowe. W szczególności stan $i$ jest nieokresowy (i powracalny, co jest własnością nieprzywiedlnych łańcuchów). Z poprzedniego lematu wiemy, że istnieje $n_0(i)$ takie, że $p_k(i,i) > 0$ dla wszystkich $k > n_0(i)$.
	\end{itemize}
	Połóżmy $n_0(i,j) := n_0(i) + m$.

	Rozważmy dowolne $n > n_0(i,j)$. Równoważnie, $n - m > n_0(i)$. Wtedy, korzystając ponownie z nierówności Chapmana-Kołmogorowa, otrzymujemy:
	\[ p_n(i,j) = \sum_{k \in S} p_{n-m}(i,k) p_m(k,j) \ge \underbrace{p_{n-m}(i,i)}_{>0} \underbrace{p_m(i,j)}_{>0} > 0 \]
	Pierwszy czynnik jest dodatni, ponieważ $n-m > n_0(i)$. Drugi czynnik jest dodatni z definicji $m$. Iloczyn jest więc ściśle dodatni, co kończy dowód.
\end{proof}

Dla łańcuchów o skończonej liczbie stanów otrzymujemy natychmiastowy wniosek.

\begin{wniosek}
	Jeśli $(X_n)_n$ jest nieprzywiedlnym, nieokresowym łańcuchem Markowa o skończonej przestrzeni stanów ($\#S < \infty$), to istnieje $n_0$ takie, że dla wszystkich $n > n_0$ macierz przejścia $P^n$ jest ściśle dodatnia (tzn. wszystkie jej elementy są dodatnie).
\end{wniosek}

\begin{proof}
	Wynika to wprost z poprzedniego twierdzenia. Dla każdej pary $(i,j)$ istnieje $n_0(i,j)$. Ponieważ zbiór par $(i,j)$ jest skończony, możemy zdefiniować $n_0 = \max_{i,j \in S} n_0(i,j)$.
\end{proof}

\section{Główne twierdzenia graniczne}

Powyższe własności pozwalają sformułować fundamentalne twierdzenia dotyczące zbieżności łańcuchów Markowa do równowagi.

\begin{twierdzenie}[Ergodyczne dla Łańcuchów Markowa]
	Niech $(X_n)_n$ będzie nieprzywiedlnym, nieokresowym łańcuchem Markowa o skończonej przestrzeni stanów. Wówczas:
	\begin{enumerate}
		\item Istnieje dokładnie jeden rozkład stacjonarny $\bar{\pi}$.
		\item Wszystkie składowe rozkładu stacjonarnego są ściśle dodatnie, tzn. $\bar{\pi}_j > 0$ dla każdego $j \in S$.
		\item Granica prawdopodobieństw przejścia istnieje i jest niezależna od stanu początkowego:
		      \[ \lim_{n \to \infty} p_n(i,j) = \bar{\pi}_j \quad \text{dla wszystkich } i,j \in S \]
	\end{enumerate}
\end{twierdzenie}

Warunek nieokresowości jest kluczowy dla zbieżności punktowej. Jeśli go opuścimy, wciąż możemy mówić o zbieżności w słabszym sensie.

\begin{twierdzenie}[Zbieżność w sensie Cesàro]
	Niech $(X_n)_n$ będzie nieprzywiedlnym łańcuchem Markowa o skończonej przestrzeni stanów. Wówczas dla wszystkich $i,j \in S$ granica średnich arytmetycznych prawdopodobieństw przejścia istnieje i jest równa składowej jedynego rozkładu stacjonarnego $\bar{\pi}_j$:
	\[ \lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^{n} p_k(i,j) = \bar{\pi}_j \]
\end{twierdzenie}

\begin{obserwacja}
	Należy podkreślić, że łańcuch Markowa, który jest nieprzywiedlny i ma skończoną przestrzeń stanów, jest również \textbf{powracający}. Oznacza to, że każdy stan jest powracalny, czyli prawdopodobieństwo powrotu do stanu $j$ w skończonym czasie, startując z $j$, wynosi 1:
	\[ P(T_j < \infty | X_0 = j) = 1 \]
	Co więcej, średni czas powrotu do każdego stanu jest skończony.
\end{obserwacja}

\section{Średnie czasy powrotu a rozkład stacjonarny}

W tej sekcji pokażemy fundamentalny związek między rozkładem stacjonarnym a średnimi czasami powrotu do poszczególnych stanów.

\begin{definition}[Czasy wizyt i powrotów]
	Ustalmy stan $j \in S$. Zdefiniujmy ciąg zmiennych losowych:
	\begin{itemize}
		\item $T(1) := \min\{n \ge 1: X_n = j\}$ --- moment pierwszej wizyty w stanie $j$.
		\item $T(k+1) := \min\{n > T(k): X_k = j\}$ --- moment $(k+1)$-szej wizyty w $j$.
		\item $\tau(1) := T(1)$ --- czas do pierwszej wizyty.
		\item $\tau(k) := T(k) - T(k-1)$ dla $k \ge 2$ --- czas pomiędzy $(k-1)$-szą a $k$-tą wizytą w $j$.
	\end{itemize}
\end{definition}

Zmienne losowe $\tau(k)$ mają następujące własności:
\begin{itemize}
	\item Jeśli proces startuje ze stanu $X_0 = j$, to ciąg $(\tau(k))_{k \ge 1}$ jest ciągiem niezależnych zmiennych losowych o identycznym rozkładzie (i.i.d.).
	\item Jeśli proces startuje ze stanu $X_0 = i \ne j$, to ciąg $(\tau(k))_{k \ge 2}$ jest ciągiem i.i.d., a rozkład każdej z tych zmiennych jest taki sam, jak rozkład $\tau(1)$ przy starcie z $X_0=j$.
\end{itemize}
Własność niezależności (zawarta w "i.i.d.") oznacza, że dla $n, m \ge 2$ ($n \neq m$), zdarzenia dotyczące $\tau(n)$ i $\tau(m)$ są niezależne. Przykładowo, dla $X_0 = i \ne j$:
\[ \mathbb{P}(\tau(5)=k, \tau(7)=l | X_0=i) = \mathbb{P}(\tau(5)=k | X_0=i) \cdot \mathbb{P}(\tau(7)=l | X_0=i) \]
\[ \mathbb{P}(\tau(n)=k | X_0=i) = \mathbb{P}(\tau(n)=k | X_0=j) \quad \forall n \ge 2 \]
(stały rozkład dla $n \ge 2$)

Powyższa własność implikuje równość wartości oczekiwanych. \textbf{Średnim czasem powrotu} do stanu $j$ nazywamy wartość oczekiwaną czasu pierwszego powrotu do $j$, przy założeniu, że proces startuje w $j$. Oznaczamy go jako $\mu_j$:
\[ \mathbb{E}[\tau(n) | X_0=i] = \mathbb{E}[\tau(n) | X_0=j] = \mathbb{E}[\tau(1) | X_0=j] =: \mu_j \]
Wartość $\mu_j$ może należeć do przedziału $[1, \infty]$. Dla łańcuchów nieprzywiedlnych o skończonej liczbie stanów $\mu_j < \infty$.

Dzięki własności i.i.d. czasów $\tau(k)$, $\mu_j$ jest również \textbf{średnim czasem pomiędzy dowolnymi dwiema kolejnymi wizytami} w stanie $j$.

Wprowadzenie średniego czasu powrotu $\mu_j$ jest kluczowe, ponieważ, jak za chwilę pokażemy, istnieje fundamentalny związek między tą wartością a długoterminową częstotliwością, z jaką proces odwiedza stan $j$. Kolejnym krokiem będzie wykorzystanie Mocnego Prawa Wielkich Liczb, aby ten związek precyzyjnie wykazać.

Zauważmy, że $T(n) = \tau(1) + \tau(2) + \dots + \tau(n)$. Korzystając z Mocnego Prawa Wielkich Liczb (MPWL) dla ciągu $(\tau(k))_{k \ge 2}$, otrzymujemy zbieżność prawie na pewno, niezależnie od stanu startowego $i$:
\[ P\left(\lim_{n \to \infty} \frac{T(n)}{n} = \mu_j \bigg| X_0=i\right) = 1 \]
Teraz powiążemy to z częstością odwiedzin stanu $j$. Oznaczmy przez $n = N_j(k) = \sum_{l=1}^{k} \mathbf{1}_{\{X_l=j\}}$ liczbę wizyt w stanie $j$ do kroku $k$.

Dla danego $k$, liczba wizyt $n$ spełnia nierówność:
\[ T(n) \le k < T(n+1) \]
Dzieląc przez $n$ i odwracając (przy założeniu $n>0$), otrzymujemy:
\[ \frac{T(n)}{n} \le \frac{k}{n} < \frac{T(n+1)}{n} \]
Gdy $k \to \infty$, to również $n \to \infty$ (ponieważ stan jest powracalny). Z MPWL wiemy, że $\frac{T(m)}{m} \to \mu_j$ p.n. (dla $m \to \infty$). Zatem obie skrajne strony nierówności zbiegają do $\mu_j$. Analogicznie do twierdzenia o trzech ciągach wnioskujemy, że:
\[ \lim_{k \to \infty} \frac{k}{n} = \mu_j \quad \text{p.n.} \]
co jest równoważne:
\[ \lim_{k \to \infty} \frac{n}{k} = \frac{1}{\mu_j} \quad \text{p.n.} \]
Otrzymaliśmy ważny wynik: długoterminowa częstotliwość przebywania w stanie $j$ jest równa odwrotności średniego czasu powrotu do tego stanu.

Pozostaje ostatni krok: powiązanie tego wyniku z rozkładem stacjonarnym. Weźmy wartość oczekiwaną obu stron powyższej granicy. Ponieważ $\frac{N_j(k)}{k} \le 1$, możemy skorzystać z twierdzenia Lebesgue'a o zbieżności zmajoryzowanej i zamienić granicę z wartością oczekiwaną:
\[ \lim_{k \to \infty} E\left[ \frac{N_j(k)}{k} \bigg| X_0=i \right] = E\left[ \lim_{k \to \infty} \frac{N_j(k)}{k} \bigg| X_0=i \right] = E\left[ \frac{1}{\mu_j} \right] = \frac{1}{\mu_j} \]
Z drugiej strony, z liniowości wartości oczekiwanej:
\[ E\left[ \frac{N_j(k)}{k} \bigg| X_0=i \right] = \frac{1}{k} \sum_{l=1}^{k} E[\mathbf{1}_{\{X_l=j\}} | X_0=i] = \frac{1}{k} \sum_{l=1}^{k} P(X_l=j | X_0=i) = \frac{1}{k} \sum_{l=1}^{k} p_l(i,j) \]
Z twierdzenia o zbieżności w sensie Cesàro wiemy, że granica tego wyrażenia, gdy $k \to \infty$, jest równa $\bar{\pi}_j$. Porównując oba wyniki, dochodzimy do fundamentalnej tożsamości.

\begin{twierdzenie}
	Dla nieprzywiedlnego, powracającego łańcucha Markowa, składowe jedynego rozkładu stacjonarnego $\bar{\pi}$ oraz średnie czasy powrotu $\mu_j$ są ze sobą związane wzorem:
	\[ \boxed{ \bar{\pi}_j = \frac{1}{\mu_j} } \]
	dla każdego stanu $j \in S$.
\end{twierdzenie}

Ten wynik dostarcza niezwykle ważnej intuicji: prawdopodobieństwo znalezienia się w danym stanie w stanie równowagi jest odwrotnie proporcjonalne do średniego czasu, jaki upływa między kolejnymi wizytami w tym stanie. Stany, do których proces często powraca (małe $\mu_j$), mają wysokie prawdopodobieństwo stacjonarne.


\section{Podsumowanie własności ergodycznych}

Rozważmy łańcuch Markowa $(X_n)_n$ na przestrzeni stanów $S$, gdzie moc zbioru $\#S < \infty$ (przestrzeń jest skończona). Załóżmy, że łańcuch jest \textbf{nieprzywiedlny}.

\begin{theorem}[O istnieniu i zbieżności średnich]
Jeżeli łańcuch jest nieprzywiedlny i skończony, to:
\begin{enumerate}
    \item Istnieje dokładnie jeden rozkład stacjonarny $\pi > 0$ (tzn. $\pi_j > 0$ dla każdego $j$).
    \item Średni czas powrotu do stanu $j$ wynosi:
    \[
    \mu_j = \mathbb{E}[T_j \mid X_0=j] = \frac{1}{\pi_j} < \infty \quad \forall j.
    \]
    \item (Prawo Wielkich Liczb dla Łańcuchów Markowa) Prawie na pewno (p.n.) dla każdego stanu początkowego $X_0=i$:
    \[
    \frac{1}{n} \sum_{k=1}^{n} \mathbf{1}_{\{X_k=j\}} \xrightarrow{n\to\infty} \pi_j.
    \]
\end{enumerate}
\end{theorem}

Oznacza to, że frakcja czasu spędzonego w stanie $j$ dąży do prawdopodobieństwa stacjonarnego $\pi_j$. Możemy to zapisać również jako zbieżność średnich Césaro prawdopodobieństw przejścia:
\[
\lim_{n\to\infty} \frac{1}{n} \sum_{k=1}^{n} p_k(i,j) = \pi_j \quad \forall i,j.
\]

\begin{theorem}[Ergodyczne dla łańcuchów nieokresowych]
Jeżeli dodatkowo łańcuch jest \textbf{nieokresowy}, to zachodzi mocniejszy warunek zbieżności (punktowa zbieżność rozkładu):
\[
\lim_{n\to\infty} p_n(i,j) = \pi_j \quad \forall i,j.
\]
\end{theorem}

\begin{example}[Porównanie macierzowe]

\textbf{A. Przypadek Okresowy (Gwiazda $1 \leftrightarrow \{2,3\}$)} \\
Wiersze zwykłej potęgi $P^n$ skaczą i są różne (zależnie od startu). Dopiero średnia je wyrównuje.
\[
P = \begin{pmatrix} 0 & 0.5 & 0.5 \\ 1 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix}
\quad \xrightarrow[\text{średnia}]{\text{Cesàro}} \quad
\underbrace{\begin{pmatrix} 0.5 & 0.25 & 0.25 \\ 0.5 & 0.25 & 0.25 \\ 0.5 & 0.25 & 0.25 \end{pmatrix}}_{\text{Identyczne wiersze (rozkład } \pi)}
\]

\vspace{0.5cm}

\textbf{B. Przypadek Nieokresowy (Leniwy)} \\
Tu nie trzeba uśredniać. Sama macierz zbiega do stanu, gdzie wiersze są identyczne.
\[
P = \begin{pmatrix} 0.5 & 0.5 \\ 1 & 0 \end{pmatrix}
\quad \xrightarrow{n \to \infty} \quad
\underbrace{\begin{pmatrix} 2/3 & 1/3 \\ 2/3 & 1/3 \end{pmatrix}}_{\text{Identyczne wiersze (rozkład } \pi)}
\]

\end{example}

\section{Odwracalność czasowa i Równowaga Szczegółowa}

Rozważmy łańcuch $(X_n)_n$ na przestrzeni $S$ ($\#S \le \infty$) z rozkładem początkowym $\alpha$ i macierzą przejścia $P$.

\begin{definition}[Równowaga szczegółowa]
Mówimy, że para $(\alpha, P)$ jest w \textbf{równowadze szczegółowej} (ang. \textit{detailed balance}), jeśli:
\[
\alpha_i p_{ij} = \alpha_j p_{ji} \quad \forall i,j \in S.
\]
\end{definition}

Pojęcie to jest ściśle związane z fizyczną koncepcją odwracalności procesu w czasie.

\begin{theorem}[Równoważność odwracalności i równowagi szczegółowej]
Łańcuch $(X_0, X_1, \dots, X_n)$ jest czasowo odwracalny względem $\alpha$, tzn.:
\[
(X_0, X_1, \dots, X_{n-1}, X_n) \stackrel{d}{=} (X_n, X_{n-1}, \dots, X_1, X_0)
\]
wtedy i tylko wtedy, gdy para $(\alpha, P)$ jest w równowadze szczegółowej.
\end{theorem}

Intuicja stojąca za odwracalnością (dla $n=2$):
\[
\mathbb{P}(X_0=x_0, X_1=x_1, X_2=x_2) = \mathbb{P}(X_2=x_0, X_1=x_1, X_0=x_2).
\]


\begin{obserwacja}
Jeżeli $\pi$ i $P$ są w relacji równowagi szczegółowej, to $\pi$ jest rozkładem stacjonarnym.
\end{obserwacja}

\begin{proof}
Załóżmy, że zachodzi warunek równowagi szczegółowej: $\pi_i p_{ij} = \pi_j p_{ji}$. Sumując obustronnie po $i$:
\[
\sum_{i} \pi_i p_{ij} = \sum_{i} \pi_j p_{ji} = \pi_j \underbrace{\sum_{i} p_{ji}}_{1} = \pi_j.
\]
Zatem $\sum_{i} \pi_i p_{ij} = \pi_j$, co jest dokładnie definicją rozkładu stacjonarnego zapisaną w notacji macierzowej jako $(\pi P)_j = \pi_j$.
\end{proof}

W praktyce czasami łatwiej jest „zgadnąć” rozkład $\pi$, z którym łańcuch jest w równowadze szczegółowej (np. z zasad fizyki).

\section{Własności spektralne łańcuchów odwracalnych}

Łańcuchy czasowo odwracalne są matematycznie prostsze i bardziej eleganckie niż łańcuchy nieodwracalne. Dlaczego?
Niech $(X_n)_n$ będzie nieprzywiedlnym łańcuchem na skończonej przestrzeni o mocy $N$ z jedynym dodatnim rozkładem stacjonarnym $\pi$.

Zdefiniujmy macierz diagonalną $Q$:
\[
Q = \text{diag}(\pi_1^{1/2}, \dots, \pi_N^{1/2}) \implies Q^{-1} = \text{diag}(\pi_1^{-1/2}, \dots, \pi_N^{-1/2}).
\]
Rozważmy macierz $A$ powstałą przez zmianę bazy macierzy $P$:
\[
A = Q P Q^{-1}.
\]
Elementy macierzy $A$ wyrażają się wzorem (zwykłe mnożenie macierzy):
\[
A_{ij} = \sum_{r=1}^N \sum_{s=1}^N Q_{ir} P_{rs} (Q^{-1})_{sj} = Q_{ii} P_{ij} (Q^{-1})_{jj} = \sqrt{\pi_i} P_{ij} \frac{1}{\sqrt{\pi_j}}.
\]

Skorzystajmy z warunku odwracalności: $\pi_i P_{ij} = \pi_j P_{ji} \implies P_{ij} = \frac{\pi_j}{\pi_i} P_{ji}$. Podstawiając to do wzoru na $A_{ij}$:
\[
A_{ij} = \sqrt{\pi_i} \left( \frac{\pi_j}{\pi_i} P_{ji} \right) \frac{1}{\sqrt{\pi_j}} = \frac{\pi_j}{\sqrt{\pi_j}} P_{ji} \frac{1}{\sqrt{\pi_i}} = \sqrt{\pi_j} P_{ji} \frac{1}{\sqrt{\pi_i}} = A_{ji}.
\]
\textbf{Wniosek:} Macierz $A$ jest symetryczna ($A = A^T$).
Dlaczego to jest ważne? Ponieważ macierze symetryczne mają rzeczywiste wartości własne (spectrum $\subset \mathbb{R}$) i posiadają bazę ortonormalną wektorów własnych.
\section{Przykład: Spacer losowy po grafie (Łańcuch czasowo odwracalny)}

Rozważmy \textbf{spacer losowy} (ang. \textit{random walk}) na grafie. Jest to klasyczny przykład procesu, który z natury jest czasowo odwracalny.

\subsection*{Założenia modelu}
Niech $G = (S, E)$ będzie grafem prostym i nieskierowanym, gdzie:
\begin{itemize}
    \item $\#S < \infty$ (przestrzeń stanów jest skończona),
    \item $E \subset S \times S$ (zbiór krawędzi),
    \item Graf nie posiada wierzchołków izolowanych (tzn. $\forall x \in S, \deg_G(x) > 0$).
\end{itemize}
\begin{obserwacja}
Założenie o braku wierzchołków izolowanych jest techniczne, ale konieczne, aby uniknąć dzielenia przez zero w definicji prawdopodobieństwa przejścia (mianownik $\deg_G(x)$).
\end{obserwacja}

\subsection*{Macierz przejścia}
Definiujemy łańcuch Markowa $(X_n)_n$ na przestrzeni $S$ o macierzy przejścia $P$ danej wzorem:
\[
\forall x,y \in S \quad p(x,y) = \frac{1}{\deg_G(x)} \cdot \mathbf{1}_E((x,y)).
\]
Gdzie: $$\mathbf{1}_E((x,y)) = \begin{cases} 1 & \text{jeżeli para } (x,y) \text{ tworzy krawędź w } E \\ 0 & \text{w przeciwnym przypadku} \end{cases}$$
Interpretacja: Będąc w wierzchołku $x$, wybieramy sąsiada $y$ zgodnie z rozkładem jednostajnym spośród wszystkich $\deg_G(x)$ sąsiadów.

\subsection*{Odwracalność i Równowaga Szczegółowa}
Sprawdźmy, czy istnieje miara $\pi$, dla której zachodzi warunek równowagi szczegółowej. Zauważmy, że dla grafu nieskierowanego relacja sąsiedztwa jest symetryczna:
\[
(x,y) \in E \iff (y,x) \in E \implies \mathbf{1}_E((x,y)) = \mathbf{1}_E((y,x)).
\]
Rozważmy równanie równowagi szczegółowej ("zgadując", że waga stanu zależy od jego stopnia):
\begin{align*}
    \text{Lewa strona: } & \deg_G(x) \cdot p(x,y) = \deg_G(x) \cdot \frac{1}{\deg_G(x)} \mathbf{1}_E((x,y)) = \mathbf{1}_E((x,y)). \\
    \text{Prawa strona: } & \deg_G(y) \cdot p(y,x) = \deg_G(y) \cdot \frac{1}{\deg_G(y)} \mathbf{1}_E((y,x)) = \mathbf{1}_E((y,x)).
\end{align*}
Ponieważ $\mathbf{1}_E((x,y)) = \mathbf{1}_E((y,x))$, otrzymujemy równość:
\[
\deg_G(x) p(x,y) = \deg_G(y) p(y,x).
\]
Oznacza to, że wektor $\pi$ proporcjonalny do stopni wierzchołków spełnia warunek równowagi szczegółowej z macierzą $P$.

\subsection*{Rozkład stacjonarny}
Aby otrzymać wektor prawdopodobieństwa $\pi$ (rozkład stacjonarny), musimy znormalizować wagi. Stałą normalizującą jest suma stopni wszystkich wierzchołków (równa $2|E|$):
\[
\pi_x = \frac{\deg_G(x)}{\sum_{z \in S} \deg_G(z)} \quad \text{dla } x \in S.
\]
\section{Metody MCMC (Markov Chain Monte Carlo)}

\subsection{Idea i motywacja}
MCMC stosujemy w zadaniach, gdzie przestrzeń stanów $S$ jest skończona, ale ogromna (tak duża, że nie znamy jej dokładnej liczby elementów $N$).
Niech $\pi$ będzie zadanym rozkładem prawdopodobieństwa na $S$ (b.s.o. $\pi > 0$).

\textbf{Cel:} Chcemy próbkować z $\pi$, tzn. losować elementy z $S$ zgodnie z rozkładem $\pi$, często po to, aby estymować wartość oczekiwaną pewnej funkcji $f$:
\[
\mathbb{E}[f(X)] \quad \text{gdzie } X \sim \pi.
\]
(Np. $f = \mathbf{1}_A$, wtedy $\mathbb{E}f(X) = \mathbb{P}(X \in A)$ dla $A \subset S$).

\textbf{Przykład I: Przestrzeń konfiguracji binarnych}
Niech $S := \{0,1\}^{N \times N}$.
Liczebność $\#S = 2^{N^2}$.
\begin{itemize}
    \item Dla $N=25$: $\#S = 2^{625} \approx 10^{188}$.
    \item Dla $N=50$: $\#S = 2^{2500} \approx 10^{752}$.
\end{itemize}
Dla porównania liczba atomów we wszechświecie to ok. $10^{80}$. Przestrzeń rośnie wykładniczo!

\textbf{Przykład II: Model Hardcore (niezależnych zbiorów)}
Rozważmy kratę $N \times N$. Stanami są konfiguracje zer i jedynek $S \subset \{0,1\}^{N \times N}$ takie, że żadne dwie jedynki nie sąsiadują ze sobą (w pionie ani w poziomie).

\begin{center}
\begin{tikzpicture}[scale=0.6]
    \draw[step=1cm,gray,very thin] (0,0) grid (3,3);
    \node at (1.5,1.5) {1};
    \node at (1.5,2.5) {0};
    \node at (1.5,0.5) {0};
    \node at (0.5,1.5) {0};
    \node at (2.5,1.5) {0};
    \node at (0.5,0.5) {0}; % róg
    \node at (1.5,-0.5) {Fragment kraty (Hardcore)};
\end{tikzpicture}
\end{center}

Wielkość tej przestrzeni jest nieznana dla dużych $N$. Istnieje hipoteza, że $\#S \sim \beta^{N^2}$ dla pewnego $\beta \in (1,2)$.

\subsection{Algorytm MCMC}
\textbf{Idea:} Zamiast próbować bezpośrednio losować z trudnego rozkładu, stwórzmy łańcuch Markowa $(X_n)_n$ na przestrzeni $S$, którego rozkładem stacjonarnym (lub granicznym) będzie zadane $\pi$.

Dlaczego to działa? Opieramy się na Prawie Wielkich Liczb dla łańcuchów Markowa.
Jeżeli skonstruujemy taki łańcuch (np. używając algorytmu Metropolisa-Hastingsa), to:
\[
\lim_{n \to \infty} \frac{1}{n} \sum_{m=1}^{n} f(X_m) = \lim_{n \to \infty} \frac{1}{n} \sum_{m=1}^{n} \sum_{x \in S} f(x) \mathbf{1}_{\{X_m=x\}}.
\]
Zmieniając kolejność sumowania:
\[
= \sum_{x \in S} f(x) \underbrace{\left( \lim_{n \to \infty} \frac{1}{n} \sum_{m=1}^{n} \mathbf{1}_{\{X_m=x\}} \right)}_{\searrow \pi_x \text{ (zbiega p.n.)}} = \sum_{x \in S} f(x) \pi_x = \mathbb{E}[f(X)]_{X \sim \pi}.
\]

Zauważmy, że do zbieżności średniej (z prawa wielkich liczb) wystarczy sama \textbf{nieprzywiedlność} łańcucha (nieokresowość nie jest niezbędna).

\textbf{Wniosek praktyczny:} Wystarczy wygenerować jedną, dostatecznie długą trajektorię łańcucha Markowa. Daje ona „reprezentację” całego rozkładu $\pi$, pozwalając przybliżać całki i sumy po ogromnych przestrzeniach stanów.

\subsection{Algorytm Metropolisa-Hastingsa}

Jest to ogólna i potężna metoda konstrukcji łańcucha Markowa o zadanym rozkładzie stacjonarnym $\pi$.

\textbf{Założenia:}
\begin{itemize}
    \item $S$ – co najwyżej przeliczalna przestrzeń stanów.
    \item $\pi = (\pi_i)_{i \in S}$ – docelowy rozkład prawdopodobieństwa na $S$, o którym zakładamy, że $\pi_i > 0$ dla każdego $i$.
    \item $Q = (q_{ij})_{i,j \in S}$ – macierz przejścia tzw. **łańcucha propozycji**. Musi to być macierz stochastyczna dowolnego nieprzywiedlnego łańcucha Markowa na $S$.
\end{itemize}

\begin{example}
Jako $Q$ można przyjąć np. błądzenie losowe na $\mathbb{Z}$: $q_{i, i+1} = q_{i, i-1} = 1/2$.
\end{example}

\textbf{Kroki algorytmu (przejście z kroku $n$ do $n+1$):}

Załóżmy, że proces znajduje się w stanie $X_n = i \in S$.
\begin{enumerate}
    \item \textbf{Propozycja:} Generujemy stan kandydujący $j$ z rozkładu danego przez $i$-ty wiersz macierzy $Q$. Oznaczmy to jako $j \sim Q(i, \cdot)$.

    \item \textbf{Obliczenie współczynnika akceptacji:} Obliczamy wartość:
    \[
    a(i,j) := \frac{\pi_j q_{ji}}{\pi_i q_{ij}}
    \]
    
    \begin{obserwacja}
    To kluczowa własność algorytmu: do obliczenia $a(i,j)$ wystarczy znać \textbf{stosunek} prawdopodobieństw $\pi_j / \pi_i$. Oznacza to, że nie musimy znać stałej normalizującej rozkładu $\pi$, co jest niezwykle użyteczne w praktyce (np. w statystyce bayesowskiej).
    \end{obserwacja}

    \item \textbf{Akceptacja/Odrzucenie:} Prawdopodobieństwo przejścia do stanu $j$ wynosi $\min\{1, a(i,j)\}$. W praktyce generujemy liczbę losową $u \sim U(0,1)$ i ustawiamy:
    \[
    X_{n+1} := \begin{cases}
    j, & \text{jeśli } u \le a(i,j) \quad \text{(akceptacja propozycji)} \\
    i, & \text{jeśli } u > a(i,j) \quad \text{(odrzucenie, pozostajemy w miejscu)}
    \end{cases}
    \]
\end{enumerate}

\begin{stwierdzenie}
Skonstruowany w ten sposób ciąg $(X_n)_n$ jest łańcuchem Markowa, który jest odwracalny względem $\pi$. W szczególności, jeśli jest nieprzywiedlny, to $\pi$ jest jego jedynym rozkładem stacjonarnym.
\end{stwierdzenie}

\section{Procesy Poissona}

Przechodzimy do procesów stochastycznych z czasem ciągłym. Będziemy rozważać procesy zliczające zdarzenia w czasie.

\subsection{Definicja i Intuicja}
\textbf{Proces liczący} (ang. \textit{Counting Process}) $(N_t)_{t \ge 0}$ modeluje skumulowaną liczbę zdarzeń, które zaszły do momentu $t$.

\textbf{Własności:}
\begin{enumerate}
	\item $N_t \in \mathbb{N}_0$ – wartości są liczbami całkowitymi nieujemnymi.
	\item $N_0 = 0$ – na początku nie zaobserwowaliśmy żadnych zdarzeń.
	\item Trajektorie procesu są \textbf{niemalejące} ($s < t \implies N_s \le N_t$).
	\item Trajektorie są \textbf{prawostronnie ciągłe}.
\end{enumerate}

\textbf{Przyrost procesu:}
Dla $0 \le s < t$, wielkość $N_t - N_s$ oznacza liczbę zdarzeń, które zaszły w przedziale czasu $(s, t]$.

\subsection{Proces Poissona z intensywnością $\lambda$}

Najważniejszym i najbardziej fundamentalnym przykładem procesu liczącego jest Proces Poissona $(N_t)_{t \ge 0}$ z intensywnością (ratą) $\lambda > 0$.

\begin{definition}
Proces liczący $(N_t)_{t \ge 0}$ jest procesem Poissona, jeśli spełnia następujące warunki:
\begin{enumerate}
	\item $N_0 = 0$.
	\item Proces ma \textbf{stacjonarne przyrosty}: rozkład liczby zdarzeń w dowolnym przedziale zależy tylko od jego długości. Formalnie, dla dowolnych $s, t \ge 0$:
	      \[N_{t+s} - N_s \sim \text{Poiss}(\lambda t)\]
	      W szczególnym przypadku (dla $s=0$) otrzymujemy rozkład brzegowy: $N_t \sim \text{Poiss}(\lambda t)$.
	\item Proces ma \textbf{niezależne przyrosty}: liczba zdarzeń w rozłącznych przedziałach czasu to niezależne zmienne losowe. Formalnie, dla dowolnego ciągu chwil $0 \le t_0 < t_1 < \dots < t_n$, zmienne losowe:
	      \[N_{t_1} - N_{t_0}, \ N_{t_2} - N_{t_1}, \ \dots, \ N_{t_n} - N_{t_{n-1}}\]
	      są wzajemnie niezależne.
\end{enumerate}
\end{definition}

\textbf{Interpretacja parametru $\lambda$:}
Parametr $\lambda$ to średnia liczba zdarzeń (zgłoszeń) na jednostkę czasu.
\[\mathbb{E}[N_t] = \lambda t \implies \lambda = \frac{\mathbb{E}[N_t]}{t}\]

\subsection{Przykład obliczeniowy}

Czy z powyższej definicji jesteśmy w stanie obliczyć prawdopodobieństwo łączne dla procesu w różnych chwilach czasu? Rozważmy $P(N_2=3, N_7=8)$.

Aby to zdarzenie zaszło, do chwili $t=2$ muszą zajść 3 zdarzenia, a w przedziale $(2, 7]$ musi zajść $8-3=5$ zdarzeń. Możemy to zapisać przy pomocy przyrostów:
\[ P(N_2=3, N_7=8) = P(N_2 - N_0 = 3, \ N_7 - N_2 = 5) \]
Przedziały czasu $[0, 2]$ i $(2, 7]$ są rozłączne, więc na mocy własności niezależnych przyrostów:
\begin{align*}
P(N_2=3, N_7=8) &= P(N_2 - N_0 = 3) \cdot P(N_7 - N_2 = 5) \\
&= P(N_2 = 3) \cdot P(N_7 - N_2 = 5)
\end{align*}
Teraz korzystamy ze stacjonarności przyrostów:
\begin{itemize}
    \item $N_2 = N_2 - N_0$ to przyrost na przedziale o długości 2, więc $N_2 \sim \text{Poiss}(2\lambda)$.
    \item $N_7 - N_2$ to przyrost na przedziale o długości $7-2=5$, więc $N_7-N_2 \sim \text{Poiss}(5\lambda)$.
\end{itemize}
Ostatecznie, korzystając ze wzoru na prawdopodobieństwo w rozkładzie Poissona $P(X=k) = e^{-\mu}\frac{\mu^k}{k!}$, otrzymujemy:
\[
P(N_2=3, N_7=8) = \left( e^{-2\lambda}\frac{(2\lambda)^3}{3!} \right) \cdot \left( e^{-5\lambda}\frac{(5\lambda)^5}{5!} \right) = e^{-7\lambda} \frac{8\lambda^3 \cdot 3125\lambda^5}{6 \cdot 120}
\]
Ten przykład pokazuje, jak definicja procesu Poissona pozwala w pełni określić jego rozkłady skończenie wymiarowe.


\end{document}